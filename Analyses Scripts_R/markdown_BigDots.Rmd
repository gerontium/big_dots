---
title: "BigDots"
author: "Daniel Newman"
date: "12 June 2016"
output:
  html_document:
    fig_width: 8
    keep_md: yes
  word_document: default
---

```{r Load and Pre-Process the single trial Data, echo=FALSE, include=FALSE}

####Which computer/directory is this being run on?
location<-"Monash"
# location<-"DansLaptop"

if (location=="Monash") {
    setwd(("C:/GitHub/big_dots/Analyses Scripts_R"))
} else if (location=="DansLaptop") {
    setwd(("C:/Users/Dan/Documents/GitHub/big_dots/Analyses Scripts_R"))
} else setwd(("~"))





####################################
#######  How to use ################
####################################

# 1) Install the packages and software specified below. (consider also updating all installed packages by chosing Update on the Packages tab)
# 2) Set the working directory (setwd) above, and directory where you have "data_ParticipantLevel", "master_matrix_R" and "ID_vector" saved
# 3) Hit Knit Word (or Knit HTML)! (Output can take while due to bootstrapping the robust effect size and calculating the Bayesian Highest Density Iinterval)


####################################
######  FIRST TIME ONLY ############
####################################

#Remove # in front of the line below and run the code. Replace the # after installing the packages, otherwise the R markdown script will give errors.

# install.packages(c("MASS", "akima", "robustbase", "cobs", "robust", "mgcv", "scatterplot3d", "quantreg", "rrcov", "lars", "pwr", "trimcluster", "mc2d", "psych", "Rfit","MBESS", "BayesFactor", "PoweR", "ggplot2", "reshape2", "plyr", "devtools", "rmarkdown","gmodels", "HLMdiag", "car", "gridExtra", "bootES", "BEST","foreign","nlme","pastecs","multcomp","ggplot2","compute.es","ez","lattice","lme4","effects","diagram","png", "grid", "dplyr","readxl"))

###################################################################################################################################

## Install relevant libraries 
library(foreign)
library(car)
library(nlme)
library(ggplot2)
library(pastecs)
library(psych)
library(plyr)
library(multcomp)
library(reshape2)
library(compute.es)
library(ez)
library(lattice)
library(lme4)
library(png)
library(grid)
library(readxl)

###### Import single trial data:
if (location=="Monash") {
data <- read.csv("C:/GitHub/big_dots/master_matrix_R_BigDots.csv", header=FALSE)
} else if (location=="DansLaptop") {
data <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/master_matrix_R_BigDots.csv", header=FALSE)
} else setwd(("~"))
#Import IDs:
if (location=="Monash") {
ID <- read.table("C:/GitHub/big_dots/ID_vector_BigDots.csv", quote="\"")
} else if (location=="DansLaptop") {
ID <- read.table("C:/Users/Dan/Documents/GitHub/big_dots/ID_vector_BigDots.csv", quote="\"")
} else setwd(("~"))

data$ID<-data[,1]
#Replace the participant numbers with IDs:
data[,1]<-ID[,1]
#Remove the seperate ID vector now it has been included into data dataframe
rm(ID)
drops <- c("ID")
data<-data[,!(names(data) %in% drops)]



#########################################################################################################################
#data_ParticipantLevel:

# ###### Import data_ParticipantLevel:
# if (location=="Monash") {
# data_participant_level <- read.csv("C:/GitHub/big_dots/participant_level_matrix.csv", header=FALSE)
# } else if (location=="DansLaptop") {
# data_participant_level <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/participant_level_matrix.csv", header=FALSE)
# } else setwd(("~"))
# 
# 
# #Import IDs:
# if (location=="Monash") {
# ID <- read.table("S:/R-MNHS-SPP/Bellgrove-data/11.Megan_ONeill/Analysis Scripts_Matlab/IDs.csv", quote="\"")
# } else if (location=="DansLaptop") {
# ID <- read.csv("C:/Users/Dan/Documents/GitHub/10_10_repeatvsnon10_10_repeat/Analyses Scripts_Matlab/IDs.csv", header=F)
# } else setwd(("~"))
# ID<-plyr::rename(ID,c("V1"="ID"))
# data_participant_level$ID<-ID$ID
# rm(ID)
# # drops <- c("ID")
# # data_participant_level<-data_participant_level[,!(names(data_participant_level) %in% drops)]
# 
# #import demographic data
# if (location=="Monash") {
# Demographics<-read.csv("S:/R-MNHS-SPP/Bellgrove-data/11.Megan_ONeill/Analysis Scripts_R/10_10_repeat_non10_10_repeat_Demographics_etc.csv", header=T)
# } else if (location=="DansLaptop") {
# Demographics<-read.csv("C:/Users/Dan/Documents/GitHub/10_10_repeatvsnon10_10_repeat/Analyses Scripts_R/10_10_repeat_non10_10_repeat_Demographics_etc.csv", header=T)
# } else setwd(("~"))
# 
# 
# 
# #Merge Demographics into data_participant_level:
# data_participant_level <- merge(data_participant_level, Demographics, by.x = "ID", by.y = "ID")
# rm(Demographics)

#########################################################################################################################


#Rename data columns:
data<-rename(data, c("V1"="ID","V2"="TotalTrialNumber","V3"="Trial","V4"="ITI","V5"="Hemifield", "V6"="Accuracy",
                     "V7"="Art_neg500_0", "V8"="Art_neg100_100PR","V9"="Art_neg500_100PR", "V10"="Art_neg100_1000",
                     "V11"="FixBreak_neg500_0", "V12"="FixBreak_neg100_100PR","V13"="FixBreak_neg500_100PR", "V14"="FixBreak_neg100_1000",
                     "V15"="RT"))   
#NOTE: FOR N2c/i,  the _GA or _PA suffix indicates whether N2c/i is measured with a measurement window based
#on Grand average (GA) peak N2c/i latency,  or based on Participant level average (PA) peak N2c/i latency
             
#Make the required columns into factors:
data$ITI <- factor(data$ITI)
data$Hemifield <- factor(data$Hemifield)
data$Accuracy <- factor(data$Accuracy)

#Rename factor Levels:
data$Hemifield <- revalue(data$Hemifield, c("1"="Left", "2"="Right"))
data$Accuracy <- revalue(data$Accuracy, c("1"="Hit", "0"="RejectedTrial", "2"="WrongButton", "3"="Miss"))


#Re-class required vectors into Logicals:
data$Art_neg500_0<-!as.logical(data$Art_neg500_0)
data$Art_neg100_100PR<-!as.logical(data$Art_neg100_100PR)
data$Art_neg500_100PR<-!as.logical(data$Art_neg500_100PR)
data$Art_neg100_1000<-!as.logical(data$Art_neg100_1000)
data$FixBreak_neg500_0<-!as.logical(data$FixBreak_neg500_0)
data$FixBreak_neg100_100PR<-!as.logical(data$FixBreak_neg100_100PR)
data$FixBreak_neg500_100PR<-!as.logical(data$FixBreak_neg500_100PR)
data$FixBreak_neg100_1000<-!as.logical(data$FixBreak_neg100_1000)



############################################ Import DAT1 Data ##############################################
DAT1 <- read_excel("DAT1genotypes_forR.xlsx") 
#Make the required columns into factors:
DAT1$DAT1_3UTR_VNTRraw <- factor(DAT1$DAT1_3UTR_VNTRraw)
DAT1$DAT1_Int8_VNTRraw <- factor(DAT1$DAT1_Int8_VNTRraw)
DAT1$Site <- factor(DAT1$Site)
DAT1$ID<-as.factor(DAT1$ID)

DAT1$DAT1_10_10_repeats  <- revalue(DAT1$DAT1_3UTR_VNTRraw , 
                                       c("10 10"="Two", 
                                         "10 11"="One", 
                                         "7 10"="One",
                                         "7 9"="Zero",
                                         "8 11"="Zero",
                                         "9 10"="One",
                                         "9 9"="Zero"))
summary(DAT1$DAT1_10_10_repeats)

DAT1$DAT1_3UTR  <- revalue(DAT1$DAT1_3UTR_VNTRraw , 
                                 c("10 10"="10_10_repeat", 
                                   "10 11"="non10_10_repeat", 
                                   "7 10"="non10_10_repeat",
                                   "7 9"="non10_10_repeat",
                                   "8 11"="non10_10_repeat",
                                   "9 10"="non10_10_repeat",
                                  "9 9"="non10_10_repeat"))
summary(DAT1$DAT1_3UTR)

DAT1$DAT1_int8  <- revalue(DAT1$DAT1_Int8_VNTRraw , 
                                 c("6 6"="6_6_repeat", 
                                   "5 6"="non6_6_repeat", 
                                   "5 5"="non6_6_repeat"))
summary(DAT1$DAT1_int8)

#Only keep Genotypes for the participants who we actually tested on big dots 
#(there are a few extra participant genotypes in the DAT1 sheet)
DAT1 <-DAT1[DAT1$ID %in% data$ID, ]

#How many participant's have missing DAT1 genotype?
summary(DAT1$DAT1_3UTR) #So 4 participant have missing DAT1 genotype

#### Merge the data sets together
data<-merge(data, DAT1, by.x = "ID", by.y = "ID") 

################################################################################################



###############Data Cleaning For Single Trial Data######################


#Check number of Trials for each participant by running the function 'length', 
#on "data$RT" for each DAT1_3UTR, broken down by ID + Light
num_trials1 <- ddply(data, c("ID"), summarise,
               Trials    = length(RT))
summary(num_trials1$Trials)
mean(num_trials1$Trials)

##################Accuracy ##########################
Accuracy_checker <- ddply(data, c("ID"), summarise,
               Hits  = sum(Accuracy=="Hit"),
               Misses = sum(Accuracy=="Miss" | Accuracy=="WrongButton"))
Accuracy_checker$Total=Accuracy_checker$Hits+Accuracy_checker$Misses
Accuracy_checker$Accuracy_overall=(Accuracy_checker$Hits/Accuracy_checker$Total)*100
summary(Accuracy_checker$Accuracy_overall)

##Add in overall accuracy 
data <- merge(data, Accuracy_checker, by.x = "ID", by.y = "ID")

#Remove trials where RT=0 (i.e. they did not respond)
data<-data[data$RT!=0,]
#Remove trials where RT longer than 1000ms (i.e. after target finished)
data<-data[data$RT<1500,]
#Remove trials where RT faster than 100ms (i.e. too fast must be false alarm)
data<-data[data$RT>150,]
#Kick out trials with fixation breaks:
data<-data[!data$FixBreak_neg100_100PR,]

############################################ Log transform:
##############################################################################################
data$log_RT<-log(data$RT) #log
#####Z-score each participant's log_RT data ####
data$IDbyITIbyHemifield<-interaction(data$ID, data$ITI, data$Hemifield)
#calculate mean and sd 
m <- tapply(data$log_RT,data$IDbyITIbyHemifield,mean)
s <- sqrt(tapply(data$log_RT,data$IDbyITIbyHemifield,var))
#calculate log_RT.Z and save it inside data.frame
data$log_RT.Z <- (data$log_RT-m[data$IDbyITIbyHemifield])/s[data$IDbyITIbyHemifield]
#check that Z scores have mean=0 and std=1 
log_RT.Z_checker <- ddply(data, c("ID", "ITI", "Hemifield"), summarise,
               N    = length(log_RT.Z ),
               mean = round(mean(log_RT.Z )),
               sd   = sd(log_RT.Z ),
               se   = sd / sqrt(N))
summary(log_RT.Z_checker$mean)#make sure mean is 0
summary(log_RT.Z_checker$sd) #Make sure SD is 1

#Remove trials where absolute log_RT.Z>3 (i.e. remove outlier RTs)
data<-data[!abs(data$log_RT.Z)>3,]


#plot again after outlier removal:
ggplot(data, aes(RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white") 
ggplot(data, aes(log_RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white") 


# #Calculate alpha desynchronisation by subtracting Pre-target Alpha from post target alpha
# data$AlphaDesyncRH<-(data$PreAlphaPowerRH)-(data$PostAlphaPowerRH)
# data$AlphaDesyncLH<-data$PreAlphaPowerLH-data$PostAlphaPowerLH
# 
# # Make PostAlpha contralateral (PostAlpha_c) and -Ipsilateral (PostAlpha_i) variables:
# A<-data$Hemifield=="Left"
# #Absolute post target alpha
# data$PostAlpha_c[A]<-data$PostAlphaPowerRH[A]
# data$PostAlpha_c[!A]<-data$PostAlphaPowerLH[!A]
# data$PostAlpha_i[!A]<-data$PostAlphaPowerRH[!A]
# data$PostAlpha_i[A]<-data$PostAlphaPowerLH[A]
# 
# #Post target Alpha desynchronisation 
# data$AlphaDesync_c[A]<-data$AlphaDesyncRH[A]
# data$AlphaDesync_c[!A]<-data$AlphaDesyncLH[!A]
# data$AlphaDesync_i[!A]<-data$AlphaDesyncRH[!A]
# data$AlphaDesync_i[A]<-data$AlphaDesyncLH[A]
# 
# rm(A)

#################################################################################################################################
#################################################################################################################################
#################################################################################################################################
#################################################################################################################################
# Participant level data

# #Rename data_participant_level columns of data_participant_level:
# data_participant_level<-rename(data_participant_level, c("V1"="ValidPreAlphaTrials",
#                      "V2"="ValidERPTrials","V3"="PreAlpha_LeftHemi",
#                      "V4"="PreAlpha_RightHemi","V5"="N2c_LeftTarget_PA","V6"="N2c_RightTarget_PA",
#                      "V7"="N2i_LeftTarget_PA","V8"="N2i_RightTarget_PA","V9"="AlphaDesync_LeftHemi_LeftTarget",
#                      "V10"="AlphaDesync_LeftHemi_RightTarget","V11"="AlphaDesync_RightHemi_LeftTarget",
#                      "V12"="AlphaDesync_RightHemi_RightTarget",
#                      "V13"="CPPonset_LeftTarget","V14"="CPPonset_RightTarget","V15"="N2c_latency_LeftTarget",
#                      "V16"="N2c_latency_RightTarget","V17"="N2i_latency_LeftTarget","V18"="N2i_latency_RightTarget",
#                      "V19"="CPPslope_LeftTarget","V20"="CPPslope_RightTarget","V21"="DAT1_3UTR"))
# 
# 
# #NOTE: FOR N2c/i ,  the _GA or _PA suffix indicates whether N2c/i is measured with a measurement window based  
# #on Grand average (GA) peak N2c/i latency ,  or based on Participant level average (PA) peak N2c/i latency
# 
# #Look at Column names:
# colnames(data_participant_level)
#              
# #Make the required columns into factors:
# data_participant_level$DAT1_3UTR <- factor(data_participant_level$DAT1_3UTR)
# data_participant_level$Gender <- factor(data_participant_level$Gender)
# 
# #Rename factor Levels:
# data_participant_level$DAT1_3UTR <- revalue(data_participant_level$DAT1_3UTR, c("1"="10_10_repeat", "2"="non10_10_repeat"))
# 
# #add in accuracy
# data_participant_level <- merge(data_participant_level, Accuracy_checker, by.x = "ID", by.y = "ID")
# data <- merge(data, Accuracy_checker, by.x = "ID", by.y = "ID")
# 
# ###Incorporate the demographic variables from data_participant_level into the single trial 'data' dataframe 
# target<-dplyr::select(data_participant_level, ID, Gender, Age,  Years_of_Education, Greyscale_correct, Greyscales_L_chosen, Bells_Cancellation, CoC_Index, Extinction,          Landmark_Spatial_Index)
# 
# data<-merge(data, target, by.x="ID", by.y = "ID")
# rm(target)

#Calculate the number of trials each participant has left after fixation break trials are kicked out:
num_trials2 <- ddply(data, c("ID"), summarise,
               Num_RT_Trials    = length(RT))
```

#First Look at the effect of Hemifield on RT, regardless of DAT1 genotype (because we loose 4 participants with failed genotypes later when testing for effect of DAT1 genotype)
```{r, echo=FALSE, warning=FALSE}
RT_random_effects_only<-lmer(log(RT) ~ 1 + (Hemifield | ID) +(1|ITI) + (1|Trial), data = data, REML=FALSE, na.action = na.omit)
RT_Hemifield<-update(RT_random_effects_only, .~. + Hemifield)
RT_TOT<-update(RT_Hemifield, .~. + Trial)
RT_Hemifield_by_TOT<-update(RT_TOT, .~. + Hemifield:Trial)
anova(RT_random_effects_only, RT_Hemifield, RT_Hemifield_by_TOT)


source("summarySE.R") 
source("summarySEwithin.R") #function to calculate Std.Er of mean
source("normDataWithin.R")
plotdata <- summarySEwithin(data, measurevar="RT", withinvars=c("Hemifield"), idvar="ID")
ggplot(plotdata, aes(x=Hemifield, y=RT, fill=Hemifield)) +
    geom_bar(position=position_dodge(.9), colour="Black", stat="identity") + 
    geom_errorbar(position=position_dodge(.9), width=.3, aes(ymin=RT-ci, ymax=RT+ci)) + #can change "se" to "ci" if I want to use 95%ci instead
    geom_hline(yintercept=0) +  coord_cartesian(ylim = c(400, 600)) +
    xlab("Hemifield") + ylab("RT (ms)") +
    theme(axis.title.x = element_text(face="bold", size=12),
          axis.text.x  = element_text(face="bold", angle=0,  size=12)) +
    theme(axis.title.y = element_text(face="bold", size=12),
          axis.text.y  = element_text(angle=0, vjust=0.5, size=12)) +
    theme(legend.title = element_text(size=11, face="bold")) +
    theme(legend.text = element_text(size = 11, face = "bold")) +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
          panel.background = element_blank(), axis.line = element_line(colour = "black")) 


#Look at a boxplot of RT
ggplot(data, aes(Hemifield, RT, colour = Hemifield))  + 
    geom_boxplot() + coord_flip() + theme_bw ()

#Look at a boxplot of log(RT)
ggplot(data, aes(Hemifield, log(RT), colour = Hemifield))  + 
    geom_boxplot() + coord_flip() + theme_bw ()


#Plot the effect of Hemifield*Time-on-task
ggplot(data, aes(x=data$Trial, y=data$RT,fill=Hemifield,colour=Hemifield)) +
     # stat_smooth(method="glm",level = 0.95,size=1) + # Add a glm smoothed fit curve with 95% confidence region around the three light conditions
    geom_smooth() +
    scale_fill_manual(name="Target\nHemifield",  breaks=c("Left", "Right"), labels=c(" Left", " Right"), guide = guide_legend(reverse=TRUE), values=c("#999999", "black")) +
    scale_colour_manual(name="Target\nHemifield",  breaks=c("Left", "Right"), labels=c(" Left", " Right"), guide = guide_legend(reverse=TRUE), values=c("black", "black")) +
    ylab("RT (ms)") +  xlab("Time On Task (trials)") + coord_cartesian(ylim = c(500, 700))+
    theme(axis.title.x = element_text(face="bold", size=14),
          axis.text.x  = element_text(face="bold", angle=0,  size=12)) +
    theme(axis.title.y = element_text(face="bold", size=14),
          axis.text.y  = element_text(angle=0, vjust=0.5, size=12)) +
    theme(legend.title = element_text(size=14, face="bold")) +
    theme(legend.text = element_text(size = 12, face = "bold")) +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
    panel.background = element_blank(), axis.line = element_line(colour = "black")) 

##Check the plot of the model parameters matches with this^ plot of the raw data 
# require(effects)
# plot(allEffects(RT_Hemifield_by_TOT), multiline=T)


```

**So this ^ shows that regardless of DAT1 genotype, participants tended to react faster to left hemifield targets, but this leftward advangate decreased over time**

#Check for difference in behavioural accuracy between 10_10_repeat and non10_10_repeat participants?
```{r, echo=FALSE, warning=FALSE}
data2<-data[complete.cases(data$DAT1_3UTR),]####### This kicks out 4 the participants for which we didn't have DAT1 genotpes  


Accuracy_collapsed<-ddply(data2, .(ID, DAT1_3UTR), summarise, Accuracy=mean(Accuracy_overall))
###Check for Accuracy_overall outliers
min(Accuracy_collapsed$Accuracy)
#Plot the Accuracy distribution for each DAT1_3UTR
ggplot(Accuracy_collapsed, aes(Accuracy))  + geom_histogram() + facet_wrap(~ DAT1_3UTR)

############ Are there significant accuracy differences between 10_10_repeat and non10_10_repeat? ##############
##############################################################
#Overall Accuracy by DAT1_3UTR
log <- capture.output({
   Accuracy_DAT1_3UTR <- ezPerm(data = Accuracy_collapsed
                                  , dv = .(Accuracy)
                                  , wid = .(ID)
                                  , between = .(DAT1_3UTR)
                                  , perms = 1000);
 })
print("Factorial Permutation test for the effect of DAT1_3UTR on Accuracy:")
print(Accuracy_DAT1_3UTR);
```



**So this ^ shows shows no significant difference in accuracy between the DAT1 genotype groups** 

#Simple effects of Genotype inside each DAT1 Group show that non10_10_repeat participants have significant leftward RT asymmetry, and the 10_10_repeat participants do not
```{r, echo=FALSE, warning=FALSE}
#Calculate the number of trials each participant has left after NAs are kicked out:
num_trials2 <- ddply(data2, c("ID"), summarise,
               Num_RT_Trials    = length(RT))

summary(num_trials2)


data2$DAT1_3UTR_by_Hemifield<-interaction(data2$DAT1_3UTR, data2$Hemifield)
ggplot(data2, aes(RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white") + facet_wrap(~ DAT1_3UTR_by_Hemifield)
ggplot(data2, aes(log_RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white") + facet_wrap(~ DAT1_3UTR_by_Hemifield)

#Try a density plot
ggplot(data2, aes(RT, colour = DAT1_3UTR_by_Hemifield))  + 
    geom_density(alpha = 0.1) 



#So get participant level RT into long format so I can run permutated t-tests  
RT_collapsed<-ddply(data2, .(ID, Hemifield, DAT1_3UTR), summarise, RT=mean(RT))

#Plot RT by DAT1_3UTR and hemifield:
RT_collapsed$DAT1_3UTR_by_Hemifield<-interaction(RT_collapsed$Hemifield, RT_collapsed$DAT1_3UTR)
#non log transformed:
ggplot(RT_collapsed, aes(RT))  + geom_histogram() + facet_wrap(~ DAT1_3UTR_by_Hemifield)
#Try a density plot
ggplot(RT_collapsed, aes(RT, colour = DAT1_3UTR_by_Hemifield))  + 
    geom_density(alpha = 0.1) 



## 2 seperate permutated within subjects test for the effect of Hemifield##
#non10_10_repeat:
log <- capture.output({
RT_Hemifield_non10_10_repeat <- ezPerm(data = dplyr::filter(RT_collapsed, DAT1_3UTR=="non10_10_repeat")
                                  , dv = .(RT)
                                  , wid = .(ID)
                                  , within = .(Hemifield)
                                  , perms = 1000
) })
print("Factorial Permutation test for the simple effect of Target Hemifield on RT in the non10_10_repeat group:")
print(RT_Hemifield_non10_10_repeat)



#10_10_repeat:
log <- capture.output({
RT_Hemifield_10_10_repeat <- ezPerm(data = dplyr::filter(RT_collapsed, DAT1_3UTR=="10_10_repeat")
                                  , dv = .(RT)
                                  , wid = .(ID)
                                  , within = .(Hemifield)
                                  , perms = 1000
)})
print("Factorial Permutation test for the simple effect of Target Hemifield on RT in the 10_10_repeat group:")
print(RT_Hemifield_10_10_repeat)



```


###However, the difference the DAT1Group x Hemifield interaction in RT is not significant, and also there is no significant difference in RT-asymmetry between the 10_10_repeat and non10_10_repeat DAT1_3UTRs:

```{r, echo=FALSE, warning=FALSE}
log <- capture.output({
RT_Hemifield_by_DAT1_3UTR <- ezPerm(data = RT_collapsed
                                  , dv = .(RT)
                                  , wid = .(ID)
                                  , within = .(Hemifield)
                                  , between = .(DAT1_3UTR)
                                  , perms = 1000
)})
print("Factorial Permutation test for Hemifield x DAT1 group interaction on RT:")
print(RT_Hemifield_by_DAT1_3UTR)


##Try the old school 
ezANOVA(
    data = RT_collapsed
    , dv = .(RT)
    , wid = .(ID)
    , within = .(Hemifield)
    , between = .(DAT1_3UTR)
    , observed = .(DAT1_3UTR)
    , type = 3
    , detailed = F
)


######Calculate RT asymmetry Index and add it to "data_participant_level"######
#Collapse each participant's trials accross ITI
RT_collapsed<-ddply(data2, .(ID, Hemifield, DAT1_3UTR), summarise, RT=mean(RT))
#Bring Target-Hemifield up into wide format
RT_collapsed <- dcast(RT_collapsed, ID  ~ Hemifield, value.var="RT", fun.aggregate=mean)
RT_collapsed<-rename(RT_collapsed, c("Left"="RT_Left", "Right"="RT_Right"))
#Calculate RT asymmetry
RT_collapsed$RT_Asym<-(RT_collapsed$RT_Left-RT_collapsed$RT_Right)/(RT_collapsed$RT_Left+RT_collapsed$RT_Right)
RT_collapsed<-merge(RT_collapsed, DAT1, by.x = "ID", by.y = "ID") 

##################################################################################
ggplot(RT_collapsed, aes(RT_Asym))  + geom_histogram(aes(y=..count..), colour="black", fill="white") + facet_wrap(~ DAT1_3UTR)
#Try a density plot
ggplot(RT_collapsed, aes(RT_Asym, colour = DAT1_3UTR))  + 
    geom_density(alpha = 0.1) 

#Remove outliers
RT_collapsed$RT_Asym.Z<-scale(RT_collapsed$RT_Asym)
RT_collapsed<-RT_collapsed[abs(RT_collapsed$RT_Asym.Z)<3,]
#Try a density plot after outlier remove
ggplot(RT_collapsed, aes(RT_Asym, colour = DAT1_3UTR))  + 
    geom_density(alpha = 0.1) 

RT_Asym.mean <- ddply(RT_collapsed, "DAT1_3UTR", summarise, RT_Asym.mean=mean(RT_Asym))
RT_Asym.mean
##Between DAT1_3UTRs t-test for RT_Asym
t.test(RT_collapsed$RT_Asym ~ RT_collapsed$DAT1_3UTR)

##Try permutated t-test
log <- capture.output({
RTasym_DAT1_3UTR <- ezPerm(data = RT_collapsed
                                  , dv = .(RT_Asym)
                                  , wid = .(ID)
                                  , between = .(DAT1_3UTR)
                                  , perms = 1000
)})
print("Factorial Permutation test for effect if DAT1 group RT Asymmetry:")
print(RTasym_DAT1_3UTR)

```


#Try linear mixed model approach to test the DAT1_3UTR x Hemifield effect on log(RTs) in the single trial data:

```{r, echo=FALSE, warning=FALSE}

#Uncomment this if you want to kick out the 2 participants with lowest accuracy
### data2<-dplyr::filter(data2, Accuracy_overall>80)

#Plots show that a log transform fixes the skew in the single trial data
ggplot(data2, aes(RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white") + facet_wrap(~ DAT1_3UTR)
ggplot(data2, aes(log_RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white") + facet_wrap(~ DAT1_3UTR)


########################### Multi-level Models ########################## 
RT_random_intercepts_only<-lmer(log(RT) ~ 1 + (Hemifield + Trial | ID) +(1|ITI) + (1|Trial), data = data2, REML=FALSE, na.action = na.omit)
RT_DAT1_3UTR<-update(RT_random_intercepts_only, .~. + DAT1_3UTR)
RT_Hemifield<-update(RT_DAT1_3UTR, .~. + Hemifield)
RT_HemifieldbyDAT1_3UTR<-update(RT_Hemifield, .~. + Hemifield:DAT1_3UTR)
anova(RT_random_intercepts_only, RT_DAT1_3UTR, RT_Hemifield, RT_HemifieldbyDAT1_3UTR)


# RT_random_intercepts_only<-glmer(log(RT) ~ 1 + (Hemifield | ID) +(1|ITI) + (1|Trial), data = data2, family = Gamma(link = log) , na.action = na.omit)
# RT_DAT1_3UTR<-update(RT_random_intercepts_only, .~. + DAT1_3UTR)
# RT_Hemifield<-update(RT_DAT1_3UTR, .~. + Hemifield)
# RT_HemifieldbyDAT1_3UTR<-update(RT_Hemifield, .~. + Hemifield:DAT1_3UTR)
# anova(RT_random_intercepts_only, RT_DAT1_3UTR, RT_Hemifield, RT_HemifieldbyDAT1_3UTR)

# require(LMERConvenienceFunctions)
#   data2 <- romr.fnc(RT_HemifieldbyDAT1_3UTR, data2, trim = 3)
#   data2$n.removed
#   data2$percent.removed
#   data2<-data2$data

```

**So the linear mixed model approach ^ shows no significant DAT1_3UTR x Hemifield effect**

##However simple effects of hemifield inside DAT1_3UTR linear mixed model approach confirms that non10_10_repeat participants have signficantly faster RTs to left targets and 10_10_repeat participants do not: 
```{r, echo=FALSE, warning=FALSE}
#########Break down the signifiant Hemifield by DAT1_3UTR interaction:
#look at the effect of Hemifield for 10_10_repeat only  -
summary(glht(lmer(log(RT) ~ Hemifield + (Hemifield|ID)+(1|ITI) + (1|Hemifield)+ (1|Trial), data = data2[data2$DAT1_3UTR=="10_10_repeat",], REML=FALSE, na.action = na.omit)))
#look at the effect of Hemifield for non10_10_repeat only - 
summary(glht(lmer(log(RT) ~ Hemifield + (Hemifield|ID)+(1|ITI) + (1|Hemifield)+ (1|Trial), data = data2[data2$DAT1_3UTR=="non10_10_repeat",], REML=FALSE, na.action = na.omit)))

```

###So non10_10_repeat have significant pseudoneglect (i.e. faster RTs to left hemifield targets), and 10_10_repeat do not, but this is only seen in the simple effects (doing seperate test for each DAT1_3UTR). The factorial design gives no significant DAT1_3UTR x Hemifield effect



##Look at the DAT1Group x Hemifield x Time-on-task interaction in the single trial data:
```{r, echo=FALSE, warning=FALSE}

RT_random_effects_only<-lmer(log(RT) ~ 1 + (1 | ID) +(1|ITI) + (1|Trial), data = data2, REML=FALSE, na.action = na.omit)
RT_Hemifield<-update(RT_random_effects_only, .~. + Hemifield)
RT_DAT1<-update(RT_Hemifield, .~. + DAT1_3UTR)
RT_TOT<-update(RT_DAT1, .~. + Trial)
RT_Hemifield_by_DAT1<-update(RT_TOT, .~. + Hemifield:DAT1_3UTR)
RT_Hemifield_by_TOT<-update(RT_Hemifield_by_DAT1, .~. + Hemifield:Trial)
RT_DAT1_by_TOT<-update(RT_Hemifield_by_TOT, .~. + DAT1_3UTR:Trial)
RT_Hemifield_by_DAT1_by_TOT<-update(RT_DAT1_by_TOT, .~. + Hemifield:DAT1_3UTR:Trial)
anova(RT_random_effects_only, RT_Hemifield, RT_DAT1,RT_TOT, RT_Hemifield_by_DAT1, RT_Hemifield_by_TOT,RT_DAT1_by_TOT,RT_Hemifield_by_DAT1_by_TOT)



#Plot the effect of Hemifield*Time-on-task
ggplot(data2, aes(x=data2$Trial, y=data2$RT,fill=Hemifield,colour=Hemifield)) +
     # stat_smooth(method="glm",level = 0.95,size=1) + # Add a glm smoothed fit curve with 95% confidence region around the three light conditions
    geom_smooth() +
    scale_fill_manual(name="Target\nHemifield",  breaks=c("Left", "Right"), labels=c(" Left", " Right"), guide = guide_legend(reverse=TRUE), values=c("#999999", "black")) +
    scale_colour_manual(name="Target\nHemifield",  breaks=c("Left", "Right"), labels=c(" Left", " Right"), guide = guide_legend(reverse=TRUE), values=c("black", "black")) +
    ylab("RT (ms)") +  xlab("Time On Task (trials)") + coord_cartesian(ylim = c(500, 650))+
    theme(axis.title.x = element_text(face="bold", size=14),
          axis.text.x  = element_text(face="bold", angle=0,  size=12)) +
    theme(axis.title.y = element_text(face="bold", size=14),
          axis.text.y  = element_text(angle=0, vjust=0.5, size=12)) +
    theme(legend.title = element_text(size=14, face="bold")) +
    theme(legend.text = element_text(size = 12, face = "bold")) +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
    panel.background = element_blank(), axis.line = element_line(colour = "black")) + facet_wrap(~ DAT1_3UTR)


```

###So there is no evidence for a 3-way DAT1Group x Hemifield x Time-on-task interaction. I haven't included random slopes directly above, so if there was any hint on a 3-way DAT1Group x Hemifield x Time-on-task interaction this model should have detected 
