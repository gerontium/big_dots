---
title: "BigDots"
author: "Daniel Newman"
output:
  html_document:
    fig_width: 8
    keep_md: yes
  word_document: default
---

```{r Load and Pre-Process the single trial Data, echo=FALSE, include=FALSE, warning=FALSE}

####Which computer/directory is this being run on?
location<-"Monash"
# location<-"GersLaptop"

if (location=="Monash") {
    setwd(("C:/GitHub/big_dots/Analyses Scripts_R"))
} else if (location=="GersLaptop") {
    setwd(("C:/Users/loughnge/Documents/GitHub/big_dots/Analyses Scripts_R"))
} else setwd(("~"))



### Install/load required packages
#List of R packages required for this analysis:
required_packages <- c("psych", "ggplot2", "dplyr", "tidyr", "stringr", "lubridate", "readxl","knitr",
                       "readr", "rmarkdown", "png", "lme4", "ez", "multcomp","zoo")
#Install required_packages:
new.packages <- required_packages[!(required_packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
#Load required_packages:
lapply(required_packages, require, character.only = TRUE)


#Set decimal points and disable scientific notation
options(digits=3, scipen=999) 


###### Import single trial data:
if (location=="Monash") {
data <- read.csv("C:/GitHub/big_dots/master_matrix_R_BigDots.csv", header=FALSE)
} else if (location=="GersLaptop") {
data <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/master_matrix_R_BigDots.csv", header=FALSE)
} else setwd(("~"))
#Import IDs:
if (location=="Monash") {
ID <- read.table("C:/GitHub/big_dots/ID_vector_BigDots.csv", quote="\"")
} else if (location=="GersLaptop") {
ID <- read.table("C:/Users/Dan/Documents/GitHub/big_dots/ID_vector_BigDots.csv", quote="\"")
} else setwd(("~"))

data$ID<-data[,1]
#Replace the participant numbers with IDs:
data[,1]<-ID[,1]
#Remove the seperate ID vector now it has been included into data dataframe
rm(ID)
drops <- c("ID")
data<-data[,!(names(data) %in% drops)]


###Read in Participant Demographics (note for Sex 1=male)
Demographics<-read_excel("Participant_Demographics.xlsx") %>% #then calculate Age at testing date:
    mutate(Age_as_period=as.period(interval(Date_Of_Birth, Date_Of_Testing), units="years")) %>%
    mutate(Sex = ifelse(Sex==1, "Male", "Female"))
#Calculate Age in numeric format
Demographics$Age<-as.numeric(difftime(as.Date(Demographics$Date_Of_Testing), as.Date(Demographics$Date_Of_Birth), units = "days")/365)
summary(Demographics$Age)


#########################################################################################################################

data<- data %>% #Rename data columns:
    rename(., 
            ID=V1,
            TotalTrialNumber=V2,
            Trial=V3,
            ITI=V4,
            Hemifield=V5,
            Accuracy=V6,
            Art_neg500_0=V7,
            Art_neg100_100PR=V8,
            Art_neg500_100PR=V9,
            Art_neg100_1000=V10,
            FixBreak_neg500_0=V11,
            FixBreak_neg100_100PR=V12,
            FixBreak_neg500_100PR=V13,
            FixBreak_neg100_1000=V14,
            RT=V15,
           PreAlphaPower=V16,
           PreAlphaPowerLH=V17,
           PreAlphaPowerRH=V18,
           PreAlphaAsym=V19,
           PostAlphaPowerLH=V20,
           PostAlphaPowerRH=V21,
           Location=V22) %>% #next make the required columns into factors:
    mutate_each_(funs(factor), c("ITI", "Hemifield", "Accuracy")) %>% #next re-class required vectors into Logicals:
    mutate_at(vars(starts_with("Art_")), funs(as.logical)) %>% 
    mutate_at(vars(starts_with("FixBreak_")), funs(as.logical)) %>% #next use the ! negation operator to reverse of a TRUE/FALSE vectors: 
    mutate_if(purrr::is_logical, funs(!.)) %>% #next Rename factor Levels:
    mutate(Hemifield = ifelse(Hemifield==1, "Left", "Right"), 
           Accuracy= ifelse(Accuracy==1, "Hit", ifelse(Accuracy==2, "WrongButton", "Miss")),
            Location = ifelse(Location==1, "TCD", "Monash"))


Demographics <-Demographics[Demographics$ID %in% data$ID, ]   

###############Data Cleaning For Single Trial Data######################

#Check number of Trials for each participant by running the function 'length', 
#on "data$RT" for each DAT1_3UTR, broken down by ID + Light
num_trials1 <- data %>% group_by(ID) %>% summarise( Trials = length(RT))
summary(num_trials1$Trials)


##################Accuracy ##########################
Accuracy_checker <- data %>% group_by(ID) %>% 
                    summarise(Hits  = sum(Accuracy=="Hit"),
                               Misses = sum(Accuracy=="Miss" | Accuracy=="WrongButton")) %>%
                    mutate(Total=Hits+Misses,
                           Accuracy_overall= (Hits/Total)*100) 
summary(Accuracy_checker$Accuracy_overall)

##Add in overall accuracy 
data <- merge(data, Accuracy_checker, by.x = "ID", by.y = "ID")

######Test for effect of Hemifield on Accuracy:
# Accuracy_checker <- data %>% group_by(ID, Hemifield) %>% 
#                     summarise(Hits  = sum(Accuracy=="Hit"),
#                                Misses = sum(Accuracy=="Miss" | Accuracy=="WrongButton")) %>%
#                     mutate(Total=Hits+Misses,
#                            Accuracy_overall= (Hits/Total)*100) 
# log <- capture.output({
#    Hemifield_Perm <- ezPerm(data = data.frame(Accuracy_checker)
#                           , dv = .(Accuracy_overall)
#                           , wid = .(ID)
#                           , within = .(Hemifield)
#                           , perms = 1000);
#  })
# print("Factorial Permutation test for the effect of Hemifield Accuracy:")
# print(Hemifield_Perm);
##########################################################################


###Remove trials where:
#RT longer than 1000ms (i.e. after target finished)
#RT faster than 100ms (i.e. too fast must be false alarm) or RT=0 (i.e. they did not respond)
#Kick out trials with fixation breaks:
data<-filter(data, RT<1500, RT>150, !-FixBreak_neg100_100PR)


############################################ Log transform:
##############################################################################################
data$log_RT<-log(data$RT) #log
#####Z-score each participant's log_RT data ####
data$IDbyITIbyHemifield<-interaction(data$ID, data$ITI, data$Hemifield)
#calculate mean and sd 
m <- tapply(data$log_RT,data$IDbyITIbyHemifield,mean, na.rm = T)
s <- tapply(data$log_RT,data$IDbyITIbyHemifield,sd, na.rm = T)
#calculate log_RT.Z and save it inside data.frame
data$log_RT.Z <- (data$log_RT-m[data$IDbyITIbyHemifield])/s[data$IDbyITIbyHemifield]
#Remove trials where absolute log_RT.Z>3 (i.e. remove outlier RTs)
data<-data[!abs(data$log_RT.Z)>3,]


#plot again after outlier removal:
ggplot(data, aes(RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white") 
ggplot(data, aes(log_RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white") 


#Calculate the number of trials each participant has left after fixation break trials are kicked out:
num_trials2 <- data %>% group_by(ID) %>% summarise( Trials = length(RT))
summary(num_trials2$Trials)

####Import participant_level_matrix with ERP measures
if (location=="Monash") {
participant_level <- read.csv("C:/GitHub/big_dots/participant_level_matrix.csv", header=FALSE)
} else if (location=="DansLaptop") {
participant_level <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/participant_level_matrix.csv", header=FALSE)
} else setwd(("~"))
#Import IDs:
if (location=="Monash") {
ID <- read.table("C:/GitHub/big_dots/IDs.csv", quote="\"")
} else if (location=="DansLaptop") {
ID <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/IDs.csv", header=F)
} else setwd(("~"))
ID<-plyr::rename(ID,c("V1"="ID"))
participant_level$ID<-ID$ID
rm(ID)

participant_level<- participant_level %>% #Rename data columns:
                            rename(., 
                                    N2c_LeftTarget=V1,
                                    N2c_RightTarget=V2,
                                    N2i_LeftTarget=V3,
                                    N2i_RightTarget=V4,
                                    N2c_latency_LeftTarget=V5,
                                    N2c_latency_RightTarget=V6,
                                    N2i_latency_LeftTarget=V7,
                                    N2i_latency_RightTarget=V8,
                                    CPPonset_LeftTarget=V9,
                                    CPPonset_RightTarget=V10,
                                    CPPslope_LeftTarget=V11,
                                    CPPslope_RightTarget=V12,
                                    Location=V13 ) %>% ##next calculate the ERP asymmetry measures:
                            mutate(., 
                                  N2c_Asym = (N2c_LeftTarget-N2c_RightTarget)/(N2c_LeftTarget+N2c_RightTarget), 
                                  N2i_Asym = (N2i_LeftTarget-N2i_RightTarget)/(N2i_LeftTarget+N2i_RightTarget),
                                  N2c_latency_Asym = (N2c_latency_LeftTarget-N2c_latency_RightTarget)/(N2c_latency_LeftTarget+N2c_latency_RightTarget), 
                                  N2i_latency_Asym =(N2i_latency_LeftTarget-N2i_latency_RightTarget)/(N2i_latency_LeftTarget+N2i_latency_RightTarget),
                                  CPPonset_Asym = (CPPonset_LeftTarget-CPPonset_RightTarget)/(CPPonset_LeftTarget+CPPonset_RightTarget),
                                  CPPslope_Asym = (CPPslope_LeftTarget-CPPslope_RightTarget)/(CPPslope_LeftTarget+CPPslope_RightTarget),
                                  Location = ifelse(Location==1, "TCD", "Monash")
                                  )

####################################################################################
#Collapse each participant's PreAlpha trials to participant level
PreAlpha_collapsed<- data %>% 
            filter(!Art_neg500_0, !FixBreak_neg500_0) %>%
            group_by(ID) %>%
            summarise(PreAlphaAsym=mean(PreAlphaAsym),
                      PreAlpha_LeftHemi=mean(PreAlphaPowerLH),
                      PreAlpha_RightHemi=mean(PreAlphaPowerRH))
#Merge it in with the ERP measures
participant_level<-merge(participant_level, PreAlpha_collapsed, by.x = "ID", by.y = "ID") 


#Collapse each participant's RT single trials to participant level
RT_collapsed<- data %>% 
            group_by(ID, Hemifield) %>%
            summarise(RT=mean(RT)) %>% #next bring Target-Hemifield up into wide format:
            spread(Hemifield, RT) %>% #next rename
            rename(RT_Left=Left, RT_Right=Right) %>% # next Calculate RT asymmetry:
            mutate(RT_Asym=(RT_Left-RT_Right)/(RT_Left+RT_Right)) 
#Merge it in with the ERP measures
participant_level<-merge(participant_level, RT_collapsed, by.x = "ID", by.y = "ID") 


#Transform it to long format
participant_level_long<-participant_level %>%
                    gather(measure_type, data, -ID, -Location) %>%
                    na.omit()
####Find outliers in the Participant level data (abs z-score >3)####
#################################################################
#Calculate Z scores inside measure_type type TO REMOVE OUTLIERS
#Z-score each participant's data inside measure_type ####
#calculate mean and sd 
m <- tapply(participant_level_long$data,participant_level_long$measure_type,mean, na.rm = T)
s <- tapply(participant_level_long$data,participant_level_long$measure_type,sd, na.rm = T)
 
#calculate data.Z and save it inside participant_level_long
participant_level_long$data.Z <- (participant_level_long$data-m[participant_level_long$measure_type])/s[participant_level_long$measure_type]
#Remove trials where absolute data.Z>3 (i.e. remove outlier RTs)
# participant_level_long<-participant_level_long[!abs(participant_level_long$data.Z)>3,]

# Shift extream outliers back to +/- 3 standard deviations from the mean
participant_level_long$data[participant_level_long$data.Z>3]<-m[participant_level_long$measure_type][participant_level_long$data.Z>3] + 3*s[participant_level_long$measure_type][participant_level_long$data.Z>3]
participant_level_long$data[participant_level_long$data.Z<(-3)]<-m[participant_level_long$measure_type][participant_level_long$data.Z<(-3)] - 3*s[participant_level_long$measure_type][participant_level_long$data.Z<(-3)]


#calculate data.Z again and save it inside participant_level_long
participant_level_long$data.Z <- (participant_level_long$data-m[participant_level_long$measure_type])/s[participant_level_long$measure_type]


#Plot density plots again after outlier removal
ggplot(participant_level_long, aes(data))  + geom_density() + facet_wrap(~ measure_type, scales="free")

#change measure_type to factor class
participant_level_long$measure_type<-as.factor(participant_level_long$measure_type)

#Put it back into wide format so I can use lapply to do t-test on columns 
drops <- c("data.Z")
participant_level_long<-participant_level_long[ , !(names(participant_level_long) %in% drops)]

participant_level<-participant_level_long %>%  
                    spread(measure_type, data) 

#Merge in the Demographics
participant_level<-merge(participant_level, Demographics, by.x = "ID", by.y = "ID") 
####################################################################################

#Change class of Location and Sex to Factor variavles 
participant_level$Location<-as.factor(participant_level$Location)
participant_level$Sex<-as.factor(participant_level$Sex)

```


# Stim Locked ERP trace plots
```{r, Stim Locked ERP trace plots, echo=FALSE, warning=FALSE}

###### Import trial sample level data Resp locked Beta
if (location=="Monash") {
data_Stim_locked_ERP <- read.csv("C:/GitHub/big_dots/master_matrix_R_Stim_locked_ERP.csv", header=FALSE)
ID <- read.table("C:/GitHub/big_dots/ID_vector_Stim_locked_ERP.csv", quote="\"")
} else if (location=="DansLaptop") {
data_Stim_locked_ERP <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/master_matrix_R_Stim_locked_ERP.csv", header=FALSE)
ID <- read.table("C:/Users/Dan/Documents/GitHub/big_dots/ID_vector_Stim_locked_ERP.csv", quote="\"")
} else setwd(("~"))


data_Stim_locked_ERP$ID<-data_Stim_locked_ERP[,1]
#Replace the participant numbers with IDs:
data_Stim_locked_ERP[,1]<-ID[,1]
#Remove the seperate ID vector now it has been included into data dataframe
rm(ID)
drops <- c("ID")
data_Stim_locked_ERP<-data_Stim_locked_ERP[,!(names(data_Stim_locked_ERP) %in% drops)]

#Merge with the RT, Accuracy, Hemifield data 
data_Stim_locked_ERP<- data_Stim_locked_ERP %>% #Rename data columns:
    rename(., 
           ID=V1,
           TotalTrialNumber=V2,
           Trial=V3,
           Time=V4,
           CPP=V5,
           N2c=V6,
           N2i=V7)

#Grab the columns from data that I need to merge in
toMerge<-data %>% select(ID, Trial, Art_neg100_100PR, FixBreak_neg100_100PR, Hemifield, RT) 
#Now merge them 
data_Stim_locked_ERP<-data_Stim_locked_ERP %>%   merge(., toMerge, by = c("ID", "Trial")) 
#Filter out artifacts
data_Stim_locked_ERP<- data_Stim_locked_ERP %>% 
    filter(!Art_neg100_100PR, !FixBreak_neg100_100PR) %>%
    select(-Art_neg100_100PR, -FixBreak_neg100_100PR)
###########################################################################################################

#Plot Stimonse locked 
detach("package:dplyr", unload=TRUE) #Detach dplyr as functions below use plyr
source("summarySE.R") 
source("summarySEwithin.R") #function to calculate Std.Er of mean
source("normDataWithin.R")
plotdata_Stim_locked_CPP <- summarySEwithin(data_Stim_locked_ERP, measurevar="CPP", withinvars=c("Time", "Hemifield"), idvar="ID")
plotdata_Stim_locked_CPP$Time<-as.numeric(as.character(plotdata_Stim_locked_CPP$Time))
plotdata_Stim_locked_N2c <- summarySEwithin(data_Stim_locked_ERP, measurevar="N2c", withinvars=c("Time", "Hemifield"), idvar="ID")
plotdata_Stim_locked_N2c$Time<-as.numeric(as.character(plotdata_Stim_locked_N2c$Time))
plotdata_Stim_locked_N2i <- summarySEwithin(data_Stim_locked_ERP, measurevar="N2i", withinvars=c("Time", "Hemifield"), idvar="ID")
plotdata_Stim_locked_N2i$Time<-as.numeric(as.character(plotdata_Stim_locked_N2i$Time))
summary(plotdata_Stim_locked_CPP$Time)
lapply(required_packages, require, character.only = TRUE) # re-load all librarys no that I'm finished with dlyr


##First import the scalp plots from matlab to inclued on a ggplot
library(png)
library(grid)
#Read in .png and transform it to a raster grob
CPP_scalp <- rasterGrob(readPNG("CPP_scalp.png",native = T, info = T), interpolate=TRUE)
N2c_LeftTarget_scalp <- rasterGrob(readPNG("N2c_LeftTarget_scalp.png"), interpolate=TRUE)
N2c_RightTarget_scalp <- rasterGrob(readPNG("N2c_RightTarget_scalp.png"), interpolate=TRUE)
Alpha_scalp<- rasterGrob(readPNG("Alpha_scalp.png",native = T, info = T), interpolate=TRUE)
Beta_scalp<- rasterGrob(readPNG("Beta_scalp.png",native = T, info = T), interpolate=TRUE)
N2_scalp<- rasterGrob(readPNG("N2_scalp.png",native = T, info = T), interpolate=TRUE)
N2_scalp2<- rasterGrob(readPNG("N2_scalp2.png",native = T, info = T), interpolate=TRUE)
Paradigm<- rasterGrob(readPNG("Paradigm_v2.png",native = T, info = T), interpolate=TRUE)

participant_level_long<-participant_level %>% 
                    select(ID, RT_Left, RT_Right, CPPonset_LeftTarget, CPPonset_RightTarget) %>%
                    gather(measure_type, data, -ID)
participant_level_long$Hemifield[participant_level_long$measure_type=="CPPonset_RightTarget"|
                                     participant_level_long$measure_type=="RT_Right"] <- "Right"
participant_level_long$Hemifield[participant_level_long$measure_type=="CPPonset_LeftTarget"|
                                     participant_level_long$measure_type=="RT_Left"] <- "Left"
participant_level_long$Measure[participant_level_long$measure_type=="CPPonset_RightTarget"|
                                     participant_level_long$measure_type=="CPPonset_LeftTarget"] <- "CPP Onset"
participant_level_long$Measure[participant_level_long$measure_type=="RT_Right"|
                                     participant_level_long$measure_type=="RT_Left"] <- "RT"


p_violin<-ggplot(participant_level_long, aes(measure_type, data, colour = Hemifield))  +
    scale_y_continuous(limits = c(-100, 900)) +
    geom_violin(aes(linetype = Measure), size=1) + 
    # geom_boxplot(aes(linetype = Measure), alpha=0.1, notch=T, notchwidth=0.75, width = 0.3) + 
    xlab("Target Hemifield") + ylab("Time (ms)") +
    theme(  axis.title.x = element_blank(), #element_text(face="bold", size=12),
            axis.text.x  =  element_blank(), #element_text(face="bold", angle=0,  size=12),
            axis.ticks.x=element_blank(),
            axis.title.y = element_text(face="bold", size=12, colour = "white"),
            axis.text.y=element_text(angle=90, vjust=0.5, size=10, colour = "white"),
            axis.ticks.y=element_blank(),
            legend.title = element_text(size=12, face="bold"),
            legend.text = element_text(size = 12, face = "bold"),
            panel.background = element_blank(), #remove grey background 
            legend.position=c(0.9,0.22),  #Move ledgend position
            axis.line = element_line(colour = "black")) +
        guides(colour=FALSE) +
    geom_hline(yintercept=0, alpha = 0.5) +
    geom_hline(yintercept=as.numeric(participant_level %>% select(RT_Left) %>% summarise(mean(RT_Left))), #add dashed verticle for RT
               colour  = scales::hue_pal()(1), size=0.75,  linetype="dashed", alpha=0.75) +
    geom_hline(yintercept=as.numeric(participant_level %>% select(RT_Right) %>% summarise(mean(RT_Right))), 
               colour  = scales::hue_pal()(2)[2], size=0.75,  linetype="dashed", alpha=0.75) +
    geom_hline(yintercept=as.numeric(participant_level %>% select(CPPonset_LeftTarget) %>% summarise(mean(CPPonset_LeftTarget))), 
               colour  = scales::hue_pal()(1), size=0.75, alpha=0.75) +
    geom_hline(yintercept=as.numeric(participant_level %>% select(CPPonset_RightTarget) %>% summarise(mean(CPPonset_RightTarget))), 
                colour  = scales::hue_pal()(2)[2], size=0.75, alpha=0.75) +
    stat_summary(fun.data="mean_se",  fun.args = list(mult=1), 
               geom="pointrange", color = "purple", size=0.5) +
     coord_flip() +
    annotate("text", x = 4.25, y = -75, label = "[A]", size=6)



p_CPP<-ggplot(plotdata_Stim_locked_CPP, aes(x=Time, y=CPP, color=Hemifield,fill=Hemifield)) + 
    geom_line(size=1) + 
    geom_ribbon(aes(ymin=CPP-ci, ymax=CPP+ci), alpha = 0.5, colour=NA) + 
    coord_cartesian(ylim = c(-0.1, 6),  xlim = c(-100, 900)) +
    xlab("Time (ms)") + ylab("CPP Amplitude (uV)") +
    theme(axis.title.x = element_text(face="bold", size=12),
          axis.text.x  = element_text(face="bold", angle=0,  size=12), #element_text(face="bold", angle=0,  size=12),
          axis.title.y = element_text(face="bold", size=12),
          axis.text.y  = element_text(angle=0, vjust=0.5, size=12),
          legend.title = element_text(size=12, face="bold"),
          legend.text = element_text(size = 12, face = "bold"),
          panel.background = element_blank(), #remove grey background 
          legend.position= c(0.88,0.88)) + #Move ledgend position
    guides(color=FALSE) +
    annotation_custom(CPP_scalp,xmin = 30, xmax = 270, ymin = 4, ymax = 6.25) + #add the CPP scapl plot 
    geom_vline(xintercept=as.numeric(participant_level %>% select(RT_Left) %>% summarise(mean(RT_Left))), #add dashed verticle for RT
               colour  = scales::hue_pal()(1), size=0.75,  linetype="dashed", alpha=0.75) +
    geom_vline(xintercept=as.numeric(participant_level %>% select(RT_Right) %>% summarise(mean(RT_Right))), 
                colour  = scales::hue_pal()(2)[2], size=0.75,  linetype="dashed", alpha=0.75) +
    geom_vline(xintercept=as.numeric(participant_level %>% select(CPPonset_LeftTarget) %>% summarise(mean(CPPonset_LeftTarget))), 
               colour  = scales::hue_pal()(1), size=0.75, alpha=0.75) +
    geom_vline(xintercept=as.numeric(participant_level %>% select(CPPonset_RightTarget) %>% summarise(mean(CPPonset_RightTarget))), 
                colour  = scales::hue_pal()(2)[2], size=0.75, alpha=0.75) +
    geom_hline(yintercept=0, alpha = 0.5) + 
    geom_vline(xintercept=0, alpha = 0.5) + #add black likes at 0 on x and y axis 
    scale_x_continuous(breaks = seq(-100, 900, 50)) + #increase the resolution of the axis ticks
    scale_y_continuous(breaks = seq(0,6,1)) +
    annotate("text", x = -75, y = 6, label = "[B]", size=6)
p_CPP


#N2c plot
ggplot(plotdata_Stim_locked_N2c, aes(x=Time, y=N2c, color=Hemifield,fill=Hemifield)) + 
    geom_line(size=1.4) + geom_ribbon(aes(ymin=N2c-ci, ymax=N2c+ci), alpha = 0.3, colour=NA) + 
        geom_hline(yintercept=0, alpha = 0.5) + geom_vline(xintercept=0, alpha = 0.5) +   
    coord_cartesian(ylim = c(-3, 0.5),  xlim = c(-100, 500)) +
    xlab("Time") + ylab("N2c Amplitude (uV)") +
    theme(axis.title.x = element_text(face="bold", size=12),
          axis.text.x  = element_text(face="bold", angle=0,  size=12)) +
    theme(axis.title.y = element_text(face="bold", size=12),
          axis.text.y  = element_text(angle=0, vjust=0.5, size=12)) +
    theme(legend.title = element_text(size=11, face="bold")) +
    theme(legend.text = element_text(size = 11, face = "bold")) +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
          panel.background = element_blank(), axis.line = element_line(colour = "black")) 


#N2i plot
ggplot(plotdata_Stim_locked_N2i, aes(x=Time, y=N2i, color=Hemifield,fill=Hemifield)) + 
    geom_line(size=1.4) + geom_ribbon(aes(ymin=N2i-ci, ymax=N2i+ci), alpha = 0.3, colour=NA) + 
        geom_hline(yintercept=0, alpha = 0.5) + geom_vline(xintercept=0, alpha = 0.5) +   
    coord_cartesian(ylim = c(-3, 0.5),  xlim = c(-100, 500)) +
    xlab("Time") + ylab("N2i Amplitude (uV)") +
    theme(axis.title.x = element_text(face="bold", size=12),
          axis.text.x  = element_text(face="bold", angle=0,  size=12)) +
    theme(axis.title.y = element_text(face="bold", size=12),
          axis.text.y  = element_text(angle=0, vjust=0.5, size=12)) +
    theme(legend.title = element_text(size=11, face="bold")) +
    theme(legend.text = element_text(size = 11, face = "bold")) +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
          panel.background = element_blank(), axis.line = element_line(colour = "black"))

###################Plot N2c and N2i trace in the same plot #####################
plotdata_Stim_locked_N2i$Hemisphere<-rep("Ipsilateral",length(plotdata_Stim_locked_N2i[,1]))
names(plotdata_Stim_locked_N2i)[names(plotdata_Stim_locked_N2i)=="N2i"] <- "N2"
names(plotdata_Stim_locked_N2i)[names(plotdata_Stim_locked_N2i)=="N2i_norm"] <- "N2_norm"

plotdata_Stim_locked_N2c$Hemisphere<-rep("Contralateral",length(plotdata_Stim_locked_N2c[,1]))
names(plotdata_Stim_locked_N2c)[names(plotdata_Stim_locked_N2c)=="N2c"] <- "N2"
names(plotdata_Stim_locked_N2c)[names(plotdata_Stim_locked_N2c)=="N2c_norm"] <- "N2_norm"
plotdata_N2<-rbind(plotdata_Stim_locked_N2i,plotdata_Stim_locked_N2c)

p_N2<-ggplot(plotdata_N2, aes(x=Time, y=N2, color=Hemifield,fill=Hemifield, linetype=Hemisphere)) + 
    annotation_custom(N2_scalp2,xmin = 0, xmax = 230, ymin = -1.2, ymax = -2.72) + #add the scapl plot 
    geom_line(size=1) + 
    geom_ribbon(aes(ymin=N2-ci, ymax=N2+ci), alpha = 0.3, colour=NA) + 
        geom_hline(yintercept=0, alpha = 0.5) + geom_vline(xintercept=0, alpha = 0.5) +   
    coord_cartesian(ylim = c(-2.7, 0.45), xlim = c(-100, 500)) +
    xlab("Time (ms)") + ylab("N2 Amplitude (uV)") +
       theme(axis.title.x = element_text(face="bold", size=12),
          axis.text.x  = element_text(face="bold", angle=0,  size=12), #element_text(face="bold", angle=0,  size=12),
          axis.title.y = element_text(face="bold", size=12),
          axis.text.y  = element_text(angle=0, vjust=0.5, size=12),
          legend.title = element_text(size=12, face="bold"),
          legend.text = element_text(size = 12, face = "bold"),
          panel.background = element_blank(), #remove grey background 
          legend.position= c(0.85,0.19)) + #Move ledgend position
    guides(color=FALSE, fill=FALSE) +
    theme(panel.margin = unit(1.5, "lines")) +
    scale_x_continuous(breaks = seq(-100, 500, 100)) + #increase the resolution of the axis ticks
    scale_y_continuous(breaks = seq(-2.7,1, 0.5)) +
    annotate("text", x = -75, y = 0.45, label = "[E]", size=6)
    
p_N2

```


# Stim Locked Beta
```{r, Stim Locked Beta, echo=FALSE, warning=FALSE}
###########################################################################################################
###### Import trial sample level data Stim locked Beta
if (location=="Monash") {
data_Stim_locked_Beta <- read.csv("C:/GitHub/big_dots/master_matrix_R_Stim_locked_beta.csv", header=FALSE)
ID <- read.table("C:/GitHub/big_dots/ID_vector_Stim_locked_beta.csv", quote="\"")
} else if (location=="DansLaptop") {
data_Stim_locked_Beta <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/master_matrix_R_Stim_locked_beta.csv", header=FALSE)
ID <- read.table("C:/Users/Dan/Documents/GitHub/big_dots/ID_vector_Stim_locked_beta.csv", quote="\"")
} else setwd(("~"))

data_Stim_locked_Beta$ID<-data_Stim_locked_Beta[,1]
#Replace the participant numbers with IDs:
data_Stim_locked_Beta[,1]<-ID[,1]
#Remove the seperate ID vector now it has been included into data dataframe
rm(ID)
drops <- c("ID")
data_Stim_locked_Beta<-data_Stim_locked_Beta[,!(names(data_Stim_locked_Beta) %in% drops)]

#Merge with the RT, Accuracy, Hemifield data 
data_Stim_locked_Beta<- data_Stim_locked_Beta %>% #Rename data columns:
    rename(., 
           ID=V1,
           TotalTrialNumber=V2,
           Trial=V3,
           Time=V4,
           Stim_locked_Beta=V5) %>%
    merge(., data, by = c("ID", "Trial", "TotalTrialNumber")) 
#Filter out artifacts
data_Stim_locked_Beta<- data_Stim_locked_Beta %>% filter(!Art_neg100_100PR, !FixBreak_neg100_100PR)
###########################################################################################################

#Plot Stimonse locked 
detach("package:dplyr", unload=TRUE) #Detach dplyr as functions below use plyr
source("summarySE.R") 
source("summarySEwithin.R") #function to calculate Std.Er of mean
source("normDataWithin.R")
plotdata_Stim_locked_Beta <- summarySEwithin(data_Stim_locked_Beta, measurevar="Stim_locked_Beta", withinvars=c("Time", "Hemifield"), idvar="ID")
plotdata_Stim_locked_Beta$Time<-as.numeric(as.character(plotdata_Stim_locked_Beta$Time))
summary(plotdata_Stim_locked_Beta$Time)
lapply(required_packages, require, character.only = TRUE) # re-load all librarys no that I'm finished with dlyr

#Stim_locked_Beta Group on same plot
p_Beta<-ggplot(plotdata_Stim_locked_Beta, aes(x=Time, y=Stim_locked_Beta, color=Hemifield,fill=Hemifield)) + 
    annotation_custom(Beta_scalp,xmin = 200, xmax = 800, ymin = -0.04, ymax = -0.001) + #add the scapl plot 
    geom_line(size=1) + 
    geom_ribbon(aes(ymin=Stim_locked_Beta-ci, ymax=Stim_locked_Beta+ci), alpha = 0.3, colour=NA) + 
        geom_hline(yintercept=0, alpha = 0.5) + geom_vline(xintercept=0, alpha = 0.5) +   
    coord_cartesian(ylim = c(-0.1, 0.01),  xlim = c(-100, 800)) +
    xlab("Time") + ylab("Beta Power (uV)") +
    theme(axis.title.x = element_text(face="bold", size=12),
              axis.text.x  = element_text(face="bold", angle=0,  size=12), #element_text(face="bold", angle=0,  size=12),
              axis.title.y = element_text(face="bold", size=12),
              axis.text.y  = element_text(face="bold", angle=0, size=12),
              panel.background = element_blank(),
              legend.position= c(0.35,0.19),
              legend.title = element_text(size=12, face="bold"),
              legend.text = element_text(size = 12, face = "bold")) +
    annotate("text", x = -75, y = 0.01, label = "[D]", size=6)
p_Beta

##Calculate t_values for each of the rolling variables ability to predict log(RT) at each time point
plot_data<-data_Stim_locked_Beta %>% 
            group_by(Hemifield, Time) %>%  
            do(Beta_Amplitude = summary(lmer(log(RT) ~ Stim_locked_Beta + (1|ID) + (1|ITI), data = ., REML=F))$coefficients[2,3]) %>%
            gather(., key, t_value, -Hemifield, -Time) %>%
            mutate(t_value= as.double(t_value)) %>% 
            arrange(key)

plot_data <- plot_data %>% arrange(key)


ggplot(plot_data, aes(Time, t_value, colour=Hemifield)) + geom_line(size=1.4) + 
    geom_hline(yintercept=2, alpha = 0.5,  size=1.4) + geom_hline(yintercept=-2, alpha = 0.5,  size=1.4) + geom_vline(xintercept=0, alpha = 0.5,  size=1.4) +
     coord_cartesian(ylim = c(-5, 8), xlim = c(-100, 800)) +
    theme(axis.title.x = element_text(face="bold", size=14),
          axis.text.x  = element_text(face="bold", angle=0,  size=14)) +
    theme(axis.title.y = element_text(face="bold", size=14),
          axis.text.y  = element_text(angle=0, vjust=0.5, size=14)) +
    theme(plot.title = element_text(face="bold", size=16)) +
    theme(strip.text.x = element_text(size = 13)) 


##Pull out mean beta amplitude measures from 300 - 500ms in stim locked beta
beta_participant_level<- data_Stim_locked_Beta %>% 
                            filter(Time>300, Time<500) %>% 
                            group_by(ID, Hemifield) %>% 
                            summarise(Stim_locked_Beta=mean(Stim_locked_Beta)) %>%
                            spread(Hemifield, Stim_locked_Beta) %>% 
                            select(Beta_LeftTarget = Left,
                                   Beta_RightTarget = Right) %>%
                            mutate(Beta_Asym = (Beta_LeftTarget-Beta_RightTarget)/(Beta_LeftTarget+Beta_RightTarget)) %>%
                            ungroup()

#Merge with participant_level data.frame (note don't worry that it coerces ID from factor to character vector)
participant_level<-left_join(participant_level, beta_participant_level, by = "ID")


#Remove it to free up some memory
rm(data_Stim_locked_Beta)




```

# Resp Locked Beta Slope
```{r, Resp Locked Beta, echo=FALSE, warning=FALSE}
###########################################################################################################
###### Import trial sample level data Resp locked Beta
if (location=="Monash") {
data_Resp_locked_Beta <- read.csv("C:/GitHub/big_dots/master_matrix_R_Resp_locked_beta.csv", header=FALSE)
ID <- read.table("C:/GitHub/big_dots/ID_vector_Resp_locked_beta.csv", quote="\"")
} else if (location=="DansLaptop") {
data_Stim_locked_Beta <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/master_matrix_R_Resp_locked_beta.csv", header=FALSE)
ID <- read.table("C:/Users/Dan/Documents/GitHub/big_dots/ID_vector_Resp_locked_beta.csv", quote="\"")
} else setwd(("~"))

data_Resp_locked_Beta$ID<-data_Resp_locked_Beta[,1]
#Replace the participant numbers with IDs:
data_Resp_locked_Beta[,1]<-ID[,1]
#Remove the seperate ID vector now it has been included into data dataframe
rm(ID)
drops <- c("ID")
data_Resp_locked_Beta<-data_Resp_locked_Beta[,!(names(data_Resp_locked_Beta) %in% drops)]

#Merge with the RT, Accuracy, Hemifield data 
data_Resp_locked_Beta<- data_Resp_locked_Beta %>% #Rename data columns:
    rename(., 
           ID=V1,
           TotalTrialNumber=V2,
           Trial=V3,
           Time=V4,
           Resp_locked_Beta=V5,
           Resp_locked_Beta_NOTbaselined=V6) %>%
    merge(., data, by = c("ID", "Trial", "TotalTrialNumber")) 

#Filter out artifacts
data_Resp_locked_Beta<- data_Resp_locked_Beta %>% filter(!Art_neg100_100PR)
###########################################################################################################

#Plot response locked 
detach("package:dplyr", unload=TRUE) #Detach dplyr as functions below use plyr
source("summarySE.R") 
source("summarySEwithin.R") #function to calculate Std.Er of mean
source("normDataWithin.R")
plotdata_Resp_locked_Beta <- summarySEwithin(data_Resp_locked_Beta, measurevar="Resp_locked_Beta", withinvars=c("Time", "Hemifield"), idvar="ID")
plotdata_Resp_locked_Beta_NOTbaselined <- summarySEwithin(data_Resp_locked_Beta, measurevar="Resp_locked_Beta_NOTbaselined", withinvars=c("Time", "Hemifield"), idvar="ID")
plotdata_Resp_locked_Beta$Time<-as.numeric(as.character(plotdata_Resp_locked_Beta$Time))
plotdata_Resp_locked_Beta_NOTbaselined$Time<-as.numeric(as.character(plotdata_Resp_locked_Beta_NOTbaselined$Time))
summary(plotdata_Resp_locked_Beta$Time)
lapply(required_packages, require, character.only = TRUE) # re-load all librarys now that I'm finished with plyr

#Resp_locked_Beta Group on same plot
ggplot(plotdata_Resp_locked_Beta, aes(x=Time, y=Resp_locked_Beta, color=Hemifield,fill=Hemifield)) + 
    geom_line(size=1.4) + geom_ribbon(aes(ymin=Resp_locked_Beta-ci, ymax=Resp_locked_Beta+ci), alpha = 0.3, colour=NA) + 
        geom_hline(yintercept=0, alpha = 0.5) + geom_vline(xintercept=0, alpha = 0.5) +   
    coord_cartesian(ylim = c(-0.104, 0.01),  xlim = c(-600, 100)) +
    xlab("Time") + ylab("Beta Power (uV)") +
    theme(axis.title.x = element_text(face="bold", size=12),
          axis.text.x  = element_text(face="bold", angle=0,  size=12)) +
    theme(axis.title.y = element_text(face="bold", size=12),
          axis.text.y  = element_text(angle=0, vjust=0.5, size=12)) +
    theme(legend.title = element_text(size=11, face="bold")) +
    theme(legend.text = element_text(size = 11, face = "bold")) +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
          panel.background = element_blank(), axis.line = element_line(colour = "black"))




##Pull out mean beta amplitude measures from -300 to -50ms in Resp locked beta
beta_participant_level<- data_Resp_locked_Beta %>% 
                            filter(Time>-300, Time<(-50)) %>% 
                            group_by(ID, Hemifield) %>% 
                            summarise( xyBar =mean(Time*Resp_locked_Beta),
                                       xBar = mean(Time),
                                       yBar = mean(Resp_locked_Beta),
                                       x2Bar =mean(Time^2),
                                       Resp_locked_Beta_Slope = (xyBar - xBar*yBar) / (x2Bar - xBar^2)) %>%
                            select(ID, Hemifield, Resp_locked_Beta_Slope) %>%
                            spread(Hemifield, Resp_locked_Beta_Slope) %>% 
                            select(Beta_slope_LeftTarget = Left,
                                   Beta_slope_RightTarget = Right) %>%
                            mutate(Beta_slope_Asym = (Beta_slope_LeftTarget-Beta_slope_RightTarget)/(Beta_slope_LeftTarget+Beta_slope_RightTarget)) 

#Merge with participant_level data.frame (note don't worry that it coerces ID from factor to character vector)
participant_level<-left_join(participant_level, beta_participant_level, by = "ID")

#Remove it to free up some memory
rm(data_Resp_locked_Beta)
```


#Run tests of normality on the RT, CPPonset, N2c, etc. measures 
```{r, test of normality, echo=FALSE, warning=FALSE}
options(scipen=99)
Normality_tests <-participant_level %>% 
                    select(contains("Left"), contains("Right"))  %>% 
                    gather() %>% 
                    group_by(key) %>%
                    do(ShapiroWilk_p_value= shapiro.test(.$value)[2],
                       Anderson_Darling_p_value = nortest::ad.test(.$value)[2], 
                       CramerVonMises_p_value = nortest::cvm.test(.$value)[2],
                       Shapiro_Francia_p_value = nortest::sf.test(.$value)[2],
                       Kolmogorov_Smirnov_p_value= nortest::lillie.test(.$value)[2]) %>% 
                    mutate(ShapiroWilk_p_value= unlist(ShapiroWilk_p_value),
                       Anderson_Darling_p_value = unlist(Anderson_Darling_p_value), 
                       CramerVonMises_p_value = unlist(CramerVonMises_p_value),
                       Shapiro_Francia_p_value = unlist(Shapiro_Francia_p_value),
                       Kolmogorov_Smirnov_p_value = unlist(Kolmogorov_Smirnov_p_value)) %>% 
                    mutate(average_p_value=(ShapiroWilk_p_value + 
                                                Anderson_Darling_p_value + 
                                                CramerVonMises_p_value + 
                                                Shapiro_Francia_p_value + 
                                                Kolmogorov_Smirnov_p_value)/5) %>% arrange(average_p_value)
kable(Normality_tests,
    format.args = list(big.mark = ","), digits=4,
      caption="Normality tests")
```


#Test the effect of Target Hemifield on RT, CPPonset, N2c, etc. using repeated measures ANOVA

##In cases where the assumption of normality was violated, a factorial permutation test for the effect of Target Hemifield was performed with 1000 permutations and the permuted p-value also reported
```{r, effect of Target Hemifield, echo=FALSE, warning=FALSE}
###################################################################
ANOVA_data<- participant_level %>%
    select(ID, RT_Left, RT_Right) %>%
    na.omit() %>%
    gather(Hemifield, dv, -ID)

   Hemifield_ANOVA <- ezANOVA(data = ANOVA_data
                        , dv = .(dv)
                        , wid = .(ID)
                        , within = .(Hemifield)
                        , within_covariates = NULL
                        , between = NULL
                        , between_covariates = NULL
                        , observed = NULL
                        , type = 3)
print("Repeated Measures ANOVA  for the effect of Hemifield on RT:")
print(Hemifield_ANOVA);

kable(ANOVA_data %>% group_by(Hemifield) %>% summarise(mean=mean(dv),sd=sd(dv)))

#Permuted test

Perm_data<- participant_level %>%
    select(ID, RT_Left, RT_Right) %>%
    na.omit() %>%
    gather(Hemifield, dv, -ID)%>%
    mutate(Hemifield=factor(Hemifield)) %>%
    mutate(ID=factor(ID)) 


log <- capture.output({
   Hemifield_Perm <- ezPerm(data = Perm_data
                          , dv = .(dv)
                          , wid = .(ID)
                          , within = .(Hemifield)
                          , perms = 1000);
 })
print("Factorial Permutation test for the effect of Hemifield on RT:")
print(Hemifield_Perm);


ggplot(ANOVA_data, aes(Hemifield, dv, colour = Hemifield))  +
          geom_violin() + 
    geom_boxplot(alpha=0.1) +  
    theme_bw () + 
    geom_point() +
    xlab("Target Hemifield") + ylab("Reaction Time (ms)") + 
    theme(axis.title.x = element_text(face="bold", size=12),
          axis.text.x  = element_text(face="bold", angle=0,  size=12)) +
    theme(axis.title.y = element_text(face="bold", size=12),
          axis.text.y  = element_text(angle=0, vjust=0.5, size=12)) +
    theme(legend.title = element_text(size=11, face="bold")) +
    theme(legend.text = element_text(size = 11, face = "bold")) +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
          panel.background = element_blank(), axis.line = element_line(colour = "black")) +
     coord_flip()

####################################################################
ANOVA_data<- participant_level %>%
    select(ID, Beta_LeftTarget, Beta_RightTarget) %>%
    na.omit() %>%
    gather(Hemifield, dv, -ID)


   Hemifield_ANOVA <- ezANOVA(data = ANOVA_data
                          , dv = .(dv)
                          , wid = .(ID)
                          , within = .(Hemifield)
                        , within_covariates = NULL
                        , between = NULL
                        , between_covariates = NULL
                        , observed = NULL
                        , type = 3);
print("Repeated Measures ANOVA  for the effect of Hemifield on Stim Locked Beta Amplitude:")
print(Hemifield_ANOVA);

kable(ANOVA_data %>% group_by(Hemifield) %>% summarise(mean=mean(dv),sd=sd(dv)))

Perm_data<- participant_level %>%
    select(ID, Beta_LeftTarget, Beta_RightTarget) %>%
    na.omit() %>%
    gather(Hemifield, dv, -ID)

log <- capture.output({
   Hemifield_Perm <- ezPerm(data = Perm_data
                          , dv = .(dv)
                          , wid = .(ID)
                          , within = .(Hemifield)
                          , perms = 1000);
 })
print("Factorial Permutation test for the effect of Hemifield on Stim Locked Beta Amplitude:")
print(Hemifield_Perm);


###################################################################


ANOVA_data<- participant_level %>%
    select(ID, Beta_slope_LeftTarget, Beta_slope_RightTarget) %>%
    na.omit() %>%
    gather(Hemifield, dv, -ID)



   Hemifield_ANOVA <- ezANOVA(data = ANOVA_data
                          , dv = .(dv)
                          , wid = .(ID)
                          , within = .(Hemifield)
                        , within_covariates = NULL
                        , between = NULL
                        , between_covariates = NULL
                        , observed = NULL
                        , type = 3);
print("Repeated Measures ANOVA  for the effect of Hemifield on Resp Locked Beta Slope:")
print(Hemifield_ANOVA);

kable(ANOVA_data %>% group_by(Hemifield) %>% summarise(mean=mean(dv),sd=sd(dv)))

Perm_data<- participant_level %>%
    select(ID, Beta_slope_LeftTarget, Beta_slope_RightTarget) %>%
    na.omit() %>%
    gather(Hemifield, dv, -ID)

log <- capture.output({
   Hemifield_Perm <- ezPerm(data = Perm_data
                          , dv = .(dv)
                          , wid = .(ID)
                          , within = .(Hemifield)
                          , perms = 1000);
 })
print("Factorial Permutation test for the effect of Hemifield on Resp Locked Beta Slope:")
print(Hemifield_Perm);



###################################################################
ANOVA_data<- participant_level %>%
    select(ID, CPPonset_LeftTarget, CPPonset_RightTarget) %>%
    na.omit() %>%
    gather(Hemifield, dv, -ID)



   Hemifield_ANOVA <- ezANOVA(data = ANOVA_data
                          , dv = .(dv)
                          , wid = .(ID)
                          , within = .(Hemifield)
                        , within_covariates = NULL
                        , between = NULL
                        , between_covariates = NULL
                        , observed = NULL
                        , type = 3);
print("Repeated Measures ANOVA  for the effect of Hemifield on CPP Onset:")
print(Hemifield_ANOVA);

kable(ANOVA_data %>% group_by(Hemifield) %>% summarise(mean=mean(dv),sd=sd(dv)))

ggplot(ANOVA_data, aes(Hemifield, dv, colour = Hemifield))  +
          geom_violin() + 
    geom_boxplot(alpha=0.1) +  
    theme_bw () + 
    geom_point() +
    xlab("Target Hemifield") + ylab("CPP Onset (ms)") +
    theme(axis.title.x = element_text(face="bold", size=12),
          axis.text.x  = element_text(face="bold", angle=0,  size=12)) +
    theme(axis.title.y = element_text(face="bold", size=12),
          axis.text.y  = element_text(angle=0, vjust=0.5, size=12)) +
    theme(legend.title = element_text(size=11, face="bold")) +
    theme(legend.text = element_text(size = 11, face = "bold")) +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
          panel.background = element_blank(), axis.line = element_line(colour = "black"))



###################################################################
ANOVA_data<- participant_level %>%
    select(ID, CPPslope_LeftTarget, CPPslope_RightTarget) %>%
    na.omit() %>%
    gather(Hemifield, dv, -ID)



   Hemifield_ANOVA <- ezANOVA(data = ANOVA_data
                          , dv = .(dv)
                          , wid = .(ID)
                          , within = .(Hemifield)
                        , within_covariates = NULL
                        , between = NULL
                        , between_covariates = NULL
                        , observed = NULL
                        , type = 3);
print("Repeated Measures ANOVA  for the effect of Hemifield on CPP Slope:")
print(Hemifield_ANOVA);

kable(ANOVA_data %>% group_by(Hemifield) %>% summarise(mean=mean(dv),sd=sd(dv)))

###################################################################
ANOVA_data<- participant_level %>%
    select(ID, N2i_latency_LeftTarget, N2i_latency_RightTarget) %>%
    na.omit() %>%
    gather(Hemifield, dv, -ID)


   Hemifield_ANOVA <- ezANOVA(data = ANOVA_data
                          , dv = .(dv)
                          , wid = .(ID)
                          , within = .(Hemifield)
                        , within_covariates = NULL
                        , between = NULL
                        , between_covariates = NULL
                        , observed = NULL
                        , type = 3);
print("Repeated Measures ANOVA  for the effect of Hemifield on N2i_latency:")
print(Hemifield_ANOVA);

kable(ANOVA_data %>% group_by(Hemifield) %>% summarise(mean=mean(dv),sd=sd(dv)))

#Permutation test:
Perm_data<- participant_level %>%
    select(ID, N2i_latency_LeftTarget, N2i_latency_RightTarget) %>%
    na.omit() %>%
    gather(Hemifield, dv, -ID)

log <- capture.output({
   Hemifield_Perm <- ezPerm(data = Perm_data
                          , dv = .(dv)
                          , wid = .(ID)
                          , within = .(Hemifield)
                          , perms = 1000);
 })
print("Factorial Permutation test for the effect of Hemifield on N2i_latency:")
print(Hemifield_Perm);

###################################################################
ANOVA_data<- participant_level %>%
    select(ID, N2i_LeftTarget, N2i_RightTarget) %>%
    na.omit() %>%
    gather(Hemifield, dv, -ID)


   Hemifield_ANOVA <- ezANOVA(data = ANOVA_data
                          , dv = .(dv)
                          , wid = .(ID)
                          , within = .(Hemifield)
                        , within_covariates = NULL
                        , between = NULL
                        , between_covariates = NULL
                        , observed = NULL
                        , type = 3);
print("Repeated Measures ANOVA  for the effect of Hemifield on N2i Amplitude:")
print(Hemifield_ANOVA);

kable(ANOVA_data %>% group_by(Hemifield) %>% summarise(mean=mean(dv),sd=sd(dv)))

###################################################################
ANOVA_data<- participant_level %>%
    select(ID, N2c_latency_LeftTarget, N2c_latency_RightTarget) %>%
    na.omit() %>%
    gather(Hemifield, dv, -ID)


   Hemifield_ANOVA <- ezANOVA(data = ANOVA_data
                          , dv = .(dv)
                          , wid = .(ID)
                          , within = .(Hemifield)
                        , within_covariates = NULL
                        , between = NULL
                        , between_covariates = NULL
                        , observed = NULL
                        , type = 3);
print("Repeated Measures ANOVA  for the effect of Hemifield on N2c_latency:")
print(Hemifield_ANOVA);

kable(ANOVA_data %>% group_by(Hemifield) %>% summarise(mean=mean(dv),sd=sd(dv)))

#Permutation test:
Perm_data<- participant_level %>%
    select(ID, N2c_latency_LeftTarget, N2c_latency_RightTarget) %>%
    na.omit() %>%
    gather(Hemifield, dv, -ID)

log <- capture.output({
   Hemifield_Perm <- ezPerm(data = Perm_data
                          , dv = .(dv)
                          , wid = .(ID)
                          , within = .(Hemifield)
                          , perms = 1000);
 })
print("Factorial Permutation test for the effect of Hemifield on N2c_latency:")
print(Hemifield_Perm);

###################################################################
ANOVA_data<- participant_level %>%
    select(ID, N2c_LeftTarget, N2c_RightTarget) %>%
    na.omit() %>%
    gather(Hemifield, dv, -ID)


   Hemifield_ANOVA <- ezANOVA(data = ANOVA_data
                          , dv = .(dv)
                          , wid = .(ID)
                          , within = .(Hemifield)
                        , within_covariates = NULL
                        , between = NULL
                        , between_covariates = NULL
                        , observed = NULL
                        , type = 3);
print("Repeated Measures ANOVA  for the effect of Hemifield on N2c Amplitude:")
print(Hemifield_ANOVA);

kable(ANOVA_data %>% group_by(Hemifield) %>% summarise(mean=mean(dv),sd=sd(dv)))

###################################################################
#combine N2c and N2i into the one analysis and test for the TargetHemifield*Hemisphere interaction:
ANOVA_data<- participant_level %>%
    select(ID, N2c_LeftTarget, N2c_RightTarget, N2i_LeftTarget, N2i_RightTarget) %>%
    na.omit() %>%
    gather(condition, dv, -ID) %>%
    mutate(Hemifield = replace(condition, condition=="N2c_LeftTarget" | condition=="N2i_LeftTarget", "Left")) %>%
    mutate(Hemifield = replace(Hemifield, condition=="N2c_RightTarget" | condition=="N2i_RightTarget", "Right")) %>%
    mutate(Hemisphere = replace(condition, condition=="N2i_LeftTarget" | condition=="N2i_RightTarget", "Ipsilateral")) %>%
    mutate(Hemisphere = replace(Hemisphere, condition=="N2c_LeftTarget" | condition=="N2c_RightTarget", "Contralateral")) %>%
    as.data.frame()


Hemifield_Hemisphere_ANOVA <- ezANOVA(data = ANOVA_data
                              , dv = .(dv)
                              , wid = .(ID)
                              , within = .(Hemifield, Hemisphere)
                                , within_covariates = NULL
                                , between = NULL
                                , between_covariates = NULL
                                , observed = NULL
                                , type = 3);
print("Repeated Measures ANOVA for the effects of Hemifield*Hemisphere on N2 Amplitude:")
print(Hemifield_Hemisphere_ANOVA);



###################################################################


ANOVA_data<- participant_level %>%
    select(ID, PreAlpha_LeftHemi, PreAlpha_RightHemi) %>%
    na.omit() %>%
    gather(Hemisphere, dv, -ID)


   Hemisphere_ANOVA <- ezANOVA(data = ANOVA_data
                          , dv = .(dv)
                          , wid = .(ID)
                          , within = .(Hemisphere)
                        , within_covariates = NULL
                        , between = NULL
                        , between_covariates = NULL
                        , observed = NULL
                        , type = 3);
print("Repeated Measures ANOVA  for the effect of Hemisphere on Pre-target Alpha Power:")
print(Hemisphere_ANOVA);


kable(ANOVA_data %>% group_by(Hemisphere) %>% summarise(mean=mean(dv),sd=sd(dv)))

Perm_data<- participant_level %>%
    select(ID, PreAlpha_LeftHemi, PreAlpha_RightHemi) %>%
    na.omit() %>%
    gather(Hemisphere, dv, -ID)

log <- capture.output({
   Hemisphere_Perm <- ezPerm(data = Perm_data
                          , dv = .(dv)
                          , wid = .(ID)
                          , within = .(Hemisphere)
                          , perms = 1000);
 })
print("Factorial Permutation test for the effect of Hemisphere on Pre-target Alpha Power:")
print(Hemisphere_Perm);


p_Alpha<-ggplot(ANOVA_data, aes(Hemisphere, dv, colour = Hemisphere))  +
    annotation_custom(Alpha_scalp,xmin = 1, xmax = 2, ymin = 3.5, ymax = 5) + #add the scapl plot 
    geom_violin() + 
    geom_boxplot(alpha=0.1) +  
    geom_point() +
    xlab("Hemisphere") + ylab("Alpha Power (uV)") +
    theme(axis.title.x = element_text(face="bold", size=12),
          axis.text.x  = element_text(face="bold", angle=0,  size=12), 
          axis.title.y = element_text(face="bold", size=12),
          axis.text.y  = element_text(face="bold", angle=0, size=12),
          panel.background = element_blank()) +
    guides(colour=FALSE) +
    scale_x_discrete(labels=c("Left", "Right")) +
    annotate("text", x = 0.6, y = 5, label = "[F]", size=6)
p_Alpha

######################################################################



```

```{r, Make the multi panel figure }

Paradigm2<-ggplot(data_frame(y=c(1,460,920), x=c(1,490,985)), aes(x, y))  +
            annotation_custom(Paradigm, xmin = 0, xmax = 980, ymin = -19, ymax = 890) +
             theme(axis.title.x = element_blank(),
                  axis.text.x  = element_blank(), 
                  axis.title.y = element_blank(),
                  axis.text.y  = element_blank(),
                  axis.ticks.x = element_blank(),
                  axis.ticks.y = element_blank(),
                  panel.background = element_blank()) +
            annotate("text", x = 155, y = 930, label = "[C]", size=6)
Paradigm2

# png("Figure 2.png", width = 10*600, height = 15*600,  units = "px", res = 600)
# source("multiplot.R")
# multiplot(p_violin,p_CPP,p_scatter_CPP,p_Beta,p_N2,p_Alpha,layout= matrix(c(1,2,2,3,3,5,5,1,2,2,4,4,6,6), nrow = 7, ncol = 2))        
# dev.off()
# multiplot(p_violin,p_CPP,p_scatter_CPP,p_Beta,p_N2,p_Alpha,layout= matrix(c(1,2,2,3,3,5,5,1,2,2,4,4,6,6), nrow = 7, ncol = 2))  


png("Figure 1.png", width = 10*600, height = 15*600,  units = "px", res = 600)
source("multiplot.R")
multiplot(p_violin,p_CPP,Paradigm2,p_Beta,p_N2,p_Alpha,layout= matrix(c(1,2,2,3,3,5,5,1,2,2,4,4,6,6), nrow = 7, ncol = 2))        
dev.off()
multiplot(p_violin,p_CPP,Paradigm2,p_Beta,p_N2,p_Alpha,layout= matrix(c(1,2,2,3,3,5,5,1,2,2,4,4,6,6), nrow = 7, ncol = 2)) 



p_scatter_CPP<-ggplot(participant_level, aes(x=RT_Asym, y=CPPonset_Asym)) +
        geom_point(shape=1, size=2) +    
        geom_smooth(method=lm, se=FALSE, colour="black") + # Add linear regression line # Don't add shaded confidence region
        xlab("RT Asymmetry") + ylab("CPP-onset Asymmetry") +
        theme(axis.title.x = element_text(face="bold", size=14),
              axis.text.x  = element_text(face="bold", angle=0,  size=14), #element_text(face="bold", angle=0,  size=14),
              axis.title.y = element_text(face="bold", size=14),
              axis.text.y  = element_text(face="bold", angle=0, size=14),
              panel.background = element_blank()) +
        geom_hline(yintercept=0, alpha = 0.4) + 
        geom_vline(xintercept=0, alpha = 0.4) + #add black likes at 0 on x and y axis 
        annotate("text", x = -0.1, y = 0.40, label = "[A]", size=6)
p_scatter_CPP                   



p_scatter_Alpha<-ggplot(participant_level, aes(x=RT_Asym, y=PreAlphaAsym)) +
        geom_point(shape=1, size=2) +    
        geom_smooth(method=lm, se=FALSE, colour="black") + # Add linear regression line # Don't add shaded confidence region
        xlab("RT Asymmetry") + ylab("Pre-target Alpha Asymmetry") +
        theme(axis.title.x = element_text(face="bold", size=14),
              axis.text.x  = element_text(face="bold", angle=0,  size=14), #element_text(face="bold", angle=0,  size=14),
              axis.title.y = element_text(face="bold", size=14),
              axis.text.y  = element_text(face="bold", angle=0, size=14),
              panel.background = element_blank()) +
        geom_hline(yintercept=0, alpha = 0.4) + 
        geom_vline(xintercept=0, alpha = 0.4) + #add black likes at 0 on x and y axis 
        annotate("text", x = -0.1, y = 0.35, label = "[C]", size=6)
p_scatter_Alpha  


p_scatter_N2<-ggplot(participant_level, aes(x=RT_Asym, y=N2c_latency_Asym)) +
        geom_point(shape=1, size=2) +    
        geom_smooth(method=lm, se=FALSE, colour="black") + # Add linear regression line # Don't add shaded confidence region
        xlab("RT Asymmetry") + ylab("N2c-latency Asymmetry") +
        theme(axis.title.x = element_text(face="bold", size=14),
              axis.text.x  = element_text(face="bold", angle=0,  size=14), #element_text(face="bold", angle=0,  size=14),
              axis.title.y = element_text(face="bold", size=14),
              axis.text.y  = element_text(face="bold", angle=0, size=14),
              panel.background = element_blank()) +
        geom_hline(yintercept=0, alpha = 0.4) + 
        geom_vline(xintercept=0, alpha = 0.4) + #add black likes at 0 on x and y axis 
        annotate("text", x = -0.1, y = 0.3, label = "[B]", size=6)
p_scatter_N2    


png("Figure 2.png", width = 12*600, height = 4.3*600,  units = "px", res = 600)
source("multiplot.R")
multiplot(p_scatter_CPP, p_scatter_N2, p_scatter_Alpha,layout= matrix(c(1,2,3),nrow = 1, ncol = 3))        
dev.off()
multiplot(p_scatter_CPP, p_scatter_N2, p_scatter_Alpha,layout= matrix(c(1,2,3),nrow = 1, ncol = 3))   




```

#test normality of all the Asymmetry measures (i.e. RT, N2, CPP, alpha, asymmetry) 
```{r, correlation between Asymmetry measures, echo=FALSE, warning=FALSE}
Normality_tests <-participant_level %>% 
                    select(contains("Asym"))  %>% 
                    gather() %>% 
                    group_by(key) %>%
                    do(ShapiroWilk_p_value= shapiro.test(.$value)[2],
                       Anderson_Darling_p_value = nortest::ad.test(.$value)[2], 
                       CramerVonMises_p_value = nortest::cvm.test(.$value)[2],
                       Shapiro_Francia_p_value = nortest::sf.test(.$value)[2],
                       Kolmogorov_Smirnov_p_value= nortest::lillie.test(.$value)[2]) %>% 
                    mutate(ShapiroWilk_p_value= unlist(ShapiroWilk_p_value),
                       Anderson_Darling_p_value = unlist(Anderson_Darling_p_value), 
                       CramerVonMises_p_value = unlist(CramerVonMises_p_value),
                       Shapiro_Francia_p_value = unlist(Shapiro_Francia_p_value),
                       Kolmogorov_Smirnov_p_value = unlist(Kolmogorov_Smirnov_p_value)) %>% 
                    mutate(average_p_value=(ShapiroWilk_p_value + 
                                                Anderson_Darling_p_value + 
                                                CramerVonMises_p_value + 
                                                Shapiro_Francia_p_value + 
                                                Kolmogorov_Smirnov_p_value)/5) %>% arrange(average_p_value)

```

#Look at multiple regression to predice RT_Asym 
```{r, echo=FALSE, warning=FALSE}
library(broom)

### Fitting the Model
intercept_only<-lm(RT_Asym~ 1, data=participant_level)
Controls <- update(intercept_only, .~. + Location + Sex + Age)
PreAlphaAsym<-update(Controls, .~. + PreAlphaAsym)
N2c_Asym<-update(PreAlphaAsym, .~. + N2c_Asym)
N2c_latency_Asym<-update(N2c_Asym, .~. + N2c_latency_Asym)
CPPonset_Asym<-update(N2c_latency_Asym, .~. + CPPonset_Asym)
CPPslope_Asym<-update(CPPonset_Asym, .~. + CPPslope_Asym)
Beta_Asym<-update(CPPslope_Asym, .~. + Beta_Asym)
Beta_slope_Asym<-update(Beta_Asym, .~. + Beta_slope_Asym)

anova(intercept_only, Controls, PreAlphaAsym, N2c_Asym, N2c_latency_Asym, CPPonset_Asym, CPPslope_Asym, Beta_Asym, Beta_slope_Asym)


summary(Controls)
summary(PreAlphaAsym)
summary(N2c_Asym)
summary(N2c_latency_Asym)
summary(CPPonset_Asym)
summary(CPPslope_Asym)
summary(Beta_Asym)
summary(Beta_slope_Asym)


#For the final model, only keep predictors that significantly improve model fit
final_model<-lm(RT_Asym ~  PreAlphaAsym + N2c_latency_Asym + CPPonset_Asym, data=participant_level)

kable(tidy(final_model),digits=3)


#---We can obtain standardized parameter estimates with the lm.beta() "QuantPsyc" pachage function---
#Standardized Beta values can be compared to each other and therefore allow us to gague the relative 
#importance of each predictor.  
library(car)
library(QuantPsyc)
lm.beta(final_model)


confint(final_model, level=0.95) # CIs for model parameters 
# fitted(final_model) # predicted values
# residuals(final_model) # residuals
# vcov(final_model) # covariance matrix for model parameters 
# influence(final_model) # regression diagnostics

# diagnostic plots 
layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page 
plot(final_model)


#----Obtain casewise diagnostics and add them to the original data file.---

participant_level$residuals<-residuals(final_model)
participant_level$standardized.residuals <- rstandard(final_model)
participant_level$cooks.distance<-cooks.distance(final_model)
participant_level$dfbeta <- dfbeta(final_model)
participant_level$dffit <- dffits(final_model)
participant_level$leverage <- hatvalues(final_model)
participant_level$covariance.ratios <- covratio(final_model)
participant_level$fitted <-fitted(final_model)


#----List of standardized residuals greater than 2--------------
participant_level$large.residual<-participant_level$standardized.residuals>2| participant_level$standardized.residuals < -2
# only about 5% of the sample should have standardized residuals greater than 2
cat("Percentage of sample with standardized residuals greater than abs 2:")
cat((sum(participant_level$large.residual)/length(participant_level$RT_Asym))*100,"%")


#-----Cook's distance, leverage and covariance ratio for cases with large residuals.---------
participant_level[participant_level$large.residual , c("ID", "standardized.residuals", "cooks.distance", "leverage", "covariance.ratios")]
#no cooks difference values greater than 1, so none of these are having too much influence on the model 



#----The Durbin-Watson test is obtained with either dwt() or durbinWatsonTest()---
#This is a test for independence 
durbinWatsonTest(final_model) # D-W Statistic is close to 2 and nowhere near significant so we are all good

#----Obtaining the VIF to assess collinearity/multicillinearity---
vif(final_model)
#tolerance:
1/vif(final_model)
# If the largest VIF is greater than 10 then there is a multicillinearity problem
# If the average VIF is substantially greater than 1 there could be a multicillinearity problem
# Tolerances below 0.1 indicate a serious multicillinearity problem
# Tolerances below 0.2 indicate a potential multicillinearity problem

#Plot standardized residual histogram
residuals_final_model=residuals(final_model)

plot(residuals_final_model)
qqnorm(residuals_final_model)
qqline(residuals_final_model)
hist(residuals_final_model)





# Stepwise Regression
library(MASS)
fit <- lm(RT_Asym~ Location + Sex + Age + PreAlphaAsym + N2c_Asym + N2c_latency_Asym + CPPonset_Asym + CPPslope_Asym + Beta_Asym + Beta_slope_Asym, data=participant_level)
step <- stepAIC(fit, direction="both")
step$anova # display results
tidy(step)



# # All Subsets Regression
# library(leaps)
# leaps<-regsubsets(RT_Asym~ Location + Sex + Age + PreAlphaAsym + N2c_Asym + N2c_latency_Asym + CPPonset_Asym + CPPslope_Asym + Beta_Asym + Beta_slope_Asym, data=participant_level,nbest=9)
# # plot a table of models showing variables in each model.
# # models are ordered by the selection statistic.
# layout(1)
# plot(leaps,scale="r2")
# plot(leaps, scale="adjr2")
# plot(leaps, scale="bic")


############################################################################################
##------Bootstrapping------
library(boot)
library(simpleboot)
#---Write a bootstrap function.
bootReg<-function(formula, data, i)
{
	d <- data[i,]
	fit <- lm(formula, data = d)
	return(coef(fit))
	}

#----bootstrapping our regression model, with 5000 replications---
bootResults<-boot(statistic = bootReg, formula = RT_Asym ~  PreAlphaAsym + N2c_latency_Asym + CPPonset_Asym, data = participant_level, R = 5000)

#---We can then obtaine the bootstrap confidence intervals for the intercept:---
boot.ci(bootResults, type = "bca", index = 1)

#---And the slope estimates---
boot.ci(bootResults, type = "bca", index = 2) #PreAlphaAsym 
boot.ci(bootResults, type = "bca", index = 3) #N2c_latency_Asym
boot.ci(bootResults, type = "bca", index = 4) #CPPonset_Asym


lm.boot(final_model, 3000, rows = TRUE, new.xpts = NULL, ngrid = 100,
weights = NULL)


#Mediation? 
Model.1 = lm(RT_Asym~N2c_latency_Asym, data=participant_level) # Y ~ X
summary(Model.1)
Model.2 = lm(RT_Asym~CPPonset_Asym+N2c_latency_Asym, data=participant_level)# Y ~ M + X
summary(Model.2)
Model.3 = lm(CPPonset_Asym~N2c_latency_Asym, data=participant_level) # M ~ X
summary(Model.3)

```













