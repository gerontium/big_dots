x = x[s]
return(cov(x, y)/var(x))
}
z <- data.frame()
## x has to be ungrouped
x <- ungroup(x)
library(dplyr)
n.dates <- 60
n.stocks <- 2
date <- seq(as.Date("2011-07-01"), by=1, len=n.dates)
symbol <- replicate(n.stocks, paste0(sample(LETTERS, 5), collapse = ""))
x <- expand.grid(date, symbol)
x$return <- rnorm(n.dates*n.stocks, 0, sd = 0.05)
names(x) <- c("date", "company", "return")
With this dataframe, I can calculate the daily market average return and add that result into a new column "market.ret".
x <- group_by(x, date)
x <- mutate(x, market.ret = mean(x$return, na.rm = TRUE))
Now I want to group all my data by different companies (2 in this case).
x <- group_by(x, company)
#################################
lms <- function(y, x){
s = which(is.finite(x * y))
y = y[s]
x = x[s]
return(cov(x, y)/var(x))
}
## z is a dataframe which stores our final result
z <- data.frame()
## x has to be ungrouped
x <- ungroup(x)
symbols <- unique(x$company)
View(x)
symbols <- unique(x$company)
for(i in 1:length(symbols)){
temp <- filter(x, company == symbols[i])
z <- rbind(z, mutate(temp, beta = rollapply(temp[, c(3, 4)],
FUN = function(x) lms(x[, 1], x[, 2]),
width = 20, fill = NA,
by.column = FALSE, align = "right")))
}
print(z)
View(z)
library(data.table)
run.rolling.regressions <- function(x) {
DT <- data.table(   Y = rnorm(10000),
X = rnorm(10000),
key.group = rep(LETTERS[1:10], each = 1000))
window.length <- 12
names.of.groups <- unique(DT$key.group)
number.of.groups <- length(names.of.groups)
X.coefficients <- list()
for(j in 1:length(names.of.groups)) {
regressed.DT <- DT[key.group == names.of.groups[j]]
nrows.of.group <- nrow(regressed.DT)
print(paste0(j, ', key.group: ', names.of.groups[j]))
for (i in window.length:nrows.of.group) {
if(i == window.length) {
X.coefficients[[names.of.groups[j]]] <- c(rep(NA, nrows.of.group)) }
X.coefficients[[names.of.groups[j]]][i] <-  lm(Y ~ 1 + X,
data = regressed.DT[(i - 11):i])$coefficients['X']
}
}
return(X.coefficients)
}
system.time(X.coef <- run.rolling.regressions())
unlist(X.coef)
library(RcppRoll)
rolling2 <- function(DT, window.length) {
setNames(lapply(unique(DT$key.group), function(g) {
regressed.DT <- DT[key.group == g]
xyBar = roll_mean(regressed.DT$X*regressed.DT$Y, window.length)
xBar = roll_mean(regressed.DT$X, window.length)
yBar = roll_mean(regressed.DT$Y, window.length)
x2Bar = roll_mean(regressed.DT$X^2, window.length)
c(rep(NA, window.length-1), (xyBar - xBar*yBar) / (x2Bar - xBar^2))
}), unique(DT$key.group))
}
install.packages("RcppRoll")
library(RcppRoll)
rolling2 <- function(DT, window.length) {
setNames(lapply(unique(DT$key.group), function(g) {
regressed.DT <- DT[key.group == g]
xyBar = roll_mean(regressed.DT$X*regressed.DT$Y, window.length)
xBar = roll_mean(regressed.DT$X, window.length)
yBar = roll_mean(regressed.DT$Y, window.length)
x2Bar = roll_mean(regressed.DT$X^2, window.length)
c(rep(NA, window.length-1), (xyBar - xBar*yBar) / (x2Bar - xBar^2))
}), unique(DT$key.group))
}
set.seed(144)
DT <- data.table(   Y = rnorm(10000),
X = rnorm(10000),
key.group = rep(LETTERS[1:10], each = 1000))
View(DT)
? run.rolling.regressions
system.time(X.coef <- run.rolling.regressions(DT, 12))
system.time(X.coef2 <- rolling2(DT, 12))
X.coef2
library(RcppRoll)
rolling2 <- function(DT, window.length) {
setNames(lapply(unique(DT$key.group), function(g) {
regressed.DT <- DT[key.group == g]
xyBar = roll_mean(regressed.DT$X*regressed.DT$Y, window.length)
xBar = roll_mean(regressed.DT$X, window.length)
yBar = roll_mean(regressed.DT$Y, window.length)
x2Bar = roll_mean(regressed.DT$X^2, window.length)
c(rep(NA, window.length-1), (xyBar - xBar*yBar) / (x2Bar - xBar^2))
}), unique(DT$key.group))
}
summary(DT$key.group)
View(DT)
(3068.7-2888.23)/2888.23
((3068.7-2888.23)/2888.23)*100
3068.7-2888.23
3068.7-2888.23
? rep
library(ggplot2)
? facet_wrap
ggplot(mpg, aes(displ, hwy)) +
geom_point() +
facet_wrap(~ cyl + drv)
ggplot(mpg, aes(displ, hwy)) +
geom_point() +
facet_wrap(~ cyl)
ggplot(mpg, aes(displ, hwy)) +
geom_point() +
facet_wrap(~ cyl + drv)
ggplot(mpg, aes(displ, hwy)) +
geom_point() +
facet_wrap(~ cyl)
ggplot(mpg, aes(displ, hwy)) +
geom_point() +
facet_wrap(~ cyl + drv)
ggplot(mpg, aes(displ, hwy)) +
geom_point() +
facet_wrap(~ drv+ cyl)
4*64
(4*64)/60
50*10
50*8
50*8
47.16*8
47.16*8
install.packages("readxl")
? opts_chunk
class(C(aasd,dfgts,asa))
list.of.packages <- c("ggplot2", "Rcpp")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
list.of.packages <- c("ggplot2", "Rcpp", "genetics")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
new.packages
if(length(new.packages)) install.packages(new.packages)
list.of.packages
lapply(x, list.of.packages, character.only = TRUE)
list.of.packages <- c("ggplot2", "dplyr", "tidyr", "stringr", "lubridate", "readxl")
lapply(list.of.packages, require, character.only = TRUE)
####Which computer/directory is this being run on?
location<-"Monash"
# location<-"GersLaptop"
if (location=="Monash") {
setwd(("C:/GitHub/big_dots/Analyses Scripts_R"))
} else if (location=="GersLaptop") {
setwd(("C:/Users/loughnge/Documents/GitHub/big_dots/Analyses Scripts_R"))
} else setwd(("~"))
### Install/load required packages
#List of R packages required for this analysis:
required_packages <- c("psych", "ggplot2", "dplyr", "tidyr", "stringr", "lubridate", "readxl","knitr",
"readr", "rmarkdown", "png", "lme4", "ez", "multcomp")
#Install required_packages:
new.packages <- required_packages[!(required_packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
#Load required_packages:
lapply(required_packages, require, character.only = TRUE)
###### Import single trial data:
if (location=="Monash") {
data <- read.csv("C:/GitHub/big_dots/master_matrix_R_BigDots.csv", header=FALSE)
} else if (location=="GersLaptop") {
data <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/master_matrix_R_BigDots.csv", header=FALSE)
} else setwd(("~"))
#Import IDs:
if (location=="Monash") {
ID <- read.table("C:/GitHub/big_dots/ID_vector_BigDots.csv", quote="\"")
} else if (location=="GersLaptop") {
ID <- read.table("C:/Users/Dan/Documents/GitHub/big_dots/ID_vector_BigDots.csv", quote="\"")
} else setwd(("~"))
data$ID<-data[,1]
#Replace the participant numbers with IDs:
data[,1]<-ID[,1]
#Remove the seperate ID vector now it has been included into data dataframe
rm(ID)
drops <- c("ID")
data<-data[,!(names(data) %in% drops)]
###Read in Participant Demographics (note for Sex 1=male)
Demographics<-read_excel("Participant_Demographics.xlsx") %>% #then calculate Age at testing date:
mutate(Age_as_period=as.period(interval(Date_Of_Birth, Date_Of_Testing), units="years")) %>%
mutate(Sex = ifelse(Sex==1, "Male", "Female"))
#Calculate Age in numeric format
Demographics$Age<-as.numeric(difftime(as.Date(Demographics$Date_Of_Testing), as.Date(Demographics$Date_Of_Birth), units = "days")/365)
summary(Demographics$Age)
#########################################################################################################################
data<- data %>% #Rename data columns:
rename(.,
ID=V1,
TotalTrialNumber=V2,
Trial=V3,
ITI=V4,
Hemifield=V5,
Accuracy=V6,
Art_neg500_0=V7,
Art_neg100_100PR=V8,
Art_neg500_100PR=V9,
Art_neg100_1000=V10,
FixBreak_neg500_0=V11,
FixBreak_neg100_100PR=V12,
FixBreak_neg500_100PR=V13,
FixBreak_neg100_1000=V14,
RT=V15,
PreAlphaPower=V16,
PreAlphaPowerLH=V17,
PreAlphaPowerRH=V18,
PreAlphaAsym=V19,
PostAlphaPowerLH=V20,
PostAlphaPowerRH=V21,
Location=V22) %>% #next make the required columns into factors:
mutate_each_(funs(factor), c("ITI", "Hemifield", "Accuracy")) %>% #next re-class required vectors into Logicals:
mutate_at(vars(starts_with("Art_")), funs(as.logical)) %>%
mutate_at(vars(starts_with("FixBreak_")), funs(as.logical)) %>% #next use the ! negation operator to reverse of a TRUE/FALSE vectors:
mutate_if(purrr::is_logical, funs(!.)) %>% #next Rename factor Levels:
mutate(Hemifield = ifelse(Hemifield==1, "Left", "Right"),
Accuracy= ifelse(Accuracy==1, "Hit", ifelse(Accuracy==2, "WrongButton", "Miss")),
Location = ifelse(Location==1, "TCD", "Monash"))
Demographics <-Demographics[Demographics$ID %in% data$ID, ]
###############Data Cleaning For Single Trial Data######################
#Check number of Trials for each participant by running the function 'length',
#on "data$RT" for each DAT1_3UTR, broken down by ID + Light
num_trials1 <- data %>% group_by(ID) %>% summarise( Trials = length(RT))
summary(num_trials1$Trials)
##################Accuracy ##########################
Accuracy_checker <- data %>% group_by(ID) %>%
summarise(Hits  = sum(Accuracy=="Hit"),
Misses = sum(Accuracy=="Miss" | Accuracy=="WrongButton")) %>%
mutate(Total=Hits+Misses,
Accuracy_overall= (Hits/Total)*100)
summary(Accuracy_checker$Accuracy_overall)
##Add in overall accuracy
data <- merge(data, Accuracy_checker, by.x = "ID", by.y = "ID")
######Test for effect of Hemifield on Accuracy:
# Accuracy_checker <- data %>% group_by(ID, Hemifield) %>%
#                     summarise(Hits  = sum(Accuracy=="Hit"),
#                                Misses = sum(Accuracy=="Miss" | Accuracy=="WrongButton")) %>%
#                     mutate(Total=Hits+Misses,
#                            Accuracy_overall= (Hits/Total)*100)
# log <- capture.output({
#    Hemifield_Perm <- ezPerm(data = data.frame(Accuracy_checker)
#                           , dv = .(Accuracy_overall)
#                           , wid = .(ID)
#                           , within = .(Hemifield)
#                           , perms = 1000);
#  })
# print("Factorial Permutation test for the effect of Hemifield Accuracy:")
# print(Hemifield_Perm);
##########################################################################
###Remove trials where:
#RT longer than 1000ms (i.e. after target finished)
#RT faster than 100ms (i.e. too fast must be false alarm) or RT=0 (i.e. they did not respond)
#Kick out trials with fixation breaks:
data<-filter(data, RT<1500 & RT>150 & !FixBreak_neg100_100PR)
############################################ Log transform:
##############################################################################################
data$log_RT<-log(data$RT) #log
#####Z-score each participant's log_RT data ####
data$IDbyITIbyHemifield<-interaction(data$ID, data$ITI, data$Hemifield)
#calculate mean and sd
m <- tapply(data$log_RT,data$IDbyITIbyHemifield,mean, na.rm = T)
s <- tapply(data$log_RT,data$IDbyITIbyHemifield,sd, na.rm = T)
#calculate log_RT.Z and save it inside data.frame
data$log_RT.Z <- (data$log_RT-m[data$IDbyITIbyHemifield])/s[data$IDbyITIbyHemifield]
#Remove trials where absolute log_RT.Z>3 (i.e. remove outlier RTs)
data<-data[!abs(data$log_RT.Z)>3,]
#plot again after outlier removal:
ggplot(data, aes(RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white")
ggplot(data, aes(log_RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white")
#Calculate the number of trials each participant has left after fixation break trials are kicked out:
num_trials2 <- data %>% group_by(ID) %>% summarise( Trials = length(RT))
summary(num_trials2$Trials)
#Calculate alpha desynchronisation by subtracting Pre-target Alpha from post target alpha
data$AlphaDesyncRH<-(data$PreAlphaPowerRH)-(data$PostAlphaPowerRH)
data$AlphaDesyncLH<-data$PreAlphaPowerLH-data$PostAlphaPowerLH
# Make PostAlpha contralateral (PostAlpha_c) and -Ipsilateral (PostAlpha_i) variables:
A<-data$Hemifield=="Left"
#Absolute post target alpha
data$PostAlpha_c[A]<-data$PostAlphaPowerRH[A]
data$PostAlpha_c[!A]<-data$PostAlphaPowerLH[!A]
data$PostAlpha_i[!A]<-data$PostAlphaPowerRH[!A]
data$PostAlpha_i[A]<-data$PostAlphaPowerLH[A]
#Post target Alpha desynchronisation
data$AlphaDesync_c[A]<-data$AlphaDesyncRH[A]
data$AlphaDesync_c[!A]<-data$AlphaDesyncLH[!A]
data$AlphaDesync_i[!A]<-data$AlphaDesyncRH[!A]
data$AlphaDesync_i[A]<-data$AlphaDesyncLH[A]
rm(A)
####Import participant_level_matrix with ERP measures
if (location=="Monash") {
participant_level <- read.csv("C:/GitHub/big_dots/participant_level_matrix.csv", header=FALSE)
} else if (location=="DansLaptop") {
participant_level <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/participant_level_matrix.csv", header=FALSE)
} else setwd(("~"))
#Import IDs:
if (location=="Monash") {
ID <- read.table("C:/GitHub/big_dots/IDs.csv", quote="\"")
} else if (location=="DansLaptop") {
ID <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/IDs.csv", header=F)
} else setwd(("~"))
ID<-plyr::rename(ID,c("V1"="ID"))
participant_level$ID<-ID$ID
rm(ID)
participant_level<- participant_level %>% #Rename data columns:
rename(.,
N2c_LeftTarget=V1,
N2c_RightTarget=V2,
N2i_LeftTarget=V3,
N2i_RightTarget=V4,
N2c_latency_LeftTarget=V5,
N2c_latency_RightTarget=V6,
N2i_latency_LeftTarget=V7,
N2i_latency_RightTarget=V8,
CPPonset_LeftTarget=V9,
CPPonset_RightTarget=V10,
CPPslope_LeftTarget=V11,
CPPslope_RightTarget=V12,
Location=V13 ) %>% ##next calculate the ERP asymmetry measures:
mutate(.,
N2c_Asym = (N2c_LeftTarget-N2c_RightTarget)/(N2c_LeftTarget+N2c_RightTarget),
N2i_Asym = (N2i_LeftTarget-N2i_RightTarget)/(N2i_LeftTarget+N2i_RightTarget),
N2c_latency_Asym = (N2c_latency_LeftTarget-N2c_latency_RightTarget)/(N2c_latency_LeftTarget+N2c_latency_RightTarget),
N2i_latency_Asym =(N2i_latency_LeftTarget-N2i_latency_RightTarget)/(N2i_latency_LeftTarget+N2i_latency_RightTarget),
CPPonset_Asym = (CPPonset_LeftTarget-CPPonset_RightTarget)/(CPPonset_LeftTarget+CPPonset_RightTarget),
CPPslope_Asym = (CPPslope_LeftTarget-CPPslope_RightTarget)/(CPPslope_LeftTarget+CPPslope_RightTarget),
Location = ifelse(Location==1, "TCD", "Monash")
)
####################################################################################
#Collapse each participant's PreAlpha trials to participant level
PreAlphaAsym_collapsed<- data %>%
filter(!Art_neg500_0, !FixBreak_neg500_0) %>%
group_by(ID) %>%
summarise(PreAlphaAsym=mean(PreAlphaAsym))
#Merge it in with the ERP measures
participant_level<-merge(participant_level, PreAlphaAsym_collapsed, by.x = "ID", by.y = "ID")
#Collapse each participant's PostAlpha trials to participant level
PostAlphaAsym_collapsed<- data %>%
filter(!Art_neg500_0, !FixBreak_neg500_0, PostAlpha_c!=0, PostAlpha_i!=0) %>%
mutate(PostAlphaAsym=(PostAlpha_c-PostAlpha_i)/(PostAlpha_c+PostAlpha_i)) %>% #contra - ipsi asym
group_by(ID) %>%
summarise(PostAlphaAsym=mean(PostAlphaAsym))
#Merge it in with the ERP measures
participant_level<-merge(participant_level, PostAlphaAsym_collapsed, by.x = "ID", by.y = "ID")
#Collapse each participant's Post-target AlphaDesync single trials to participant level
AlphaDesync_c_collapsed<- data %>%
filter(!Art_neg500_100PR, !FixBreak_neg500_100PR, AlphaDesync_c!=0) %>%
group_by(ID, Hemifield) %>%
summarise(AlphaDesync_c=mean(AlphaDesync_c)) %>% #next bring Target-Hemifield up into wide format:
spread(Hemifield, AlphaDesync_c) %>% #next rename
rename(AlphaDesync_c_LeftTarget=Left, AlphaDesync_c_RightTarget=Right) %>% # next Calculate RT asymmetry:
mutate(AlphaDesync_c_Asym=(AlphaDesync_c_LeftTarget-AlphaDesync_c_RightTarget)/(AlphaDesync_c_LeftTarget+AlphaDesync_c_RightTarget))
#Merge it in with the ERP measures
participant_level<-merge(participant_level, AlphaDesync_c_collapsed, by.x = "ID", by.y = "ID")
AlphaDesync_i_collapsed<- data %>%
filter(!Art_neg500_100PR, !FixBreak_neg500_100PR, AlphaDesync_i!=0) %>%
group_by(ID, Hemifield) %>%
summarise(AlphaDesync_i=mean(AlphaDesync_i)) %>% #next bring Target-Hemifield up into wide format:
spread(Hemifield, AlphaDesync_i) %>% #next rename
rename(AlphaDesync_i_LeftTarget=Left, AlphaDesync_i_RightTarget=Right) %>% # next Calculate RT asymmetry:
mutate(AlphaDesync_i_Asym=(AlphaDesync_i_LeftTarget-AlphaDesync_i_RightTarget)/(AlphaDesync_i_LeftTarget+AlphaDesync_i_RightTarget))
#Merge it in with the ERP measures
participant_level<-merge(participant_level, AlphaDesync_i_collapsed, by.x = "ID", by.y = "ID")
#Collapse each participant's RT single trials to participant level
RT_collapsed<- data %>%
group_by(ID, Hemifield) %>%
summarise(RT=mean(RT)) %>% #next bring Target-Hemifield up into wide format:
spread(Hemifield, RT) %>% #next rename
rename(RT_Left=Left, RT_Right=Right) %>% # next Calculate RT asymmetry:
mutate(RT_Asym=(RT_Left-RT_Right)/(RT_Left+RT_Right))
#Merge it in with the ERP measures
participant_level<-merge(participant_level, RT_collapsed, by.x = "ID", by.y = "ID")
#Transform it to long format
participant_level_long<-participant_level %>%
gather(measure_type, data, -ID, -Location) %>%
na.omit()
####Find outliers in the Participant level data (abs z-score >3)####
#################################################################
#Calculate Z scores inside measure_type type TO REMOVE OUTLIERS
#Z-score each participant's data inside measure_type ####
#calculate mean and sd
m <- tapply(participant_level_long$data,participant_level_long$measure_type,mean, na.rm = T)
s <- tapply(participant_level_long$data,participant_level_long$measure_type,sd, na.rm = T)
#calculate data.Z and save it inside participant_level_long
participant_level_long$data.Z <- (participant_level_long$data-m[participant_level_long$measure_type])/s[participant_level_long$measure_type]
#Remove trials where absolute data.Z>3 (i.e. remove outlier RTs)
# participant_level_long<-participant_level_long[!abs(participant_level_long$data.Z)>3,]
# Shift extream outliers back to +/- 3 standard deviations from the mean
participant_level_long$data[participant_level_long$data.Z>3]<-m[participant_level_long$measure_type][participant_level_long$data.Z>3] + 3*s[participant_level_long$measure_type][participant_level_long$data.Z>3]
participant_level_long$data[participant_level_long$data.Z<(-3)]<-m[participant_level_long$measure_type][participant_level_long$data.Z<(-3)] - 3*s[participant_level_long$measure_type][participant_level_long$data.Z<(-3)]
#calculate data.Z again and save it inside participant_level_long
participant_level_long$data.Z <- (participant_level_long$data-m[participant_level_long$measure_type])/s[participant_level_long$measure_type]
#Plot density plots again after outlier removal
ggplot(participant_level_long, aes(data))  + geom_density() + facet_wrap(~ measure_type, scales="free")
#change measure_type to factor class
participant_level_long$measure_type<-as.factor(participant_level_long$measure_type)
#Put it back into long format so I can use lapply to do t-test on columns
participant_level<-participant_level_long %>% select(., -data.Z)  %>%
spread(measure_type, data)
#Merge in the Demographics
participant_level<-merge(participant_level, Demographics, by.x = "ID", by.y = "ID")
####################################################################################
###### Import trial sample level data (500Hz):
if (location=="Monash") {
data_Resp_locked_Beta <- read.csv("C:/GitHub/big_dots/master_matrix_R_Resp_locked_beta.csv", header=FALSE)
ID <- read.table("C:/GitHub/big_dots/ID_vector_Resp_locked_beta.csv", quote="\"")
} else if (location=="DansLaptop") {
data_Stim_locked_Beta <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/master_matrix_R_Resp_locked_beta.csv", header=FALSE)
ID <- read.table("C:/Users/Dan/Documents/GitHub/big_dots/ID_vector_Resp_locked_beta.csv", quote="\"")
} else setwd(("~"))
data_Resp_locked_Beta$ID<-data_Resp_locked_Beta[,1]
#Replace the participant numbers with IDs:
data_Resp_locked_Beta[,1]<-ID[,1]
#Remove the seperate ID vector now it has been included into data dataframe
rm(ID)
drops <- c("ID")
data_Resp_locked_Beta<-data_Resp_locked_Beta[,!(names(data_Resp_locked_Beta) %in% drops)]
#Merge with the RT, Accuracy, Hemifield data
data_Resp_locked_Beta<- data_Resp_locked_Beta %>% #Rename data columns:
rename(.,
ID=V1,
TotalTrialNumber=V2,
Trial=V3,
Time=V4,
Resp_locked_Beta=V5) %>%
merge(., data, by = c("ID", "Trial", "TotalTrialNumber"))
#Filter out artifacts
data_Resp_locked_Beta<- data_Resp_locked_Beta %>% filter(!Art_neg100_100PR)
#Plot response locked
source("summarySE.R")
source("summarySEwithin.R") #function to calculate Std.Er of mean
source("normDataWithin.R")
detach("package:dplyr", unload=TRUE)
plotdata_Resp_locked_Beta <- summarySEwithin(data_Resp_locked_Beta, measurevar="Resp_locked_Beta", withinvars=c("Time", "Hemifield"), idvar="ID")
plotdata_Resp_locked_Beta$Time<-as.numeric(as.character(plotdata_Resp_locked_Beta$Time))
summary(plotdata_Resp_locked_Beta$Time)
detach("package:plyr", unload=TRUE)
library(dplyr)
#Resp_locked_Beta Group on same plot
ggplot(plotdata_Resp_locked_Beta, aes(x=Time, y=Resp_locked_Beta, color=Hemifield,fill=Hemifield)) +
geom_line(size=1.4) + geom_ribbon(aes(ymin=Resp_locked_Beta-ci, ymax=Resp_locked_Beta+ci), alpha = 0.3, colour=NA) +
geom_hline(yintercept=0, alpha = 0.5) + geom_vline(xintercept=0, alpha = 0.5) +
coord_cartesian(ylim = c(0.6, 0.75),  xlim = c(-400, 100)) +
xlab("Time") + ylab("Beta Power (uV)") +
theme(axis.title.x = element_text(face="bold", size=12),
axis.text.x  = element_text(face="bold", angle=0,  size=12)) +
theme(axis.title.y = element_text(face="bold", size=12),
axis.text.y  = element_text(angle=0, vjust=0.5, size=12)) +
theme(legend.title = element_text(size=11, face="bold")) +
theme(legend.text = element_text(size = 11, face = "bold")) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"))
#Plot response locked
source("summarySE.R")
source("summarySEwithin.R") #function to calculate Std.Er of mean
source("normDataWithin.R")
detach("package:dplyr", unload=TRUE)
plotdata_Resp_locked_Beta <- summarySEwithin(data_Resp_locked_Beta, measurevar="Resp_locked_Beta", withinvars=c("Time", "Hemifield"), idvar="ID")
plotdata_Resp_locked_Beta$Time<-as.numeric(as.character(plotdata_Resp_locked_Beta$Time))
summary(plotdata_Resp_locked_Beta$Time)
lapply(required_packages, require, character.only = TRUE)
#Resp_locked_Beta Group on same plot
ggplot(plotdata_Resp_locked_Beta, aes(x=Time, y=Resp_locked_Beta, color=Hemifield,fill=Hemifield)) +
geom_line(size=1.4) + geom_ribbon(aes(ymin=Resp_locked_Beta-ci, ymax=Resp_locked_Beta+ci), alpha = 0.3, colour=NA) +
geom_hline(yintercept=0, alpha = 0.5) + geom_vline(xintercept=0, alpha = 0.5) +
coord_cartesian(ylim = c(0.6, 0.75),  xlim = c(-400, 100)) +
xlab("Time") + ylab("Beta Power (uV)") +
theme(axis.title.x = element_text(face="bold", size=12),
axis.text.x  = element_text(face="bold", angle=0,  size=12)) +
theme(axis.title.y = element_text(face="bold", size=12),
axis.text.y  = element_text(angle=0, vjust=0.5, size=12)) +
theme(legend.title = element_text(size=11, face="bold")) +
theme(legend.text = element_text(size = 11, face = "bold")) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"))
#Plot response locked
source("summarySE.R")
source("summarySEwithin.R") #function to calculate Std.Er of mean
source("normDataWithin.R")
detach("package:dplyr", unload=TRUE)
plotdata_Resp_locked_Beta <- summarySEwithin(data_Resp_locked_Beta, measurevar="Resp_locked_Beta", withinvars=c("Time", "Hemifield"), idvar="ID")
plotdata_Resp_locked_Beta$Time<-as.numeric(as.character(plotdata_Resp_locked_Beta$Time))
summary(plotdata_Resp_locked_Beta$Time)
lapply(required_packages, require, character.only = TRUE)
#Resp_locked_Beta Group on same plot
ggplot(plotdata_Resp_locked_Beta, aes(x=Time, y=Resp_locked_Beta, color=Hemifield,fill=Hemifield)) +
geom_line(size=1.4) + geom_ribbon(aes(ymin=Resp_locked_Beta-ci, ymax=Resp_locked_Beta+ci), alpha = 0.3, colour=NA) +
geom_hline(yintercept=0, alpha = 0.5) + geom_vline(xintercept=0, alpha = 0.5) +
coord_cartesian(ylim = c(0.6, 0.75),  xlim = c(-400, 100)) +
xlab("Time") + ylab("Beta Power (uV)") +
theme(axis.title.x = element_text(face="bold", size=12),
axis.text.x  = element_text(face="bold", angle=0,  size=12)) +
theme(axis.title.y = element_text(face="bold", size=12),
axis.text.y  = element_text(angle=0, vjust=0.5, size=12)) +
theme(legend.title = element_text(size=11, face="bold")) +
theme(legend.text = element_text(size = 11, face = "bold")) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"))
