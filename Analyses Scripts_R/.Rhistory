#calculate log_RT.Z and save it inside data.frame
data$log_RT.Z <- (data$log_RT-m[data$IDbyITIbyHemifield])/s[data$IDbyITIbyHemifield]
#Remove trials where absolute log_RT.Z>3 (i.e. remove outlier RTs)
data<-data[!abs(data$log_RT.Z)>3,]
#plot again after outlier removal:
ggplot(data, aes(RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white")
ggplot(data, aes(log_RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white")
#Calculate the number of trials each participant has left after fixation break trials are kicked out:
num_trials2 <- data %>% group_by(ID) %>% summarise( Trials = length(RT))
summary(num_trials2$Trials)
####Import participant_level_matrix with ERP measures
if (location=="Monash") {
participant_level <- read.csv("C:/GitHub/big_dots/participant_level_matrix.csv", header=FALSE)
} else if (location=="DansLaptop") {
participant_level <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/participant_level_matrix.csv", header=FALSE)
} else setwd(("~"))
#Import IDs:
if (location=="Monash") {
ID <- read.table("C:/GitHub/big_dots/IDs.csv", quote="\"")
} else if (location=="DansLaptop") {
ID <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/IDs.csv", header=F)
} else setwd(("~"))
ID<-plyr::rename(ID,c("V1"="ID"))
participant_level$ID<-ID$ID
rm(ID)
participant_level<- participant_level %>% #Rename data columns:
rename(.,
N2c_LeftTarget=V1,
N2c_RightTarget=V2,
N2i_LeftTarget=V3,
N2i_RightTarget=V4,
N2c_latency_LeftTarget=V5,
N2c_latency_RightTarget=V6,
N2i_latency_LeftTarget=V7,
N2i_latency_RightTarget=V8,
CPPonset_LeftTarget=V9,
CPPonset_RightTarget=V10,
CPPslope_LeftTarget=V11,
CPPslope_RightTarget=V12,
location=V13) %>% #next calculate the ERP asymmetry measures:
mutate(.,
N2c_Asym = (N2c_LeftTarget-N2c_RightTarget)/(N2c_LeftTarget+N2c_RightTarget),
N2i_Asym = (N2i_LeftTarget-N2i_RightTarget)/(N2i_LeftTarget+N2i_RightTarget),
N2c_latency_Asym = (N2c_latency_LeftTarget-N2c_latency_RightTarget)/(N2c_latency_LeftTarget+N2c_latency_RightTarget),
N2i_latency_Asym =(N2i_latency_LeftTarget-N2i_latency_RightTarget)/(N2i_latency_LeftTarget+N2i_latency_RightTarget),
CPPonset_Asym = (CPPonset_LeftTarget-CPPonset_RightTarget)/(CPPonset_LeftTarget+CPPonset_RightTarget),
CPPslope_Asym = (CPPslope_LeftTarget-CPPslope_RightTarget)/(CPPslope_LeftTarget+CPPslope_RightTarget),
location = ifelse(location==1, "TCD", "Monash")
)
####################################################################################
## Find outliers in the Participant level data (abs z-score >3)
#Collapse each participant's RT single trials to participant level
RT_collapsed<- data %>%
group_by(ID, Hemifield) %>%
summarise(RT=mean(RT)) %>% #next bring Target-Hemifield up into wide format:
spread(Hemifield, RT) %>% #next rename
rename(RT_Left=Left, RT_Right=Right) %>% # next Calculate RT asymmetry:
mutate(RT_Asym=(RT_Left-RT_Right)/(RT_Left+RT_Right))
#Merge it in with the ERP measures
participant_level<-merge(RT_collapsed, participant_level, by.x = "ID", by.y = "ID")
#Transform it to long format
participant_level_long<-participant_level %>%
gather(measure_type, data, -ID) %>%
na.omit()
#################################################################
#Calculate Z scores inside measure_type type TO REMOVE OUTLIERS
#Z-score each participant's data inside measure_type ####
#calculate mean and sd
m <- tapply(participant_level_long$data,participant_level_long$measure_type,mean, na.rm = T)
s <- sqrt(tapply(participant_level_long$data,participant_level_long$measure_type,var, na.rm = T))
#calculate data.Z and save it inside participant_level_long
participant_level_long$data.Z <- (participant_level_long$data-m[participant_level_long$measure_type])/s[participant_level_long$measure_type]
#Remove trials where absolute data.Z>3 (i.e. remove outlier RTs)
# participant_level_long<-participant_level_long[!abs(participant_level_long$data.Z)>3,]
#Plot density plots again after outlier removal
ggplot(participant_level_long, aes(data))  + geom_density() + facet_wrap(~ measure_type, scales="free")
#change measure_type to factor class
participant_level_long$measure_type<-as.factor(participant_level_long$measure_type)
#Put it back into long format so I can use lapply to do t-test on columns
participant_level<-participant_level_long %>% select(., -data.Z)  %>%
spread(measure_type, data)
#Merge in the Demographics
participant_level<-merge(participant_level, Demographics, by.x = "ID", by.y = "ID")
####################################################################################
####Which computer/directory is this being run on?
location<-"Monash"
# location<-"GersLaptop"
if (location=="Monash") {
setwd(("C:/GitHub/big_dots/Analyses Scripts_R"))
} else if (location=="GersLaptop") {
setwd(("C:/Users/loughnge/Documents/GitHub/big_dots/Analyses Scripts_R"))
} else setwd(("~"))
####################################
#######  How to use ################
####################################
# 1) Install the packages and software specified below. (consider also updating all installed packages by chosing Update on the Packages tab)
# 2) Set the working directory (setwd) above, and directory where you have "data_ParticipantLevel", "master_matrix_R" and "ID_vector" saved
# 3) Hit Knit Word (or Knit HTML)! (Output can take while due to bootstrapping the robust effect size and calculating the Bayesian Highest Density Iinterval)
####################################
######  FIRST TIME ONLY ############
####################################
#Remove # in front of the line below and run the code. Replace the # after installing the packages, otherwise the R markdown script will give errors.
# install.packages(c("MASS", "akima", "robustbase", "cobs", "robust", "mgcv", "scatterplot3d", "quantreg", "rrcov", "lars", "pwr", "trimcluster", "mc2d", "psych", "Rfit","MBESS", "BayesFactor", "PoweR", "ggplot2", "reshape2", "plyr", "devtools", "rmarkdown","gmodels", "HLMdiag", "car", "gridExtra", "bootES", "BEST","foreign","nlme","pastecs","multcomp","compute.es","ez","lattice","lme4","effects","diagram","png", "grid", "dplyr","readxl", "openxlsx", "haven","schoRsch", "lubridate"))
###################################################################################################################################
## load relevant libraries
library(foreign)
library(car)
library(nlme)
library(ggplot2)
library(pastecs)
library(psych)
library(multcomp)
library(compute.es)
library(ez)
library(lme4)
library(png)
library(grid)
library(readxl)
library(dplyr)
library(tidyr)
library(lubridate)
###### Import single trial data:
if (location=="Monash") {
data <- read.csv("C:/GitHub/big_dots/master_matrix_R_BigDots.csv", header=FALSE)
} else if (location=="GersLaptop") {
data <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/master_matrix_R_BigDots.csv", header=FALSE)
} else setwd(("~"))
#Import IDs:
if (location=="Monash") {
ID <- read.table("C:/GitHub/big_dots/ID_vector_BigDots.csv", quote="\"")
} else if (location=="GersLaptop") {
ID <- read.table("C:/Users/Dan/Documents/GitHub/big_dots/ID_vector_BigDots.csv", quote="\"")
} else setwd(("~"))
data$ID<-data[,1]
#Replace the participant numbers with IDs:
data[,1]<-ID[,1]
#Remove the seperate ID vector now it has been included into data dataframe
rm(ID)
drops <- c("ID")
data<-data[,!(names(data) %in% drops)]
###Read in Participant Demographics (note for Sex 1=male)
Demographics<-read_excel("Participant_Demographics.xlsx") %>% #then calculate Age at testing date:
mutate(Age_as_period=as.period(interval(Date_Of_Birth, Date_Of_Testing), units="years")) %>%
mutate(Sex = ifelse(Sex==1, "Male", "Female"))
#Calculate Age in numeric format
Demographics$Age<-as.numeric(difftime(as.Date(Demographics$Date_Of_Testing), as.Date(Demographics$Date_Of_Birth), units = "days")/365)
summary(Demographics$Age)
#########################################################################################################################
data<- data %>% #Rename data columns:
rename(.,
ID=V1,
TotalTrialNumber=V2,
Trial=V3,
ITI=V4,
Hemifield=V5,
Accuracy=V6,
Art_neg500_0=V7,
Art_neg100_100PR=V8,
Art_neg500_100PR=V9,
Art_neg100_1000=V10,
FixBreak_neg500_0=V11,
FixBreak_neg100_100PR=V12,
FixBreak_neg500_100PR=V13,
FixBreak_neg100_1000=V14,
RT=V15) %>% #next make the required columns into factors:
mutate_each_(funs(factor), c("ITI", "Hemifield", "Accuracy")) %>% #next re-class required vectors into Logicals:
mutate_at(vars(starts_with("Art_")), funs(as.logical)) %>%
mutate_at(vars(starts_with("FixBreak_")), funs(as.logical)) %>% #next use the ! negation operator to reverse of a TRUE/FALSE vectors:
mutate_if(purrr::is_logical, funs(!.)) %>% #next Rename factor Levels:
mutate(Hemifield = ifelse(Hemifield==1, "Left", "Right"),
Accuracy= ifelse(Accuracy==1, "Hit", ifelse(Accuracy==2, "WrongButton", "Miss")))
Demographics <-Demographics[Demographics$ID %in% data$ID, ]
###############Data Cleaning For Single Trial Data######################
#Check number of Trials for each participant by running the function 'length',
#on "data$RT" for each DAT1_3UTR, broken down by ID + Light
num_trials1 <- data %>% group_by(ID) %>% summarise( Trials = length(RT))
summary(num_trials1$Trials)
##################Accuracy ##########################
Accuracy_checker <- data %>% group_by(ID) %>%
summarise(Hits  = sum(Accuracy=="Hit"),
Misses = sum(Accuracy=="Miss" | Accuracy=="WrongButton")) %>%
mutate(Total=Hits+Misses,
Accuracy_overall= (Hits/Total)*100)
summary(Accuracy_checker$Accuracy_overall)
##Add in overall accuracy
data <- merge(data, Accuracy_checker, by.x = "ID", by.y = "ID")
###Remove trials where:
#RT longer than 1000ms (i.e. after target finished)
#RT faster than 100ms (i.e. too fast must be false alarm) or RT=0 (i.e. they did not respond)
#Kick out trials with fixation breaks:
data<-filter(data, RT<1500 & RT>150 & !FixBreak_neg100_100PR)
############################################ Log transform:
##############################################################################################
data$log_RT<-log(data$RT) #log
#####Z-score each participant's log_RT data ####
data$IDbyITIbyHemifield<-interaction(data$ID, data$ITI, data$Hemifield)
#calculate mean and sd
m <- tapply(data$log_RT,data$IDbyITIbyHemifield,mean, na.rm = T)
s <- sqrt(tapply(data$log_RT,data$IDbyITIbyHemifield,var, na.rm = T))
#calculate log_RT.Z and save it inside data.frame
data$log_RT.Z <- (data$log_RT-m[data$IDbyITIbyHemifield])/s[data$IDbyITIbyHemifield]
#Remove trials where absolute log_RT.Z>3 (i.e. remove outlier RTs)
data<-data[!abs(data$log_RT.Z)>3,]
#plot again after outlier removal:
ggplot(data, aes(RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white")
ggplot(data, aes(log_RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white")
#Calculate the number of trials each participant has left after fixation break trials are kicked out:
num_trials2 <- data %>% group_by(ID) %>% summarise( Trials = length(RT))
summary(num_trials2$Trials)
####Import participant_level_matrix with ERP measures
if (location=="Monash") {
participant_level <- read.csv("C:/GitHub/big_dots/participant_level_matrix.csv", header=FALSE)
} else if (location=="DansLaptop") {
participant_level <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/participant_level_matrix.csv", header=FALSE)
} else setwd(("~"))
#Import IDs:
if (location=="Monash") {
ID <- read.table("C:/GitHub/big_dots/IDs.csv", quote="\"")
} else if (location=="DansLaptop") {
ID <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/IDs.csv", header=F)
} else setwd(("~"))
ID<-plyr::rename(ID,c("V1"="ID"))
participant_level$ID<-ID$ID
rm(ID)
participant_level<- participant_level %>% #Rename data columns:
rename(.,
N2c_LeftTarget=V1,
N2c_RightTarget=V2,
N2i_LeftTarget=V3,
N2i_RightTarget=V4,
N2c_latency_LeftTarget=V5,
N2c_latency_RightTarget=V6,
N2i_latency_LeftTarget=V7,
N2i_latency_RightTarget=V8,
CPPonset_LeftTarget=V9,
CPPonset_RightTarget=V10,
CPPslope_LeftTarget=V11,
CPPslope_RightTarget=V12,
location=V13) %>% #next calculate the ERP asymmetry measures:
mutate(.,
N2c_Asym = (N2c_LeftTarget-N2c_RightTarget)/(N2c_LeftTarget+N2c_RightTarget),
N2i_Asym = (N2i_LeftTarget-N2i_RightTarget)/(N2i_LeftTarget+N2i_RightTarget),
N2c_latency_Asym = (N2c_latency_LeftTarget-N2c_latency_RightTarget)/(N2c_latency_LeftTarget+N2c_latency_RightTarget),
N2i_latency_Asym =(N2i_latency_LeftTarget-N2i_latency_RightTarget)/(N2i_latency_LeftTarget+N2i_latency_RightTarget),
CPPonset_Asym = (CPPonset_LeftTarget-CPPonset_RightTarget)/(CPPonset_LeftTarget+CPPonset_RightTarget),
CPPslope_Asym = (CPPslope_LeftTarget-CPPslope_RightTarget)/(CPPslope_LeftTarget+CPPslope_RightTarget),
location = ifelse(location==1, "TCD", "Monash")
)
####################################################################################
## Find outliers in the Participant level data (abs z-score >3)
#Collapse each participant's RT single trials to participant level
RT_collapsed<- data %>%
group_by(ID, Hemifield) %>%
summarise(RT=mean(RT)) %>% #next bring Target-Hemifield up into wide format:
spread(Hemifield, RT) %>% #next rename
rename(RT_Left=Left, RT_Right=Right) %>% # next Calculate RT asymmetry:
mutate(RT_Asym=(RT_Left-RT_Right)/(RT_Left+RT_Right))
#Merge it in with the ERP measures
participant_level<-merge(RT_collapsed, participant_level, by.x = "ID", by.y = "ID")
#Transform it to long format
participant_level_long<-participant_level %>%
gather(measure_type, data, -ID) %>%
na.omit()
#################################################################
#Calculate Z scores inside measure_type type TO REMOVE OUTLIERS
#Z-score each participant's data inside measure_type ####
#calculate mean and sd
m <- tapply(participant_level_long$data,participant_level_long$measure_type,mean, na.rm = T)
s <- sqrt(tapply(participant_level_long$data,participant_level_long$measure_type,var, na.rm = T))
#calculate data.Z and save it inside participant_level_long
participant_level_long$data.Z <- (participant_level_long$data-m[participant_level_long$measure_type])/s[participant_level_long$measure_type]
#Remove trials where absolute data.Z>3 (i.e. remove outlier RTs)
# participant_level_long<-participant_level_long[!abs(participant_level_long$data.Z)>3,]
#Plot density plots again after outlier removal
ggplot(participant_level_long, aes(data))  + geom_density() + facet_wrap(~ measure_type, scales="free")
#change measure_type to factor class
participant_level_long$measure_type<-as.factor(participant_level_long$measure_type)
#Put it back into long format so I can use lapply to do t-test on columns
participant_level<-participant_level_long %>% select(., -data.Z)  %>%
spread(measure_type, data)
#Merge in the Demographics
participant_level<-merge(participant_level, Demographics, by.x = "ID", by.y = "ID")
####################################################################################
View(participant_level)
RT_collapsed<- data %>%
group_by(ID, Hemifield) %>%
summarise(RT=mean(RT)) %>% #next bring Target-Hemifield up into wide format:
spread(Hemifield, RT) %>% #next rename
rename(RT_Left=Left, RT_Right=Right) %>% # next Calculate RT asymmetry:
mutate(RT_Asym=(RT_Left-RT_Right)/(RT_Left+RT_Right))
#Merge it in with the ERP measures
participant_level<-merge(RT_collapsed, participant_level, by.x = "ID", by.y = "ID")
#Transform it to long format
participant_level_long<-participant_level %>%
gather(measure_type, data, -ID) %>%
na.omit()
#################################################################
#Calculate Z scores inside measure_type type TO REMOVE OUTLIERS
#Z-score each participant's data inside measure_type ####
#calculate mean and sd
m <- tapply(participant_level_long$data,participant_level_long$measure_type,mean, na.rm = T)
s <- sqrt(tapply(participant_level_long$data,participant_level_long$measure_type,var, na.rm = T))
#calculate data.Z and save it inside participant_level_long
participant_level_long$data.Z <- (participant_level_long$data-m[participant_level_long$measure_type])/s[participant_level_long$measure_type]
#Remove trials where absolute data.Z>3 (i.e. remove outlier RTs)
# participant_level_long<-participant_level_long[!abs(participant_level_long$data.Z)>3,]
#Plot density plots again after outlier removal
ggplot(participant_level_long, aes(data))  + geom_density() + facet_wrap(~ measure_type, scales="free")
#change measure_type to factor class
participant_level_long$measure_type<-as.factor(participant_level_long$measure_type)
#Put it back into long format so I can use lapply to do t-test on columns
participant_level<-participant_level_long %>% select(., -data.Z)  %>%
spread(measure_type, data)
#Merge in the Demographics
participant_level<-merge(participant_level, Demographics, by.x = "ID", by.y = "ID")
####################################################################################
close all
####Which computer/directory is this being run on?
location<-"Monash"
# location<-"GersLaptop"
if (location=="Monash") {
setwd(("C:/GitHub/big_dots/Analyses Scripts_R"))
} else if (location=="GersLaptop") {
setwd(("C:/Users/loughnge/Documents/GitHub/big_dots/Analyses Scripts_R"))
} else setwd(("~"))
####################################
#######  How to use ################
####################################
# 1) Install the packages and software specified below. (consider also updating all installed packages by chosing Update on the Packages tab)
# 2) Set the working directory (setwd) above, and directory where you have "data_ParticipantLevel", "master_matrix_R" and "ID_vector" saved
# 3) Hit Knit Word (or Knit HTML)! (Output can take while due to bootstrapping the robust effect size and calculating the Bayesian Highest Density Iinterval)
####################################
######  FIRST TIME ONLY ############
####################################
#Remove # in front of the line below and run the code. Replace the # after installing the packages, otherwise the R markdown script will give errors.
# install.packages(c("MASS", "akima", "robustbase", "cobs", "robust", "mgcv", "scatterplot3d", "quantreg", "rrcov", "lars", "pwr", "trimcluster", "mc2d", "psych", "Rfit","MBESS", "BayesFactor", "PoweR", "ggplot2", "reshape2", "plyr", "devtools", "rmarkdown","gmodels", "HLMdiag", "car", "gridExtra", "bootES", "BEST","foreign","nlme","pastecs","multcomp","compute.es","ez","lattice","lme4","effects","diagram","png", "grid", "dplyr","readxl", "openxlsx", "haven","schoRsch", "lubridate"))
###################################################################################################################################
## load relevant libraries
library(foreign)
library(car)
library(nlme)
library(ggplot2)
library(pastecs)
library(psych)
library(multcomp)
library(compute.es)
library(ez)
library(lme4)
library(png)
library(grid)
library(readxl)
library(dplyr)
library(tidyr)
library(lubridate)
###### Import single trial data:
if (location=="Monash") {
data <- read.csv("C:/GitHub/big_dots/master_matrix_R_BigDots.csv", header=FALSE)
} else if (location=="GersLaptop") {
data <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/master_matrix_R_BigDots.csv", header=FALSE)
} else setwd(("~"))
#Import IDs:
if (location=="Monash") {
ID <- read.table("C:/GitHub/big_dots/ID_vector_BigDots.csv", quote="\"")
} else if (location=="GersLaptop") {
ID <- read.table("C:/Users/Dan/Documents/GitHub/big_dots/ID_vector_BigDots.csv", quote="\"")
} else setwd(("~"))
data$ID<-data[,1]
#Replace the participant numbers with IDs:
data[,1]<-ID[,1]
#Remove the seperate ID vector now it has been included into data dataframe
rm(ID)
drops <- c("ID")
data<-data[,!(names(data) %in% drops)]
###Read in Participant Demographics (note for Sex 1=male)
Demographics<-read_excel("Participant_Demographics.xlsx") %>% #then calculate Age at testing date:
mutate(Age_as_period=as.period(interval(Date_Of_Birth, Date_Of_Testing), units="years")) %>%
mutate(Sex = ifelse(Sex==1, "Male", "Female"))
#Calculate Age in numeric format
Demographics$Age<-as.numeric(difftime(as.Date(Demographics$Date_Of_Testing), as.Date(Demographics$Date_Of_Birth), units = "days")/365)
summary(Demographics$Age)
#########################################################################################################################
data<- data %>% #Rename data columns:
rename(.,
ID=V1,
TotalTrialNumber=V2,
Trial=V3,
ITI=V4,
Hemifield=V5,
Accuracy=V6,
Art_neg500_0=V7,
Art_neg100_100PR=V8,
Art_neg500_100PR=V9,
Art_neg100_1000=V10,
FixBreak_neg500_0=V11,
FixBreak_neg100_100PR=V12,
FixBreak_neg500_100PR=V13,
FixBreak_neg100_1000=V14,
RT=V15) %>% #next make the required columns into factors:
mutate_each_(funs(factor), c("ITI", "Hemifield", "Accuracy")) %>% #next re-class required vectors into Logicals:
mutate_at(vars(starts_with("Art_")), funs(as.logical)) %>%
mutate_at(vars(starts_with("FixBreak_")), funs(as.logical)) %>% #next use the ! negation operator to reverse of a TRUE/FALSE vectors:
mutate_if(purrr::is_logical, funs(!.)) %>% #next Rename factor Levels:
mutate(Hemifield = ifelse(Hemifield==1, "Left", "Right"),
Accuracy= ifelse(Accuracy==1, "Hit", ifelse(Accuracy==2, "WrongButton", "Miss")))
Demographics <-Demographics[Demographics$ID %in% data$ID, ]
###############Data Cleaning For Single Trial Data######################
#Check number of Trials for each participant by running the function 'length',
#on "data$RT" for each DAT1_3UTR, broken down by ID + Light
num_trials1 <- data %>% group_by(ID) %>% summarise( Trials = length(RT))
summary(num_trials1$Trials)
##################Accuracy ##########################
Accuracy_checker <- data %>% group_by(ID) %>%
summarise(Hits  = sum(Accuracy=="Hit"),
Misses = sum(Accuracy=="Miss" | Accuracy=="WrongButton")) %>%
mutate(Total=Hits+Misses,
Accuracy_overall= (Hits/Total)*100)
summary(Accuracy_checker$Accuracy_overall)
##Add in overall accuracy
data <- merge(data, Accuracy_checker, by.x = "ID", by.y = "ID")
###Remove trials where:
#RT longer than 1000ms (i.e. after target finished)
#RT faster than 100ms (i.e. too fast must be false alarm) or RT=0 (i.e. they did not respond)
#Kick out trials with fixation breaks:
data<-filter(data, RT<1500 & RT>150 & !FixBreak_neg100_100PR)
############################################ Log transform:
##############################################################################################
data$log_RT<-log(data$RT) #log
#####Z-score each participant's log_RT data ####
data$IDbyITIbyHemifield<-interaction(data$ID, data$ITI, data$Hemifield)
#calculate mean and sd
m <- tapply(data$log_RT,data$IDbyITIbyHemifield,mean, na.rm = T)
s <- sqrt(tapply(data$log_RT,data$IDbyITIbyHemifield,var, na.rm = T))
#calculate log_RT.Z and save it inside data.frame
data$log_RT.Z <- (data$log_RT-m[data$IDbyITIbyHemifield])/s[data$IDbyITIbyHemifield]
#Remove trials where absolute log_RT.Z>3 (i.e. remove outlier RTs)
data<-data[!abs(data$log_RT.Z)>3,]
#plot again after outlier removal:
ggplot(data, aes(RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white")
ggplot(data, aes(log_RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white")
#Calculate the number of trials each participant has left after fixation break trials are kicked out:
num_trials2 <- data %>% group_by(ID) %>% summarise( Trials = length(RT))
summary(num_trials2$Trials)
####Import participant_level_matrix with ERP measures
if (location=="Monash") {
participant_level <- read.csv("C:/GitHub/big_dots/participant_level_matrix.csv", header=FALSE)
} else if (location=="DansLaptop") {
participant_level <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/participant_level_matrix.csv", header=FALSE)
} else setwd(("~"))
#Import IDs:
if (location=="Monash") {
ID <- read.table("C:/GitHub/big_dots/IDs.csv", quote="\"")
} else if (location=="DansLaptop") {
ID <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/IDs.csv", header=F)
} else setwd(("~"))
ID<-plyr::rename(ID,c("V1"="ID"))
participant_level$ID<-ID$ID
rm(ID)
participant_level<- participant_level %>% #Rename data columns:
rename(.,
N2c_LeftTarget=V1,
N2c_RightTarget=V2,
N2i_LeftTarget=V3,
N2i_RightTarget=V4,
N2c_latency_LeftTarget=V5,
N2c_latency_RightTarget=V6,
N2i_latency_LeftTarget=V7,
N2i_latency_RightTarget=V8,
CPPonset_LeftTarget=V9,
CPPonset_RightTarget=V10,
CPPslope_LeftTarget=V11,
CPPslope_RightTarget=V12,
location=V13) %>% #next calculate the ERP asymmetry measures:
mutate(.,
N2c_Asym = (N2c_LeftTarget-N2c_RightTarget)/(N2c_LeftTarget+N2c_RightTarget),
N2i_Asym = (N2i_LeftTarget-N2i_RightTarget)/(N2i_LeftTarget+N2i_RightTarget),
N2c_latency_Asym = (N2c_latency_LeftTarget-N2c_latency_RightTarget)/(N2c_latency_LeftTarget+N2c_latency_RightTarget),
N2i_latency_Asym =(N2i_latency_LeftTarget-N2i_latency_RightTarget)/(N2i_latency_LeftTarget+N2i_latency_RightTarget),
CPPonset_Asym = (CPPonset_LeftTarget-CPPonset_RightTarget)/(CPPonset_LeftTarget+CPPonset_RightTarget),
CPPslope_Asym = (CPPslope_LeftTarget-CPPslope_RightTarget)/(CPPslope_LeftTarget+CPPslope_RightTarget),
location = ifelse(location==1, "TCD", "Monash")
)
View(participant_level)
RT_collapsed<- data %>%
group_by(ID, Hemifield) %>%
summarise(RT=mean(RT)) %>% #next bring Target-Hemifield up into wide format:
spread(Hemifield, RT) %>% #next rename
rename(RT_Left=Left, RT_Right=Right) %>% # next Calculate RT asymmetry:
mutate(RT_Asym=(RT_Left-RT_Right)/(RT_Left+RT_Right))
participant_level<-merge(participant_level, RT_collapsed, by.x = "ID", by.y = "ID")
#Transform it to long format
participant_level_long<-participant_level %>%
gather(measure_type, data, -ID) %>%
na.omit()
m <- tapply(participant_level_long$data,participant_level_long$measure_type,mean, na.rm = T)
s <- sqrt(tapply(participant_level_long$data,participant_level_long$measure_type,var, na.rm = T))
#calculate data.Z and save it inside participant_level_long
participant_level_long$data.Z <- (participant_level_long$data-m[participant_level_long$measure_type])/s[participant_level_long$measure_type]
#Remove trials where absolute data.Z>3 (i.e. remove outlier RTs)
# participant_level_long<-participant_level_long[!abs(participant_level_long$data.Z)>3,]
#Plot density plots again after outlier removal
ggplot(participant_level_long, aes(data))  + geom_density() + facet_wrap(~ measure_type, scales="free")
#change measure_type to factor class
participant_level_long$measure_type<-as.factor(participant_level_long$measure_type)
#Put it back into long format so I can use lapply to do t-test on columns
participant_level<-participant_level_long %>% select(., -data.Z)  %>%
spread(measure_type, data)
#Merge in the Demographics
participant_level<-merge(participant_level, Demographics, by.x = "ID", by.y = "ID")
####################################################################################
m <- tapply(participant_level_long$data,participant_level_long$measure_type,mean, na.rm = T)
warnings()
View(participant_level_long)
