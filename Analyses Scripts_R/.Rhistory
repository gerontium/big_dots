data<-merge(DAT1, RT_index, c("ID"))
########### Overall leftward Bias?? ############
t.test (data$RT_index, mu=0)
## Remove outliers
data$RT_index.Z<-scale(data$RT_index)
data<-data[abs(data$RT_index.Z)<3,]
data<-data[complete.cases(data),]
data$RT_index.Z<-scale(data$RT_index)
data<-data[abs(data$RT_index.Z)<3,]
DAT1 <- read.csv("S:/R-MNHS-SPP/Bellgrove-data/4. Dan Newman/Participant Folders_new/DAT1genotypes_forR.csv", na.strings="")
RT_index <- read.csv("S:/R-MNHS-SPP/Bellgrove-data/4. Dan Newman/Participant Folders_new/RT_index_forR.csv", na.strings="")
summary(DAT1)
summary(DAT1$DAT1_3UTR_VNTRraw)
#Make the required columns into factors:
DAT1$DAT1_3UTR_VNTRraw <- factor(DAT1$DAT1_3UTR_VNTRraw)
DAT1$Site <- factor(DAT1$Site)
DAT1$DAT1_10_10_repeats  <- plyr::revalue(DAT1$DAT1_3UTR_VNTRraw ,
c("10 10"="Two",
"10 11"="One",
"7 10"="One",
"7 9"="Zero",
"8 11"="Zero",
"9 10"="One",
"9 9"="Zero"))
summary(DAT1$DAT1_10_10_repeats)
DAT1$DAT1_3UTR  <- plyr::revalue(DAT1$DAT1_3UTR_VNTRraw ,
c("10 10"="10_10_repeat",
"10 11"="non10_10_repeat",
"7 10"="non10_10_repeat",
"7 9"="non10_10_repeat",
"8 11"="non10_10_repeat",
"9 10"="non10_10_repeat",
"9 9"="non10_10_repeat"))
summary(DAT1$DAT1_3UTR)
DAT1$DAT1_int8  <- plyr::revalue(DAT1$DAT1_Int8_VNTRraw ,
c("6 6"="6_6_repeat",
"5 6"="non6_6_repeat",
"5 5"="non6_6_repeat"))
summary(DAT1$DAT1_int8)
#### Merge the data sets together
data<-merge(DAT1, RT_index, c("ID"))
########### Overall leftward Bias?? ############
t.test (data$RT_index, mu=0)
## Remove outliers
data$RT_index.Z<-scale(data$RT_index)
data<-data[abs(data$RT_index.Z)<3,]
##Remove those with missing genotypes
data<-data[complete.cases(data),]
View(data)
DAT1 <- read.csv("S:/R-MNHS-SPP/Bellgrove-data/4. Dan Newman/Participant Folders_new/DAT1genotypes_forR.csv", na.strings="")
RT_index <- read.csv("S:/R-MNHS-SPP/Bellgrove-data/4. Dan Newman/Participant Folders_new/RT_index_forR.csv", na.strings="")
summary(DAT1)
summary(DAT1$DAT1_3UTR_VNTRraw)
#Make the required columns into factors:
DAT1$DAT1_3UTR_VNTRraw <- factor(DAT1$DAT1_3UTR_VNTRraw)
DAT1$Site <- factor(DAT1$Site)
DAT1$DAT1_10_10_repeats  <- plyr::revalue(DAT1$DAT1_3UTR_VNTRraw ,
c("10 10"="Two",
"10 11"="One",
"7 10"="One",
"7 9"="Zero",
"8 11"="Zero",
"9 10"="One",
"9 9"="Zero"))
summary(DAT1$DAT1_10_10_repeats)
DAT1$DAT1_3UTR  <- plyr::revalue(DAT1$DAT1_3UTR_VNTRraw ,
c("10 10"="10_10_repeat",
"10 11"="non10_10_repeat",
"7 10"="non10_10_repeat",
"7 9"="non10_10_repeat",
"8 11"="non10_10_repeat",
"9 10"="non10_10_repeat",
"9 9"="non10_10_repeat"))
summary(DAT1$DAT1_3UTR)
DAT1$DAT1_int8  <- plyr::revalue(DAT1$DAT1_Int8_VNTRraw ,
c("6 6"="6_6_repeat",
"5 6"="non6_6_repeat",
"5 5"="non6_6_repeat"))
summary(DAT1$DAT1_int8)
#### Merge the data sets together
data<-merge(DAT1, RT_index, c("ID"))
########### Overall leftward Bias?? ############
t.test (data$RT_index, mu=0)
## Remove outliers
data$RT_index.Z<-scale(data$RT_index)
data<-data[abs(data$RT_index.Z)<3,]
data<-data[complete.cases(data),]
ggplot2::ggplot(data, aes(RT_index))  +
geom_histogram(aes(y=..count..), colour="black", fill="white") +
facet_wrap(~ DAT1_3UTR)
ggplot2::ggplot(data, aes(RT_index, colour = DAT1_3UTR))  +
geom_density(alpha = 0.1)
ez::ezANOVA(
data = data
, dv = .(RT_index)
, wid = .(ID)
, between = .(DAT1_3UTR)
, type = 3
, detailed = F
, between_covariates= .("Site")
)
ez::ezPerm(
data = data
, dv = .(RT_index)
, wid = .(ID)
, between = .(DAT1_3UTR)
)
boot<-ez::ezBoot(
data = data
, dv = .(RT_index)
, wid = .(ID)
, between = .(DAT1_3UTR)
)
ez::ezPlot2(boot, x=DAT1_3UTR, y_lab = "RT asymmetry index")
t.test (data$RT_index[data$DAT1_3UTR=="non10_10_repeat"], mu=0)
t.test (data$RT_index[data$DAT1_3UTR=="10_10_repeat"], mu=0)
ggplot2::ggplot(data, aes(scale(RT_index)))  +
geom_histogram(aes(y=..count..), colour="black", fill="white") +
facet_wrap(~ DAT1_3UTR)
ggplot2::ggplot(data, aes(RT_index, colour = DAT1_3UTR))  +
geom_density(alpha = 0.1)
ez::ezANOVA(
data = data
, dv = .(RT_index)
, wid = .(ID)
, between = .(DAT1_3UTR)
, type = 3
, detailed = F
, between_covariates= .("Site")
)
summary(DAT1$DAT1_3UTR)
summary(data$DAT1_3UTR)
View(data)
View(DAT1)
data$RT_overall<-mean(data$RT_left, RT_right)
data$RT_overall<-mean(data$RT_left, data$RT_right)
data$RT_overall<-mean(data$RT_left + data$RT_right)/2
ez::ezANOVA(
data = data
, dv = .(RT_overall)
, wid = .(ID)
, between = .(DAT1_3UTR)
, type = 3
, detailed = F
, between_covariates= .("Site")
)
? mean
data$RT_overall<(-mean(data$RT_left + data$RT_right)/2)
data$RT_overall<-(mean(data$RT_left + data$RT_right)/2)
data$RT_overall<-(rowMeans(data$RT_left + data$RT_right)/2)
rowMeans(data$RT_left + data$RT_right)/2
? rowMeans
data$RT_overall<-rowMeans(data$RT_left + data$RT_right)
data$RT_overall<-rowMeans(c(data$RT_left + data$RT_right))
apply(rbind(data$RT_left,data$RT_right),2,mean)
(467.9143+458.4892)/2
data$RT_overall<-apply(rbind(data$RT_left,data$RT_right),2,mean)
ez::ezANOVA(
data = data
, dv = .(RT_overall)
, wid = .(ID)
, between = .(DAT1_3UTR)
, type = 3
, detailed = F
, between_covariates= .("Site")
)
boot<-ez::ezBoot(
data = data
, dv = .(RT_overall)
, wid = .(ID)
, between = .(DAT1_3UTR)
)
ez::ezPlot2(boot, x=DAT1_3UTR)
d.f <- data.frame(rating = c("AAA", "A", "A", "AAA",
"BB", "BB", "AAA", "A"))
i <- 1
by <- d.f$rating
sub.data.frame <- d.f[by == unique(by)[i], ]
View(d.f)
values <- data.frame(value = c("a", "a", "a", "a", "a",
"b", "b", "b",
"c", "c", "c", "c"))
nr.of.appearances <- aggregate(x = values,
by = list(unique.values = values$value),
FUN = length)
View(values)
View(nr.of.appearances)
View(d.f)
DAT1 <- read.csv("S:/R-MNHS-SPP/Bellgrove-data/4. Dan Newman/Participant Folders_new/DAT1genotypes_forR.csv", na.strings="")
RT_index <- read.csv("S:/R-MNHS-SPP/Bellgrove-data/4. Dan Newman/Participant Folders_new/RT_index_forR.csv", na.strings="")
t.test(RT_index$RT_left,RT_index$RT_right, paired=TRUE)
mean(RT_index$RT_left)
#Std error.
sd(RT_index$RT_left) / sqrt(length(RT_index$RT_left))
mean(RT_index$RT_left)
#Std error.
sd(RT_index$RT_left) / sqrt(length(RT_index$RT_left))
#Mean right targets
mean(RT_index$RT_right)
#Std error.
sd(RT_index$RT_left) / sqrt(length(RT_index$RT_left))
751-585
571-585
mean(RT_index$RT_left)
hist(RT_index$RT_right)
hist(RT_index$RT_left)
hist(RT_index$RT_right)
hist(RT_index$RT_left)
hist(RT_index$RT_right)
hist(log(RT_index$RT_right))
hist(log(RT_index$RT_left))
t.test(log(RT_index$RT_left),log(RT_index$RT_right), paired=TRUE)
t.test(log(RT_index$RT_left),log(RT_index$RT_right), paired=TRUE)
t.test(log(RT_index$RT_left),log(RT_index$RT_right), paired=TRUE)
mean(RT_index$RT_left)
sd(RT_index$RT_left) / sqrt(length(RT_index$RT_left))
DAT1 <- read.csv("S:/R-MNHS-SPP/Bellgrove-data/4. Dan Newman/Participant Folders_new/DAT1genotypes_forR.csv", na.strings="")
mean(RT_index$RT_right)
mean(RT_index$RT_right)
sd(RT_index$RT_left) / sqrt(length(RT_index$RT_left))
sd(RT_index$RT_right) / sqrt(length(RT_index$RT_right))
8*7
4372/56
59*60
2915/56
60*57
50*57
50*57
15*313.001781
4754.03-(15*313.001781)
9*400
5*400
5*400
9*400
30*60
1800/300
1800/10
180/60
30/1
9603+56336
9603+56336+8000
31.257/2
2050/3.8
540*3.8
2000-540
1460+540
10*31
31-29.67
1.33*10
1.4^2
(50-.07)/.07
(2.3-3)/3
37.5*8
1300/3.8
340*3.8
340*3.8
350*3.8
buy=2,125.88
buy=2125.88
sell1=618.30
sell2=1646.05
sell1+sell2
(sell1+sell2-buy)/(sell1+sell2)
(2264.35-2125.88)/2125.88
(2264.35-2165.88)/2125.88
(sell1+sell2-buy+40)/(sell1+sell2)
8*
sADF
8*3
24*50
24*50
900/.70
900/.71
900/.72
2558.37-20
(2558.37-20)/3.83
(2558.37-20)/3.82
(2558.37-20)/3.82
(2558.37-20)/3.81
1910*10
1099472*.035
.071*2
(3478.32-150)/48
69+79
location<-"Monash"
# location<-"DansLaptop"
if (location=="Monash") {
setwd(("C:/GitHub/big_dots/Analyses Scripts_R"))
} else if (location=="DansLaptop") {
setwd(("C:/Users/Dan/Documents/GitHub/big_dots/Analyses Scripts_R"))
} else setwd(("~"))
####################################
#######  How to use ################
####################################
# 1) Install the packages and software specified below. (consider also updating all installed packages by chosing Update on the Packages tab)
# 2) Set the working directory (setwd) above, and directory where you have "data_ParticipantLevel", "master_matrix_R" and "ID_vector" saved
# 3) Hit Knit Word (or Knit HTML)! (Output can take while due to bootstrapping the robust effect size and calculating the Bayesian Highest Density Iinterval)
####################################
######  FIRST TIME ONLY ############
####################################
#Remove # in front of the line below and run the code. Replace the # after installing the packages, otherwise the R markdown script will give errors.
# install.packages(c("MASS", "akima", "robustbase", "cobs", "robust", "mgcv", "scatterplot3d", "quantreg", "rrcov", "lars", "pwr", "trimcluster", "mc2d", "psych", "Rfit","MBESS", "BayesFactor", "PoweR", "ggplot2", "reshape2", "plyr", "devtools", "rmarkdown","gmodels", "HLMdiag", "car", "gridExtra", "bootES", "BEST","foreign","nlme","pastecs","multcomp","ggplot2","compute.es","ez","lattice","lme4","effects","diagram","png", "grid", "dplyr","readxl"))
#Installation of the robust statistics package: Remove # in front of each of 4 lines below and run the code. Replace the # after installing the packages, otherwise the R markdown script will give errors.
# install.packages("devtools")
# library("devtools")
# install_github("mrxiaohe/WRScpp")
# install_github("nicebread/WRS", subdir="pkg")
#Download and install JAGS to calculate Bayesian HDI: http://sourceforge.net/projects/mcmc-jags/
###################################################################################################################################
## Install relevant libraries
library(foreign)
library(car)
library(nlme)
library(ggplot2)
library(pastecs)
library(psych)
library(plyr)
library(multcomp)
library(reshape2)
library(compute.es)
library(ez)
library(lattice)
library(lme4)
library(png)
library(grid)
library(readxl)
###### Import single trial data:
if (location=="Monash") {
data <- read.csv("C:/GitHub/big_dots/master_matrix_R_BigDots.csv", header=FALSE)
} else if (location=="DansLaptop") {
data <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/master_matrix_R_BigDots.csv", header=FALSE)
} else setwd(("~"))
#Import IDs:
if (location=="Monash") {
ID <- read.table("C:/GitHub/big_dots/ID_vector_BigDots.csv", quote="\"")
} else if (location=="DansLaptop") {
ID <- read.table("C:/Users/Dan/Documents/GitHub/big_dots/ID_vector_BigDots.csv", quote="\"")
} else setwd(("~"))
data$ID<-data[,1]
#Replace the participant numbers with IDs:
data[,1]<-ID[,1]
#Remove the seperate ID vector now it has been included into data dataframe
rm(ID)
drops <- c("ID")
data<-data[,!(names(data) %in% drops)]
#########################################################################################################################
#data_ParticipantLevel:
# ###### Import data_ParticipantLevel:
# if (location=="Monash") {
# data_participant_level <- read.csv("C:/GitHub/big_dots/participant_level_matrix.csv", header=FALSE)
# } else if (location=="DansLaptop") {
# data_participant_level <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/participant_level_matrix.csv", header=FALSE)
# } else setwd(("~"))
#
#
# #Import IDs:
# if (location=="Monash") {
# ID <- read.table("S:/R-MNHS-SPP/Bellgrove-data/11.Megan_ONeill/Analysis Scripts_Matlab/IDs.csv", quote="\"")
# } else if (location=="DansLaptop") {
# ID <- read.csv("C:/Users/Dan/Documents/GitHub/10_10_repeatvsnon10_10_repeat/Analyses Scripts_Matlab/IDs.csv", header=F)
# } else setwd(("~"))
# ID<-plyr::rename(ID,c("V1"="ID"))
# data_participant_level$ID<-ID$ID
# rm(ID)
# # drops <- c("ID")
# # data_participant_level<-data_participant_level[,!(names(data_participant_level) %in% drops)]
#
# #import demographic data
# if (location=="Monash") {
# Demographics<-read.csv("S:/R-MNHS-SPP/Bellgrove-data/11.Megan_ONeill/Analysis Scripts_R/10_10_repeat_non10_10_repeat_Demographics_etc.csv", header=T)
# } else if (location=="DansLaptop") {
# Demographics<-read.csv("C:/Users/Dan/Documents/GitHub/10_10_repeatvsnon10_10_repeat/Analyses Scripts_R/10_10_repeat_non10_10_repeat_Demographics_etc.csv", header=T)
# } else setwd(("~"))
#
#
#
# #Merge Demographics into data_participant_level:
# data_participant_level <- merge(data_participant_level, Demographics, by.x = "ID", by.y = "ID")
# rm(Demographics)
#########################################################################################################################
#Rename data columns:
data<-rename(data, c("V1"="ID","V2"="TotalTrialNumber","V3"="Trial","V4"="ITI","V5"="Hemifield", "V6"="Accuracy",
"V7"="Art_neg500_0", "V8"="Art_neg100_100PR","V9"="Art_neg500_100PR", "V10"="Art_neg100_1000",
"V11"="FixBreak_neg500_0", "V12"="FixBreak_neg100_100PR","V13"="FixBreak_neg500_100PR", "V14"="FixBreak_neg100_1000",
"V15"="RT"))
#NOTE: FOR N2c/i,  the _GA or _PA suffix indicates whether N2c/i is measured with a measurement window based
#on Grand average (GA) peak N2c/i latency,  or based on Participant level average (PA) peak N2c/i latency
#Make the required columns into factors:
data$ITI <- factor(data$ITI)
data$Hemifield <- factor(data$Hemifield)
data$Accuracy <- factor(data$Accuracy)
#Rename factor Levels:
data$Hemifield <- revalue(data$Hemifield, c("1"="Left", "2"="Right"))
data$Accuracy <- revalue(data$Accuracy, c("1"="Hit", "0"="RejectedTrial", "2"="WrongButton", "3"="Miss"))
#Re-class required vectors into Logicals:
data$Art_neg500_0<-!as.logical(data$Art_neg500_0)
data$Art_neg100_100PR<-!as.logical(data$Art_neg100_100PR)
data$Art_neg500_100PR<-!as.logical(data$Art_neg500_100PR)
data$Art_neg100_1000<-!as.logical(data$Art_neg100_1000)
data$FixBreak_neg500_0<-!as.logical(data$FixBreak_neg500_0)
data$FixBreak_neg100_100PR<-!as.logical(data$FixBreak_neg100_100PR)
data$FixBreak_neg500_100PR<-!as.logical(data$FixBreak_neg500_100PR)
data$FixBreak_neg100_1000<-!as.logical(data$FixBreak_neg100_1000)
############################################ Import DAT1 Data ##############################################
DAT1 <- read_excel("DAT1genotypes_forR.xlsx")
#Make the required columns into factors:
DAT1$DAT1_3UTR_VNTRraw <- factor(DAT1$DAT1_3UTR_VNTRraw)
DAT1$DAT1_Int8_VNTRraw <- factor(DAT1$DAT1_Int8_VNTRraw)
DAT1$Site <- factor(DAT1$Site)
DAT1$ID<-as.factor(DAT1$ID)
DAT1$DAT1_10_10_repeats  <- revalue(DAT1$DAT1_3UTR_VNTRraw ,
c("10 10"="Two",
"10 11"="One",
"7 10"="One",
"7 9"="Zero",
"8 11"="Zero",
"9 10"="One",
"9 9"="Zero"))
summary(DAT1$DAT1_10_10_repeats)
DAT1$DAT1_3UTR  <- revalue(DAT1$DAT1_3UTR_VNTRraw ,
c("10 10"="10_10_repeat",
"10 11"="non10_10_repeat",
"7 10"="non10_10_repeat",
"7 9"="non10_10_repeat",
"8 11"="non10_10_repeat",
"9 10"="non10_10_repeat",
"9 9"="non10_10_repeat"))
summary(DAT1$DAT1_3UTR)
DAT1$DAT1_int8  <- revalue(DAT1$DAT1_Int8_VNTRraw ,
c("6 6"="6_6_repeat",
"5 6"="non6_6_repeat",
"5 5"="non6_6_repeat"))
summary(DAT1$DAT1_int8)
#Only keep Genotypes for the participants who we actually tested on big dots
#(there are a few extra participant genotypes in the DAT1 sheet)
DAT1 <-DAT1[DAT1$ID %in% data$ID, ]
#How many participant's have missing DAT1 genotype?
summary(DAT1$DAT1_3UTR) #So 4 participant have missing DAT1 genotype
#### Merge the data sets together
data<-merge(data, DAT1, by.x = "ID", by.y = "ID")
################################################################################################
###############Data Cleaning For Single Trial Data######################
#Check number of Trials for each participant by running the function 'length',
#on "data$RT" for each DAT1_3UTR, broken down by ID + Light
num_trials1 <- ddply(data, c("ID"), summarise,
Trials    = length(RT))
summary(num_trials1$Trials)
mean(num_trials1$Trials)
##################Accuracy ##########################
Accuracy_checker <- ddply(data, c("ID"), summarise,
Hits  = sum(Accuracy=="Hit"),
Misses = sum(Accuracy=="Miss" | Accuracy=="WrongButton"))
Accuracy_checker$Total=Accuracy_checker$Hits+Accuracy_checker$Misses
Accuracy_checker$Accuracy_overall=(Accuracy_checker$Hits/Accuracy_checker$Total)*100
summary(Accuracy_checker$Accuracy_overall)
##Add in overall accuracy
data <- merge(data, Accuracy_checker, by.x = "ID", by.y = "ID")
#Remove trials where RT=0 (i.e. they did not respond)
data<-data[data$RT!=0,]
#Remove trials where RT longer than 1000ms (i.e. after target finished)
data<-data[data$RT<1500,]
#Remove trials where RT faster than 100ms (i.e. too fast must be false alarm)
data<-data[data$RT>150,]
#Kick out trials with fixation breaks:
data<-data[!data$FixBreak_neg100_100PR,]
data2<-data[complete.cases(data$DAT1_3UTR),]####### This kicks out 4 the participants for which we didn't have DAT1 genotpes
Accuracy_collapsed<-ddply(data2, .(ID, DAT1_3UTR), summarise, Accuracy=mean(Accuracy_overall))
###Check for Accuracy_overall outliers
min(Accuracy_collapsed$Accuracy)
#Plot the Accuracy distribution for each DAT1_3UTR
ggplot(Accuracy_collapsed, aes(Accuracy))  + geom_histogram() + facet_wrap(~ DAT1_3UTR)
############ Are there significant accuracy differences between 10_10_repeat and non10_10_repeat? ##############
##############################################################
#Overall Accuracy by DAT1_3UTR
log <- capture.output({
Accuracy_DAT1_3UTR <- ezPerm(data = Accuracy_collapsed
, dv = .(Accuracy)
, wid = .(ID)
, between = .(DAT1_3UTR)
, perms = 1000);
})
print("Factorial Permutation test for the effect of DAT1_3UTR on Accuracy")
print(Accuracy_DAT1_3UTR);
#Calculate the number of trials each participant has left after NAs are kicked out:
num_trials2 <- ddply(data2, c("ID"), summarise,
Num_RT_Trials    = length(RT))
summary(num_trials2)
data2$DAT1_3UTR_by_Hemifield<-interaction(data2$DAT1_3UTR, data2$Hemifield)
ggplot(data2, aes(RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white") + facet_wrap(~ DAT1_3UTR_by_Hemifield)
ggplot(data2, aes(log_RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white") + facet_wrap(~ DAT1_3UTR_by_Hemifield)
#Try a density plot
ggplot(data2, aes(RT, colour = DAT1_3UTR_by_Hemifield))  +
geom_density(alpha = 0.1)
#So get participant level RT into long format so I can run permutated t-tests
RT_collapsed<-ddply(data2, .(ID, Hemifield, DAT1_3UTR), summarise, RT=mean(RT))
#Plot RT by DAT1_3UTR and hemifield:
RT_collapsed$DAT1_3UTR_by_Hemifield<-interaction(RT_collapsed$Hemifield, RT_collapsed$DAT1_3UTR)
#non log transformed:
ggplot(RT_collapsed, aes(RT))  + geom_histogram() + facet_wrap(~ DAT1_3UTR_by_Hemifield)
#Try a density plot
ggplot(RT_collapsed, aes(RT, colour = DAT1_3UTR_by_Hemifield))  +
geom_density(alpha = 0.1)
log <- capture.output({
RT_Hemifield_by_DAT1_3UTR <- ezPerm(data = RT_collapsed
, dv = .(RT)
, wid = .(ID)
, within = .(Hemifield)
, between = .(DAT1_3UTR)
, perms = 1000
)})
print("Factorial Permutation test for Hemifield x DAT1 group interaction on RT")
print(RT_Hemifield_by_DAT1_3UTR)
