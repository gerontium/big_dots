#Remove the seperate ID vector now it has been included into data dataframe
rm(ID)
drops <- c("ID")
data_Stim_locked_ERP<-data_Stim_locked_ERP[,!(names(data_Stim_locked_ERP) %in% drops)]
#Merge with the RT, Accuracy, Hemifield data
data_Stim_locked_ERP<- data_Stim_locked_ERP %>% #Rename data columns:
rename(.,
ID=V1,
TotalTrialNumber=V2,
Trial=V3,
Time=V4,
CPP=V5,
N2c=V6,
N2i=V7)
#Grab the columns from data that I need to merge in
toMerge<-data %>% select(ID, Trial, Art_neg100_100PR, FixBreak_neg100_100PR, Hemifield, RT)
#Now merge them
data_Stim_locked_ERP<-data_Stim_locked_ERP %>%   merge(., toMerge, by = c("ID", "Trial"))
#Filter out artifacts
data_Stim_locked_ERP<- data_Stim_locked_ERP %>%
filter(!Art_neg100_100PR, !FixBreak_neg100_100PR) %>%
select(-Art_neg100_100PR, -FixBreak_neg100_100PR)
###########################################################################################################
#Plot Stimonse locked
detach("package:dplyr", unload=TRUE) #Detach dplyr as functions below use plyr
source("summarySE.R")
source("summarySEwithin.R") #function to calculate Std.Er of mean
source("normDataWithin.R")
plotdata_Stim_locked_CPP <- summarySEwithin(data_Stim_locked_ERP, measurevar="CPP", withinvars=c("Time", "Hemifield"), idvar="ID")
plotdata_Stim_locked_CPP$Time<-as.numeric(as.character(plotdata_Stim_locked_CPP$Time))
plotdata_Stim_locked_N2c <- summarySEwithin(data_Stim_locked_ERP, measurevar="N2c", withinvars=c("Time", "Hemifield"), idvar="ID")
plotdata_Stim_locked_N2c$Time<-as.numeric(as.character(plotdata_Stim_locked_N2c$Time))
plotdata_Stim_locked_N2i <- summarySEwithin(data_Stim_locked_ERP, measurevar="N2i", withinvars=c("Time", "Hemifield"), idvar="ID")
plotdata_Stim_locked_N2i$Time<-as.numeric(as.character(plotdata_Stim_locked_N2i$Time))
summary(plotdata_Stim_locked_CPP$Time)
lapply(required_packages, require, character.only = TRUE) # re-load all librarys no that I'm finished with dlyr
##First import the scalp plots from matlab to inclued on a ggplot
library(png)
library(grid)
#Read in .png and transform it to a raster grob
CPP_scalp <- rasterGrob(readPNG("CPP_scalp.png",native = T, info = T), interpolate=TRUE)
N2c_LeftTarget_scalp <- rasterGrob(readPNG("N2c_LeftTarget_scalp.png"), interpolate=TRUE)
N2c_RightTarget_scalp <- rasterGrob(readPNG("N2c_RightTarget_scalp.png"), interpolate=TRUE)
Alpha_scalp<- rasterGrob(readPNG("Alpha_scalp.png",native = T, info = T), interpolate=TRUE)
Beta_scalp<- rasterGrob(readPNG("Beta_scalp.png",native = T, info = T), interpolate=TRUE)
N2_scalp<- rasterGrob(readPNG("N2_scalp.png",native = T, info = T), interpolate=TRUE)
N2_scalp2<- rasterGrob(readPNG("N2_scalp2.png",native = T, info = T), interpolate=TRUE)
Paradigm<- rasterGrob(readPNG("Paradigm_v2.png",native = T, info = T), interpolate=TRUE)
participant_level_long<-participant_level %>%
select(ID, RT_Left, RT_Right, CPPonset_LeftTarget, CPPonset_RightTarget) %>%
gather(measure_type, data, -ID)
participant_level_long$Hemifield[participant_level_long$measure_type=="CPPonset_RightTarget"|
participant_level_long$measure_type=="RT_Right"] <- "Right"
participant_level_long$Hemifield[participant_level_long$measure_type=="CPPonset_LeftTarget"|
participant_level_long$measure_type=="RT_Left"] <- "Left"
participant_level_long$Measure[participant_level_long$measure_type=="CPPonset_RightTarget"|
participant_level_long$measure_type=="CPPonset_LeftTarget"] <- "CPP Onset"
participant_level_long$Measure[participant_level_long$measure_type=="RT_Right"|
participant_level_long$measure_type=="RT_Left"] <- "RT"
p_violin<-ggplot(participant_level_long, aes(measure_type, data, colour = Hemifield))  +
scale_y_continuous(limits = c(-100, 900)) +
geom_violin(aes(linetype = Measure), size=1) +
# geom_boxplot(aes(linetype = Measure), alpha=0.1, notch=T, notchwidth=0.75, width = 0.3) +
xlab("Target Hemifield") + ylab("Time (ms)") +
theme(  axis.title.x = element_blank(), #element_text(face="bold", size=12),
axis.text.x  =  element_blank(), #element_text(face="bold", angle=0,  size=12),
axis.ticks.x=element_blank(),
axis.title.y = element_text(face="bold", size=12, colour = "white"),
axis.text.y=element_text(angle=90, vjust=0.5, size=10, colour = "white"),
axis.ticks.y=element_blank(),
legend.title = element_text(size=12, face="bold"),
legend.text = element_text(size = 12, face = "bold"),
panel.background = element_blank(), #remove grey background
legend.position=c(0.9,0.22),  #Move ledgend position
axis.line = element_line(colour = "black")) +
guides(colour=FALSE) +
geom_hline(yintercept=0, alpha = 0.5) +
geom_hline(yintercept=as.numeric(participant_level %>% select(RT_Left) %>% summarise(mean(RT_Left))), #add dashed verticle for RT
colour  = scales::hue_pal()(1), size=0.75,  linetype="dashed", alpha=0.75) +
geom_hline(yintercept=as.numeric(participant_level %>% select(RT_Right) %>% summarise(mean(RT_Right))),
colour  = scales::hue_pal()(2)[2], size=0.75,  linetype="dashed", alpha=0.75) +
geom_hline(yintercept=as.numeric(participant_level %>% select(CPPonset_LeftTarget) %>% summarise(mean(CPPonset_LeftTarget))),
colour  = scales::hue_pal()(1), size=0.75, alpha=0.75) +
geom_hline(yintercept=as.numeric(participant_level %>% select(CPPonset_RightTarget) %>% summarise(mean(CPPonset_RightTarget))),
colour  = scales::hue_pal()(2)[2], size=0.75, alpha=0.75) +
stat_summary(fun.data="mean_se",  fun.args = list(mult=1),
geom="pointrange", color = "purple", size=0.5) +
coord_flip() +
annotate("text", x = 4.25, y = -75, label = "[A]", size=6)
p_CPP<-ggplot(plotdata_Stim_locked_CPP, aes(x=Time, y=CPP, color=Hemifield,fill=Hemifield)) +
geom_line(size=1) +
geom_ribbon(aes(ymin=CPP-ci, ymax=CPP+ci), alpha = 0.5, colour=NA) +
coord_cartesian(ylim = c(-0.1, 6),  xlim = c(-100, 900)) +
xlab("Time (ms)") + ylab("CPP Amplitude (uV)") +
theme(axis.title.x = element_text(face="bold", size=12),
axis.text.x  = element_text(face="bold", angle=0,  size=12), #element_text(face="bold", angle=0,  size=12),
axis.title.y = element_text(face="bold", size=12),
axis.text.y  = element_text(angle=0, vjust=0.5, size=12),
legend.title = element_text(size=12, face="bold"),
legend.text = element_text(size = 12, face = "bold"),
panel.background = element_blank(), #remove grey background
legend.position= c(0.88,0.88)) + #Move ledgend position
guides(color=FALSE) +
annotation_custom(CPP_scalp,xmin = 30, xmax = 270, ymin = 4, ymax = 6.25) + #add the CPP scapl plot
geom_vline(xintercept=as.numeric(participant_level %>% select(RT_Left) %>% summarise(mean(RT_Left))), #add dashed verticle for RT
colour  = scales::hue_pal()(1), size=0.75,  linetype="dashed", alpha=0.75) +
geom_vline(xintercept=as.numeric(participant_level %>% select(RT_Right) %>% summarise(mean(RT_Right))),
colour  = scales::hue_pal()(2)[2], size=0.75,  linetype="dashed", alpha=0.75) +
geom_vline(xintercept=as.numeric(participant_level %>% select(CPPonset_LeftTarget) %>% summarise(mean(CPPonset_LeftTarget))),
colour  = scales::hue_pal()(1), size=0.75, alpha=0.75) +
geom_vline(xintercept=as.numeric(participant_level %>% select(CPPonset_RightTarget) %>% summarise(mean(CPPonset_RightTarget))),
colour  = scales::hue_pal()(2)[2], size=0.75, alpha=0.75) +
geom_hline(yintercept=0, alpha = 0.5) +
geom_vline(xintercept=0, alpha = 0.5) + #add black likes at 0 on x and y axis
scale_x_continuous(breaks = seq(-100, 900, 50)) + #increase the resolution of the axis ticks
scale_y_continuous(breaks = seq(0,6,1)) +
annotate("text", x = -75, y = 6, label = "[B]", size=6)
p_CPP
#N2c plot
ggplot(plotdata_Stim_locked_N2c, aes(x=Time, y=N2c, color=Hemifield,fill=Hemifield)) +
geom_line(size=1.4) + geom_ribbon(aes(ymin=N2c-ci, ymax=N2c+ci), alpha = 0.3, colour=NA) +
geom_hline(yintercept=0, alpha = 0.5) + geom_vline(xintercept=0, alpha = 0.5) +
coord_cartesian(ylim = c(-3, 0.5),  xlim = c(-100, 500)) +
xlab("Time") + ylab("N2c Amplitude (uV)") +
theme(axis.title.x = element_text(face="bold", size=12),
axis.text.x  = element_text(face="bold", angle=0,  size=12)) +
theme(axis.title.y = element_text(face="bold", size=12),
axis.text.y  = element_text(angle=0, vjust=0.5, size=12)) +
theme(legend.title = element_text(size=11, face="bold")) +
theme(legend.text = element_text(size = 11, face = "bold")) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"))
#N2i plot
ggplot(plotdata_Stim_locked_N2i, aes(x=Time, y=N2i, color=Hemifield,fill=Hemifield)) +
geom_line(size=1.4) + geom_ribbon(aes(ymin=N2i-ci, ymax=N2i+ci), alpha = 0.3, colour=NA) +
geom_hline(yintercept=0, alpha = 0.5) + geom_vline(xintercept=0, alpha = 0.5) +
coord_cartesian(ylim = c(-3, 0.5),  xlim = c(-100, 500)) +
xlab("Time") + ylab("N2i Amplitude (uV)") +
theme(axis.title.x = element_text(face="bold", size=12),
axis.text.x  = element_text(face="bold", angle=0,  size=12)) +
theme(axis.title.y = element_text(face="bold", size=12),
axis.text.y  = element_text(angle=0, vjust=0.5, size=12)) +
theme(legend.title = element_text(size=11, face="bold")) +
theme(legend.text = element_text(size = 11, face = "bold")) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"))
###################Plot N2c and N2i trace in the same plot #####################
plotdata_Stim_locked_N2i$Hemisphere<-rep("Ipsilateral",length(plotdata_Stim_locked_N2i[,1]))
names(plotdata_Stim_locked_N2i)[names(plotdata_Stim_locked_N2i)=="N2i"] <- "N2"
names(plotdata_Stim_locked_N2i)[names(plotdata_Stim_locked_N2i)=="N2i_norm"] <- "N2_norm"
plotdata_Stim_locked_N2c$Hemisphere<-rep("Contralateral",length(plotdata_Stim_locked_N2c[,1]))
names(plotdata_Stim_locked_N2c)[names(plotdata_Stim_locked_N2c)=="N2c"] <- "N2"
names(plotdata_Stim_locked_N2c)[names(plotdata_Stim_locked_N2c)=="N2c_norm"] <- "N2_norm"
plotdata_N2<-rbind(plotdata_Stim_locked_N2i,plotdata_Stim_locked_N2c)
p_N2<-ggplot(plotdata_N2, aes(x=Time, y=N2, color=Hemifield,fill=Hemifield, linetype=Hemisphere)) +
annotation_custom(N2_scalp2,xmin = 0, xmax = 230, ymin = -1.2, ymax = -2.72) + #add the scapl plot
geom_line(size=1) +
geom_ribbon(aes(ymin=N2-ci, ymax=N2+ci), alpha = 0.3, colour=NA) +
geom_hline(yintercept=0, alpha = 0.5) + geom_vline(xintercept=0, alpha = 0.5) +
coord_cartesian(ylim = c(-2.7, 0.45), xlim = c(-100, 500)) +
xlab("Time (ms)") + ylab("N2 Amplitude (uV)") +
theme(axis.title.x = element_text(face="bold", size=12),
axis.text.x  = element_text(face="bold", angle=0,  size=12), #element_text(face="bold", angle=0,  size=12),
axis.title.y = element_text(face="bold", size=12),
axis.text.y  = element_text(angle=0, vjust=0.5, size=12),
legend.title = element_text(size=12, face="bold"),
legend.text = element_text(size = 12, face = "bold"),
panel.background = element_blank(), #remove grey background
legend.position= c(0.85,0.19)) + #Move ledgend position
guides(color=FALSE, fill=FALSE) +
theme(panel.margin = unit(1.5, "lines")) +
scale_x_continuous(breaks = seq(-100, 500, 100)) + #increase the resolution of the axis ticks
scale_y_continuous(breaks = seq(-2.7,1, 0.5)) +
annotate("text", x = -75, y = 0.45, label = "[E]", size=6)
p_N2
###########################################################################################################
###### Import trial sample level data Stim locked Beta
if (location=="Monash") {
data_Stim_locked_Beta <- read.csv("C:/GitHub/big_dots/master_matrix_R_Stim_locked_beta.csv", header=FALSE)
ID <- read.table("C:/GitHub/big_dots/ID_vector_Stim_locked_beta.csv", quote="\"")
} else if (location=="DansLaptop") {
data_Stim_locked_Beta <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/master_matrix_R_Stim_locked_beta.csv", header=FALSE)
ID <- read.table("C:/Users/Dan/Documents/GitHub/big_dots/ID_vector_Stim_locked_beta.csv", quote="\"")
} else setwd(("~"))
data_Stim_locked_Beta$ID<-data_Stim_locked_Beta[,1]
#Replace the participant numbers with IDs:
data_Stim_locked_Beta[,1]<-ID[,1]
#Remove the seperate ID vector now it has been included into data dataframe
rm(ID)
drops <- c("ID")
data_Stim_locked_Beta<-data_Stim_locked_Beta[,!(names(data_Stim_locked_Beta) %in% drops)]
#Merge with the RT, Accuracy, Hemifield data
data_Stim_locked_Beta<- data_Stim_locked_Beta %>% #Rename data columns:
rename(.,
ID=V1,
TotalTrialNumber=V2,
Trial=V3,
Time=V4,
Stim_locked_Beta=V5) %>%
merge(., data, by = c("ID", "Trial", "TotalTrialNumber"))
#Filter out artifacts
data_Stim_locked_Beta<- data_Stim_locked_Beta %>% filter(!Art_neg100_100PR, !FixBreak_neg100_100PR)
###########################################################################################################
#Plot Stimonse locked
detach("package:dplyr", unload=TRUE) #Detach dplyr as functions below use plyr
source("summarySE.R")
source("summarySEwithin.R") #function to calculate Std.Er of mean
source("normDataWithin.R")
plotdata_Stim_locked_Beta <- summarySEwithin(data_Stim_locked_Beta, measurevar="Stim_locked_Beta", withinvars=c("Time", "Hemifield"), idvar="ID")
plotdata_Stim_locked_Beta$Time<-as.numeric(as.character(plotdata_Stim_locked_Beta$Time))
summary(plotdata_Stim_locked_Beta$Time)
lapply(required_packages, require, character.only = TRUE) # re-load all librarys no that I'm finished with dlyr
#Stim_locked_Beta Group on same plot
p_Beta<-ggplot(plotdata_Stim_locked_Beta, aes(x=Time, y=Stim_locked_Beta, color=Hemifield,fill=Hemifield)) +
annotation_custom(Beta_scalp,xmin = 200, xmax = 800, ymin = -0.04, ymax = -0.001) + #add the scapl plot
geom_line(size=1) +
geom_ribbon(aes(ymin=Stim_locked_Beta-ci, ymax=Stim_locked_Beta+ci), alpha = 0.3, colour=NA) +
geom_hline(yintercept=0, alpha = 0.5) + geom_vline(xintercept=0, alpha = 0.5) +
coord_cartesian(ylim = c(-0.1, 0.01),  xlim = c(-100, 800)) +
xlab("Time") + ylab("Beta Power (uV)") +
theme(axis.title.x = element_text(face="bold", size=12),
axis.text.x  = element_text(face="bold", angle=0,  size=12), #element_text(face="bold", angle=0,  size=12),
axis.title.y = element_text(face="bold", size=12),
axis.text.y  = element_text(face="bold", angle=0, size=12),
panel.background = element_blank(),
legend.position= c(0.35,0.19),
legend.title = element_text(size=12, face="bold"),
legend.text = element_text(size = 12, face = "bold")) +
annotate("text", x = -75, y = 0.01, label = "[D]", size=6)
p_Beta
##Calculate t_values for each of the rolling variables ability to predict log(RT) at each time point
plot_data<-data_Stim_locked_Beta %>%
group_by(Hemifield, Time) %>%
do(Beta_Amplitude = summary(lmer(log(RT) ~ Stim_locked_Beta + (1|ID) + (1|ITI), data = ., REML=F))$coefficients[2,3]) %>%
gather(., key, t_value, -Hemifield, -Time) %>%
mutate(t_value= as.double(t_value)) %>%
arrange(key)
plot_data <- plot_data %>% arrange(key)
ggplot(plot_data, aes(Time, t_value, colour=Hemifield)) + geom_line(size=1.4) +
geom_hline(yintercept=2, alpha = 0.5,  size=1.4) + geom_hline(yintercept=-2, alpha = 0.5,  size=1.4) + geom_vline(xintercept=0, alpha = 0.5,  size=1.4) +
coord_cartesian(ylim = c(-5, 8), xlim = c(-100, 800)) +
theme(axis.title.x = element_text(face="bold", size=14),
axis.text.x  = element_text(face="bold", angle=0,  size=14)) +
theme(axis.title.y = element_text(face="bold", size=14),
axis.text.y  = element_text(angle=0, vjust=0.5, size=14)) +
theme(plot.title = element_text(face="bold", size=16)) +
theme(strip.text.x = element_text(size = 13))
##Pull out mean beta amplitude measures from 300 - 500ms in stim locked beta
beta_participant_level<- data_Stim_locked_Beta %>%
filter(Time>300, Time<500) %>%
group_by(ID, Hemifield) %>%
summarise(Stim_locked_Beta=mean(Stim_locked_Beta)) %>%
spread(Hemifield, Stim_locked_Beta) %>%
select(Beta_LeftTarget = Left,
Beta_RightTarget = Right) %>%
mutate(Beta_Asym = (Beta_LeftTarget-Beta_RightTarget)/(Beta_LeftTarget+Beta_RightTarget)) %>%
ungroup()
#Merge with participant_level data.frame (note don't worry that it coerces ID from factor to character vector)
participant_level<-left_join(participant_level, beta_participant_level, by = "ID")
#Remove it to free up some memory
rm(data_Stim_locked_Beta)
###########################################################################################################
###### Import trial sample level data Resp locked Beta
if (location=="Monash") {
data_Resp_locked_Beta <- read.csv("C:/GitHub/big_dots/master_matrix_R_Resp_locked_beta.csv", header=FALSE)
ID <- read.table("C:/GitHub/big_dots/ID_vector_Resp_locked_beta.csv", quote="\"")
} else if (location=="DansLaptop") {
data_Stim_locked_Beta <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/master_matrix_R_Resp_locked_beta.csv", header=FALSE)
ID <- read.table("C:/Users/Dan/Documents/GitHub/big_dots/ID_vector_Resp_locked_beta.csv", quote="\"")
} else setwd(("~"))
data_Resp_locked_Beta$ID<-data_Resp_locked_Beta[,1]
#Replace the participant numbers with IDs:
data_Resp_locked_Beta[,1]<-ID[,1]
#Remove the seperate ID vector now it has been included into data dataframe
rm(ID)
drops <- c("ID")
data_Resp_locked_Beta<-data_Resp_locked_Beta[,!(names(data_Resp_locked_Beta) %in% drops)]
#Merge with the RT, Accuracy, Hemifield data
data_Resp_locked_Beta<- data_Resp_locked_Beta %>% #Rename data columns:
rename(.,
ID=V1,
TotalTrialNumber=V2,
Trial=V3,
Time=V4,
Resp_locked_Beta=V5,
Resp_locked_Beta_NOTbaselined=V6) %>%
merge(., data, by = c("ID", "Trial", "TotalTrialNumber"))
#Filter out artifacts
data_Resp_locked_Beta<- data_Resp_locked_Beta %>% filter(!Art_neg100_100PR)
###########################################################################################################
#Plot response locked
detach("package:dplyr", unload=TRUE) #Detach dplyr as functions below use plyr
source("summarySE.R")
source("summarySEwithin.R") #function to calculate Std.Er of mean
source("normDataWithin.R")
plotdata_Resp_locked_Beta <- summarySEwithin(data_Resp_locked_Beta, measurevar="Resp_locked_Beta", withinvars=c("Time", "Hemifield"), idvar="ID")
plotdata_Resp_locked_Beta_NOTbaselined <- summarySEwithin(data_Resp_locked_Beta, measurevar="Resp_locked_Beta_NOTbaselined", withinvars=c("Time", "Hemifield"), idvar="ID")
plotdata_Resp_locked_Beta$Time<-as.numeric(as.character(plotdata_Resp_locked_Beta$Time))
plotdata_Resp_locked_Beta_NOTbaselined$Time<-as.numeric(as.character(plotdata_Resp_locked_Beta_NOTbaselined$Time))
summary(plotdata_Resp_locked_Beta$Time)
lapply(required_packages, require, character.only = TRUE) # re-load all librarys now that I'm finished with plyr
#Resp_locked_Beta Group on same plot
ggplot(plotdata_Resp_locked_Beta, aes(x=Time, y=Resp_locked_Beta, color=Hemifield,fill=Hemifield)) +
geom_line(size=1.4) + geom_ribbon(aes(ymin=Resp_locked_Beta-ci, ymax=Resp_locked_Beta+ci), alpha = 0.3, colour=NA) +
geom_hline(yintercept=0, alpha = 0.5) + geom_vline(xintercept=0, alpha = 0.5) +
coord_cartesian(ylim = c(-0.104, 0.01),  xlim = c(-600, 100)) +
xlab("Time") + ylab("Beta Power (uV)") +
theme(axis.title.x = element_text(face="bold", size=12),
axis.text.x  = element_text(face="bold", angle=0,  size=12)) +
theme(axis.title.y = element_text(face="bold", size=12),
axis.text.y  = element_text(angle=0, vjust=0.5, size=12)) +
theme(legend.title = element_text(size=11, face="bold")) +
theme(legend.text = element_text(size = 11, face = "bold")) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"))
##Pull out mean beta amplitude measures from -300 to -50ms in Resp locked beta
beta_participant_level<- data_Resp_locked_Beta %>%
filter(Time>-300, Time<(-50)) %>%
group_by(ID, Hemifield) %>%
summarise( xyBar =mean(Time*Resp_locked_Beta),
xBar = mean(Time),
yBar = mean(Resp_locked_Beta),
x2Bar =mean(Time^2),
Resp_locked_Beta_Slope = (xyBar - xBar*yBar) / (x2Bar - xBar^2)) %>%
select(ID, Hemifield, Resp_locked_Beta_Slope) %>%
spread(Hemifield, Resp_locked_Beta_Slope) %>%
select(Beta_slope_LeftTarget = Left,
Beta_slope_RightTarget = Right) %>%
mutate(Beta_slope_Asym = (Beta_slope_LeftTarget-Beta_slope_RightTarget)/(Beta_slope_LeftTarget+Beta_slope_RightTarget))
#Merge with participant_level data.frame (note don't worry that it coerces ID from factor to character vector)
participant_level<-left_join(participant_level, beta_participant_level, by = "ID")
#Remove it to free up some memory
rm(data_Resp_locked_Beta)
library(broom)
### Fitting the Model
intercept_only<-lm(RT_Asym~ 1, data=participant_level)
Controls <- update(intercept_only, .~. + Location + Sex + Age)
PreAlphaAsym<-update(Controls, .~. + PreAlphaAsym)
N2c_Asym<-update(PreAlphaAsym, .~. + N2c_Asym)
N2c_latency_Asym<-update(N2c_Asym, .~. + N2c_latency_Asym)
CPPonset_Asym<-update(N2c_latency_Asym, .~. + CPPonset_Asym)
CPPslope_Asym<-update(CPPonset_Asym, .~. + CPPslope_Asym)
Beta_Asym<-update(CPPslope_Asym, .~. + Beta_Asym)
Beta_slope_Asym<-update(Beta_Asym, .~. + Beta_slope_Asym)
anova(intercept_only, Controls, PreAlphaAsym, N2c_Asym, N2c_latency_Asym, CPPonset_Asym, CPPslope_Asym, Beta_Asym, Beta_slope_Asym)
summary(Controls)
summary(PreAlphaAsym)
summary(N2c_Asym)
summary(N2c_latency_Asym)
summary(CPPonset_Asym)
summary(CPPslope_Asym)
summary(Beta_Asym)
summary(Beta_slope_Asym)
#For the final model, only keep predictors that significantly improve model fit
final_model<-lm(RT_Asym ~  PreAlphaAsym + N2c_latency_Asym + CPPonset_Asym, data=participant_level)
kable(tidy(final_model),digits=3)
#---We can obtain standardized parameter estimates with the lm.beta() "QuantPsyc" pachage function---
#Standardized Beta values can be compared to each other and therefore allow us to gague the relative
#importance of each predictor.
library(car)
library(QuantPsyc)
lm.beta(final_model)
confint(final_model, level=0.95) # CIs for model parameters
# fitted(final_model) # predicted values
# residuals(final_model) # residuals
# vcov(final_model) # covariance matrix for model parameters
# influence(final_model) # regression diagnostics
# diagnostic plots
layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page
plot(final_model)
#----Obtain casewise diagnostics and add them to the original data file.---
participant_level$residuals<-residuals(final_model)
participant_level$standardized.residuals <- rstandard(final_model)
participant_level$cooks.distance<-cooks.distance(final_model)
participant_level$dfbeta <- dfbeta(final_model)
participant_level$dffit <- dffits(final_model)
participant_level$leverage <- hatvalues(final_model)
participant_level$covariance.ratios <- covratio(final_model)
participant_level$fitted <-fitted(final_model)
#----List of standardized residuals greater than 2--------------
participant_level$large.residual<-participant_level$standardized.residuals>2| participant_level$standardized.residuals < -2
# only about 5% of the sample should have standardized residuals greater than 2
cat("Percentage of sample with standardized residuals greater than abs 2:")
cat((sum(participant_level$large.residual)/length(participant_level$RT_Asym))*100,"%")
#-----Cook's distance, leverage and covariance ratio for cases with large residuals.---------
participant_level[participant_level$large.residual , c("ID", "standardized.residuals", "cooks.distance", "leverage", "covariance.ratios")]
#no cooks difference values greater than 1, so none of these are having too much influence on the model
#----The Durbin-Watson test is obtained with either dwt() or durbinWatsonTest()---
#This is a test for independence
durbinWatsonTest(final_model) # D-W Statistic is close to 2 and nowhere near significant so we are all good
#----Obtaining the VIF to assess collinearity/multicillinearity---
vif(final_model)
#tolerance:
1/vif(final_model)
# If the largest VIF is greater than 10 then there is a multicillinearity problem
# If the average VIF is substantially greater than 1 there could be a multicillinearity problem
# Tolerances below 0.1 indicate a serious multicillinearity problem
# Tolerances below 0.2 indicate a potential multicillinearity problem
#Plot standardized residual histogram
residuals_final_model=residuals(final_model)
plot(residuals_final_model)
qqnorm(residuals_final_model)
qqline(residuals_final_model)
hist(residuals_final_model)
# Stepwise Regression
library(MASS)
fit <- lm(RT_Asym~ Location + Sex + Age + PreAlphaAsym + N2c_Asym + N2c_latency_Asym + CPPonset_Asym + CPPslope_Asym + Beta_Asym + Beta_slope_Asym, data=participant_level)
step <- stepAIC(fit, direction="both")
step$anova # display results
tidy(step)
# # All Subsets Regression
# library(leaps)
# leaps<-regsubsets(RT_Asym~ Location + Sex + Age + PreAlphaAsym + N2c_Asym + N2c_latency_Asym + CPPonset_Asym + CPPslope_Asym + Beta_Asym + Beta_slope_Asym, data=participant_level,nbest=9)
# # plot a table of models showing variables in each model.
# # models are ordered by the selection statistic.
# layout(1)
# plot(leaps,scale="r2")
# plot(leaps, scale="adjr2")
# plot(leaps, scale="bic")
############################################################################################
##------Bootstrapping------
library(boot)
#---Write a bootstrap function.
bootReg<-function(formula, data, i)
{
d <- data[i,]
fit <- lm(formula, data = d)
return(coef(fit))
}
#----bootstrapping our regression model, with 5000 replications---
bootResults<-boot(statistic = bootReg, formula = RT_Asym ~  PreAlphaAsym + N2c_latency_Asym + CPPonset_Asym, data = participant_level, R = 5000)
#---We can then obtaine the bootstrap confidence intervals for the intercept:---
boot.ci(bootResults, type = "bca", index = 1)
#---And the slope estimates---
boot.ci(bootResults, type = "bca", index = 2) #PreAlphaAsym
boot.ci(bootResults, type = "bca", index = 3) #N2c_latency_Asym
boot.ci(bootResults, type = "bca", index = 4) #CPPonset_Asym
lm.boot(final_model, 3000, rows = TRUE, new.xpts = NULL, ngrid = 100,
weights = NULL)
library(boot)
#---Write a bootstrap function.
bootReg<-function(formula, data, i)
{
d <- data[i,]
fit <- lm(formula, data = d)
return(coef(fit))
}
#----bootstrapping our regression model, with 5000 replications---
bootResults<-boot(statistic = bootReg, formula = RT_Asym ~  PreAlphaAsym + N2c_latency_Asym + CPPonset_Asym, data = participant_level, R = 5000)
#---We can then obtaine the bootstrap confidence intervals for the intercept:---
boot.ci(bootResults, type = "bca", index = 1)
#---And the slope estimates---
boot.ci(bootResults, type = "bca", index = 2) #PreAlphaAsym
boot.ci(bootResults, type = "bca", index = 3) #N2c_latency_Asym
boot.ci(bootResults, type = "bca", index = 4) #CPPonset_Asym
lm.boot(final_model, 3000, rows = TRUE, new.xpts = NULL, ngrid = 100,
weights = NULL)
library(MASS)
install.packages(c("acepack", "colorspace", "curl", "effects", "evaluate", "foreign", "haven", "jsonlite", "lavaan", "lubridate", "MBESS", "mc2d", "mnormt", "openssl", "pbapply", "pcaPP", "plotly", "proto", "psych", "R.matlab", "R.oo", "R.utils", "R6", "RcppArmadillo", "reshape2", "rgeos", "rmarkdown", "schoRsch", "semTools", "shiny", "sourcetools", "stringi", "survey", "survival"))
install.packages(c("acepack", "colorspace", "curl", "effects",
"evaluate", "foreign", "haven", "jsonlite", "lavaan", "lubridate", "MBESS", "mc2d", "mnormt", "openssl", "pbapply", "pcaPP", "plotly", "proto", "psych", "R.matlab", "R.oo", "R.utils", "R6", "RcppArmadillo", "reshape2", "rgeos", "rmarkdown", "schoRsch", "semTools", "shiny", "sourcetools", "stringi", "survey", "survival"))
install.packages(c("acepack", "colorspace", "curl", "effects",
))
install.packages(c("acepack", "colorspace", "curl", "evaluate", "foreign", "haven", "jsonlite", "lavaan", "lubridate", "MBESS", "mc2d", "mnormt", "openssl", "pbapply", "pcaPP", "plotly", "proto", "psych", "R.matlab", "R.oo", "R.utils", "R6", "RcppArmadillo", "reshape2", "rgeos", "rmarkdown", "schoRsch", "semTools", "shiny", "sourcetools", "stringi", "survey", "survival"))
install.packages(c("acepack", "colorspace", "curl", "evaluate",
haven))
install.packages(c("acepack", "colorspace", "curl", "evaluate", "foreign", "jsonlite", "lavaan", "lubridate", "MBESS", "mc2d", "mnormt", "openssl", "pbapply", "pcaPP", "plotly", "proto", "psych", "R.matlab", "R.oo", "R.utils", "R6", "RcppArmadillo", "reshape2", "rgeos", "rmarkdown", "schoRsch", "semTools", "shiny", "sourcetools", "stringi", "survey", "survival"))
install.packages(c("acepack", "colorspace", "curl", "evaluate",
))
install.packages(c("plotly", "proto", "psych", "R.matlab", "R.oo", "R.utils", "R6", "RcppArmadillo", "reshape2", "rgeos", "rmarkdown", "schoRsch", "semTools", "shiny", "sourcetools", "stringi", "survey", "survival"))
install.packages(c("plotly", "proto", "psych", "R.matlab", "R.oo",
))
?? lm.boot
##------Bootstrapping------
library(boot)
library(simpleboot)
#---Write a bootstrap function.
bootReg<-function(formula, data, i)
{
d <- data[i,]
fit <- lm(formula, data = d)
return(coef(fit))
}
#----bootstrapping our regression model, with 5000 replications---
bootResults<-boot(statistic = bootReg, formula = RT_Asym ~  PreAlphaAsym + N2c_latency_Asym + CPPonset_Asym, data = participant_level, R = 5000)
#---We can then obtaine the bootstrap confidence intervals for the intercept:---
boot.ci(bootResults, type = "bca", index = 1)
#---And the slope estimates---
boot.ci(bootResults, type = "bca", index = 2) #PreAlphaAsym
boot.ci(bootResults, type = "bca", index = 3) #N2c_latency_Asym
boot.ci(bootResults, type = "bca", index = 4) #CPPonset_Asym
lm.boot(final_model, 3000, rows = TRUE, new.xpts = NULL, ngrid = 100,
weights = NULL)
Model.1 = lm(RT_Asym~N2c_latency_Asym, data=lone) # Y ~ X
Model.1 = lm(RT_Asym~N2c_latency_Asym, data=participant_level) # Y ~ X
Model.2 = lm(RT_Asym~CPPonset_Asym+N2c_latency_Asym, data=participant_level)# Y ~ M + X
Model.3 = lm(CPPonset_Asym~N2c_latency_Asym, data=participant_level) # M ~ X
summary(Model.1)
summary(Model.2)
summary(Model.3)
summary(Model.1)
summary(Model.2)
? mediate
library(mediation)
library(mediation)
install.packages("‘mediation’
")
install.packages("mediation")
library(mediation)
with(participant_level, mediate(N2c_latency_Asym,RT_Asym,CPPonset_Asym,
names=c("N2c_latency_Asym","RT_Asym","CPPonset_Asym")))
? mediate
