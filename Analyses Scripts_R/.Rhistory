sd(RT_index$RT_left) / sqrt(length(RT_index$RT_left))
sd(RT_index$RT_right) / sqrt(length(RT_index$RT_right))
8*7
4372/56
59*60
2915/56
60*57
50*57
50*57
15*313.001781
4754.03-(15*313.001781)
9*400
5*400
5*400
9*400
30*60
1800/300
1800/10
180/60
30/1
9603+56336
9603+56336+8000
31.257/2
2050/3.8
540*3.8
2000-540
1460+540
10*31
31-29.67
1.33*10
1.4^2
(50-.07)/.07
(2.3-3)/3
37.5*8
1300/3.8
340*3.8
340*3.8
350*3.8
buy=2,125.88
buy=2125.88
sell1=618.30
sell2=1646.05
sell1+sell2
(sell1+sell2-buy)/(sell1+sell2)
(2264.35-2125.88)/2125.88
(2264.35-2165.88)/2125.88
(sell1+sell2-buy+40)/(sell1+sell2)
8*
sADF
8*3
24*50
24*50
900/.70
900/.71
900/.72
2558.37-20
(2558.37-20)/3.83
(2558.37-20)/3.82
(2558.37-20)/3.82
(2558.37-20)/3.81
1910*10
1099472*.035
.071*2
(3478.32-150)/48
69+79
398.25*12
# installing/loading the package:
if(!require(installr)) {
install.packages("installr"); require(installr)} #load / install+load installr
# using the package:
updateR() # this will start the updating process of your R installation.  It will check for newer versions, and if one is available, will guide you through the decisions you'd need to make.
q()
library(foreign)
library(car)
library(nlme)
library(ggplot2)
library(pastecs)
library(psych)
library(plyr)
library(multcomp)
library(reshape2)
library(compute.es)
library(ez)
library(lattice)
library(lme4)
library(png)
library(grid)
23063-378
packages <- c("haven", "readr ", "dplyr", "tidyr", "ggplot2")
sapply(packages, require, character.only = TRUE, quietly = TRUE)
packages <- c("haven", "dplyr", "tidyr", "ggplot2")
sapply(packages, require, character.only = TRUE, quietly = TRUE)
? readr
?? readr
? sapply
.35*.35
library(dplyr)
x <- 1:50
case_when(
x %% 35 == 0 ~ "fizz buzz",
x %% 5 == 0 ~ "fizz",
x %% 7 == 0 ~ "buzz",
TRUE ~ as.character(x)
)
x
x
x <- 1:50
case_when(
x %% 35 == 0 ~ "fizz buzz",
x %% 5 == 0 ~ "fizz",
x %% 7 == 0 ~ "buzz",
TRUE ~ as.character(x)
)
####Which computer/directory is this being run on?
location<-"Monash"
# location<-"GersLaptop"
if (location=="Monash") {
setwd(("C:/GitHub/big_dots/Analyses Scripts_R"))
} else if (location=="GersLaptop") {
setwd(("C:/Users/loughnge/Documents/GitHub/big_dots/Analyses Scripts_R"))
} else setwd(("~"))
####################################
#######  How to use ################
####################################
# 1) Install the packages and software specified below. (consider also updating all installed packages by chosing Update on the Packages tab)
# 2) Set the working directory (setwd) above, and directory where you have "data_ParticipantLevel", "master_matrix_R" and "ID_vector" saved
# 3) Hit Knit Word (or Knit HTML)! (Output can take while due to bootstrapping the robust effect size and calculating the Bayesian Highest Density Iinterval)
####################################
######  FIRST TIME ONLY ############
####################################
#Remove # in front of the line below and run the code. Replace the # after installing the packages, otherwise the R markdown script will give errors.
# install.packages(c("MASS", "akima", "robustbase", "cobs", "robust", "mgcv", "scatterplot3d", "quantreg", "rrcov", "lars", "pwr", "trimcluster", "mc2d", "psych", "Rfit","MBESS", "BayesFactor", "PoweR", "ggplot2", "reshape2", "plyr", "devtools", "rmarkdown","gmodels", "HLMdiag", "car", "gridExtra", "bootES", "BEST","foreign","nlme","pastecs","multcomp","ggplot2","compute.es","ez","lattice","lme4","effects","diagram","png", "grid", "dplyr","readxl", "openxlsx", "haven","schoRsch"))
###################################################################################################################################
## load relevant libraries
library(foreign)
library(car)
library(nlme)
library(ggplot2)
library(pastecs)
library(psych)
library(multcomp)
library(compute.es)
library(ez)
library(lme4)
library(png)
library(grid)
library(readxl)
library(dplyr)
library(tidyr)
###### Import single trial data:
if (location=="Monash") {
data <- read.csv("C:/GitHub/big_dots/master_matrix_R_BigDots.csv", header=FALSE)
} else if (location=="GersLaptop") {
data <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/master_matrix_R_BigDots.csv", header=FALSE)
} else setwd(("~"))
#Import IDs:
if (location=="Monash") {
ID <- read.table("C:/GitHub/big_dots/ID_vector_BigDots.csv", quote="\"")
} else if (location=="GersLaptop") {
ID <- read.table("C:/Users/Dan/Documents/GitHub/big_dots/ID_vector_BigDots.csv", quote="\"")
} else setwd(("~"))
data$ID<-data[,1]
#Replace the participant numbers with IDs:
data[,1]<-ID[,1]
#Remove the seperate ID vector now it has been included into data dataframe
rm(ID)
drops <- c("ID")
data<-data[,!(names(data) %in% drops)]
###Read in SLF data from the SPSS file Tim Sent
SLF<-haven::read_sav("S:/R-MNHS-SPP/Bellgrove-data/4. Dan Newman/Participant Folders_new/SLF_metrics_290616.sav")
DARIS_ID<-readxl::read_excel("S:/R-MNHS-SPP/Bellgrove-data/4. Dan Newman/Participant Folders_new/DARIS_ID.xlsx")
SLF<-merge(SLF, DARIS_ID, by.x = "DARIS", by.y = "DARIS")
ID_Order <- read_excel("ID_Order_for_Matlab.xlsx")
SLF<-merge(SLF, ID_Order, by.x = "ID", by.y = "ID", all=T)
SLF<-dplyr::arrange(SLF, Order)
# xlsx::write.xlsx(SLF, "SLF.xlsx", row.names=F)
#########################################################################################################################
data<- data %>% #Rename data columns:
rename(.,
ID=V1,
TotalTrialNumber=V2,
Trial=V3,
ITI=V4,
Hemifield=V5,
Accuracy=V6,
Art_neg500_0=V7,
Art_neg100_100PR=V8,
Art_neg500_100PR=V9,
Art_neg100_1000=V10,
FixBreak_neg500_0=V11,
FixBreak_neg100_100PR=V12,
FixBreak_neg500_100PR=V13,
FixBreak_neg100_1000=V14,
RT=V15) %>% #next make the required columns into factors:
mutate_each_(funs(factor), c("ITI", "Hemifield", "Accuracy")) %>% #next re-class required vectors into Logicals:
mutate_at(vars(starts_with("Art_")), funs(as.logical)) %>%
mutate_at(vars(starts_with("FixBreak_")), funs(as.logical)) %>% #next use the ! negation operator to reverse of a TRUE/FALSE vectors:
mutate_if(purrr::is_logical, funs(!.)) %>% #next Rename factor Levels:
mutate(Hemifield = ifelse(Hemifield==1, "Left", "Right"),
Accuracy= ifelse(Accuracy==1, "Hit", ifelse(Accuracy==2, "WrongButton", "Miss")))
#Only keep SLF measures for the participants who we actually tested on big dots
#(there are a few extra participants who we got SLF from who were not tested on big dots)
SLF <-SLF[SLF$ID %in% data$ID, ]
############################################ Import DAT1 Data ##############################################
DAT1 <- read_excel("DAT1genotypes_forR.xlsx")
#Make the required columns into factors:
DAT1<- DAT1 %>%  mutate_each_(funs(factor), c("DAT1_3UTR_VNTRraw", "DAT1_Int8_VNTRraw", "Site","ID"))
#Revalue the factors
DAT1$DAT1_10_10_repeats  <- plyr::revalue(DAT1$DAT1_3UTR_VNTRraw ,
c("10 10"="Two",
"10 11"="One",
"7 10"="One",
"7 9"="Zero",
"8 11"="Zero",
"9 10"="One",
"9 9"="Zero"))
summary(DAT1$DAT1_10_10_repeats)
DAT1$DAT1_3UTR  <- plyr::revalue(DAT1$DAT1_3UTR_VNTRraw ,
c("10 10"="10_10_repeat",
"10 11"="non10_10_repeat",
"7 10"="non10_10_repeat",
"7 9"="non10_10_repeat",
"8 11"="non10_10_repeat",
"9 10"="non10_10_repeat",
"9 9"="non10_10_repeat"))
summary(DAT1$DAT1_3UTR)
DAT1$DAT1_int8  <- plyr::revalue(DAT1$DAT1_Int8_VNTRraw ,
c("6 6"="6_6_repeat",
"5 6"="non6_6_repeat",
"5 5"="non6_6_repeat"))
summary(DAT1$DAT1_int8)
#Only keep Genotypes for the participants who we actually tested on big dots
#(there are a few extra participant genotypes in the DAT1 sheet)
DAT1 <-DAT1[DAT1$ID %in% data$ID, ]
#How many participant's have missing DAT1 genotype?
summary(DAT1$DAT1_3UTR) #So 4 participant have missing DAT1 genotype
#### Merge the data sets together
data<-merge(data, DAT1, by.x = "ID", by.y = "ID")
### Merge in the SLF data
SLF <-SLF[SLF$ID %in% data$ID, ]
data<-merge(data, SLF, by.x = "ID", by.y = "ID")
################################################################################################
#########Creat ordered DAT1 genotype .xlsx file for matlab:
# ID_Order <- read_excel("ID_Order_for_Matlab.xlsx")
# DAT1<-merge(DAT1, ID_Order, by.x = "ID", by.y = "ID")
#
# DAT1$DAT1_10_10  <- plyr::revalue(DAT1$DAT1_10_10_repeats ,
#                                        c("Zero"="0",
#                                          "One"="1",
#                                          "Two"="2"))
# DAT1<-dplyr::arrange(DAT1, Order)
# DAT1genotypes_for_Matlab<-dplyr::select(DAT1, ID, DAT1_10_10)
# xlsx::write.xlsx(DAT1genotypes_for_Matlab, file = "C:/GitHub/big_dots/DAT1genotypes_for_Matlab.xlsx", row.names = F)
###############Data Cleaning For Single Trial Data######################
#Check number of Trials for each participant by running the function 'length',
#on "data$RT" for each DAT1_3UTR, broken down by ID + Light
num_trials1 <- data %>% group_by(ID) %>% summarise( Trials = length(RT))
summary(num_trials1$Trials)
##################Accuracy ##########################
Accuracy_checker <- data %>% group_by(ID) %>%
summarise(Hits  = sum(Accuracy=="Hit"),
Misses = sum(Accuracy=="Miss" | Accuracy=="WrongButton")) %>%
mutate(Total=Hits+Misses,
Accuracy_overall= (Hits/Total)*100)
summary(Accuracy_checker$Accuracy_overall)
##Add in overall accuracy
data <- merge(data, Accuracy_checker, by.x = "ID", by.y = "ID")
###Remove trials where:
#RT longer than 1000ms (i.e. after target finished)
#RT faster than 100ms (i.e. too fast must be false alarm) or RT=0 (i.e. they did not respond)
#Kick out trials with fixation breaks:
data<-filter(data, RT<1500 & RT>150 & !FixBreak_neg100_100PR)
############################################ Log transform:
##############################################################################################
data$log_RT<-log(data$RT) #log
#####Z-score each participant's log_RT data ####
data$IDbyITIbyHemifield<-interaction(data$ID, data$ITI, data$Hemifield)
#calculate mean and sd
m <- tapply(data$log_RT,data$IDbyITIbyHemifield,mean, na.rm = T)
s <- sqrt(tapply(data$log_RT,data$IDbyITIbyHemifield,var, na.rm = T))
#calculate log_RT.Z and save it inside data.frame
data$log_RT.Z <- (data$log_RT-m[data$IDbyITIbyHemifield])/s[data$IDbyITIbyHemifield]
#Remove trials where absolute log_RT.Z>3 (i.e. remove outlier RTs)
data<-data[!abs(data$log_RT.Z)>3,]
#plot again after outlier removal:
ggplot(data, aes(RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white")
ggplot(data, aes(log_RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white")
#Calculate the number of trials each participant has left after fixation break trials are kicked out:
num_trials2 <- data %>% group_by(ID) %>% summarise( Trials = length(RT))
summary(num_trials2$Trials)
####Import participant_level_matrix with ERP measures
if (location=="Monash") {
data_participant_level <- read.csv("C:/GitHub/big_dots/participant_level_matrix.csv", header=FALSE)
} else if (location=="DansLaptop") {
data_participant_level <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/participant_level_matrix.csv", header=FALSE)
} else setwd(("~"))
#Import IDs:
if (location=="Monash") {
ID <- read.table("C:/GitHub/big_dots/IDs.csv", quote="\"")
} else if (location=="DansLaptop") {
ID <- read.csv("C:/Users/Dan/Documents/GitHub/big_dots/IDs.csv", header=F)
} else setwd(("~"))
ID<-plyr::rename(ID,c("V1"="ID"))
data_participant_level$ID<-ID$ID
rm(ID)
data_participant_level<- data_participant_level %>% #Rename data columns:
rename(.,
N2c_LeftTarget=V1,
N2c_RightTarget=V2,
N2i_LeftTarget=V3,
N2i_RightTarget=V4,
N2c_latency_LeftTarget=V5,
N2c_latency_RightTarget=V6,
N2i_latency_LeftTarget=V7,
N2i_latency_RightTarget=V8,
CPPonset_LeftTarget=V9,
CPPonset_RightTarget=V10,
CPPslope_LeftTarget=V11,
CPPslope_RightTarget=V12) %>% #next calculate the ERP asymmetry measures:
mutate(.,
N2c_Asym = (N2c_LeftTarget-N2c_RightTarget)/(N2c_LeftTarget+N2c_RightTarget),
N2i_Asym = (N2i_LeftTarget-N2i_RightTarget)/(N2i_LeftTarget+N2i_RightTarget),
N2c_latency_Asym = (N2c_latency_LeftTarget-N2c_latency_RightTarget)/(N2c_latency_LeftTarget+N2c_latency_RightTarget),
N2i_latency_Asym =(N2i_latency_LeftTarget-N2i_latency_RightTarget)/(N2i_latency_LeftTarget+N2i_latency_RightTarget),
CPPonset_Asym = (CPPonset_LeftTarget-CPPonset_RightTarget)/(CPPonset_LeftTarget+CPPonset_RightTarget),
CPPslope_Asym = (CPPslope_LeftTarget-CPPslope_RightTarget)/(CPPslope_LeftTarget+CPPslope_RightTarget)
)
View(num_trials1)
View(num_trials2)
RT_collapsed<- data %>%
# mutate(ID = as.character(ID)) %>% #just changed Id to as.character to stop left_join throwing a warning below :-)
group_by(ID, Hemifield, DAT1_3UTR) %>%
summarise(RT=mean(RT)) %>% #next bring Target-Hemifield up into wide format:
spread(Hemifield, RT) %>% #next rename
rename(RT_Left=Left, RT_Right=Right) %>% # next Calculate RT asymmetry:
mutate(RT_Asym=(RT_Left-RT_Right)/(RT_Left+RT_Right))
Asym_data<-RT_collapsed %>% select(., ID, DAT1_3UTR, contains("_LI_"), contains("Asym"), -contains(".Z"))
View(Asym_data)
#Collapse each participant's trials accross ITI
RT_collapsed<- data %>%
# mutate(ID = as.character(ID)) %>% #just changed Id to as.character to stop left_join throwing a warning below :-)
group_by(ID, Hemifield, DAT1_3UTR) %>%
summarise(RT=mean(RT)) %>% #next bring Target-Hemifield up into wide format:
spread(Hemifield, RT) %>% #next rename
rename(RT_Left=Left, RT_Right=Right) %>% # next Calculate RT asymmetry:
mutate(RT_Asym=(RT_Left-RT_Right)/(RT_Left+RT_Right)) %>% #next add in the ERP measures:
left_join(data_participant_level, by="ID") %>% #next add in the SLF data:
left_join(SLF, by="ID")
Asym_data<-RT_collapsed %>% select(., ID, DAT1_3UTR, contains("_LI_"), contains("Asym"), -contains(".Z"))
RT_collapsed<- data %>%
# mutate(ID = as.character(ID)) %>% #just changed Id to as.character to stop left_join throwing a warning below :-)
group_by(ID, Hemifield, DAT1_3UTR) %>%
summarise(RT=mean(RT)) %>% #next bring Target-Hemifield up into wide format:
spread(Hemifield, RT) %>% #next rename
rename(RT_Left=Left, RT_Right=Right) %>% # next Calculate RT asymmetry:
mutate(RT_Asym=(RT_Left-RT_Right)/(RT_Left+RT_Right))
Asym_data<-RT_collapsed %>% select(., ID, DAT1_3UTR, contains("_LI_"), contains("Asym"), -contains(".Z"))
View(Asym_data)
Asym_data<-RT_collapsed %>% select(., ID, DAT1_3UTR, contains("_LI_"), contains("Asym"), -contains("Left"))
View(Asym_data)
View(RT_collapsed)
RT_collapsed<- data %>%
# mutate(ID = as.character(ID)) %>% #just changed Id to as.character to stop left_join throwing a warning below :-)
group_by(ID, Hemifield, DAT1_3UTR) %>%
summarise(RT=mean(RT)) %>% #next bring Target-Hemifield up into wide format:
spread(Hemifield, RT) %>% #next rename
rename(RT_Left=Left, RT_Right=Right) %>% # next Calculate RT asymmetry:
mutate(RT_Asym=(RT_Left-RT_Right)/(RT_Left+RT_Right)) %>% #next add in the ERP measures:
left_join(data_participant_level, by="ID") %>% #next add in the SLF data:
left_join(SLF, by="ID")
colnames(RT_collapsed)
Asym_data<-RT_collapsed %>% select(., ID, DAT1_3UTR, contains("_LI_"), contains("Asym"))
View(Asym_data)
Asym_data_long<-Asym_data %>%
gather(key, asymmetry_index, -ID, -DAT1_3UTR) %>%
na.omit()
View(Asym_data_long)
ggplot(Asym_data_long, aes(asymmetry_index))  + geom_density() + facet_wrap(~ key, scales="free")
#Z-score each participant's asymmetry_index inside key ####
#calculate mean and sd
m <- tapply(Asym_data_long$asymmetry_index,Asym_data_long$key,mean, na.rm = T)
s <- sqrt(tapply(Asym_data_long$asymmetry_index,Asym_data_long$key,var, na.rm = T))
#calculate asymmetry_index.Z and save it inside Asym_data_long
Asym_data_long$asymmetry_index.Z <- (Asym_data_long$asymmetry_index-m[Asym_data_long$key])/s[Asym_data_long$key]
#Remove trials where absolute asymmetry_index.Z>3 (i.e. remove outlier RTs)
Asym_data_long<-Asym_data_long[!abs(Asym_data_long$asymmetry_index.Z)>3,]
RT_collapsed<- data %>%
# mutate(ID = as.character(ID)) %>% #just changed Id to as.character to stop left_join throwing a warning below :-)
group_by(ID, Hemifield, DAT1_3UTR) %>%
summarise(RT=mean(RT)) %>% #next bring Target-Hemifield up into wide format:
spread(Hemifield, RT) %>% #next rename
rename(RT_Left=Left, RT_Right=Right) %>% # next Calculate RT asymmetry:
mutate(RT_Asym=(RT_Left-RT_Right)/(RT_Left+RT_Right)) %>% #next add in the ERP measures:
left_join(data_participant_level, by="ID") %>% #next add in the SLF data:
left_join(SLF, by="ID")
#Get the required data i.e. ID, DAT1_3UTR and all the asymmeyry index measures
Asym_data<-RT_collapsed %>% select(., ID, DAT1_3UTR, contains("_LI_"), contains("Asym"))
#Transform it to long format
Asym_data_long<-Asym_data %>%
gather(key, asymmetry_index, -ID, -DAT1_3UTR) %>%
na.omit()
m <- tapply(Asym_data_long$asymmetry_index,Asym_data_long$key,mean, na.rm = T)
s <- sqrt(tapply(Asym_data_long$asymmetry_index,Asym_data_long$key,var, na.rm = T))
#calculate asymmetry_index.Z and save it inside Asym_data_long
Asym_data_long$asymmetry_index.Z <- (Asym_data_long$asymmetry_index-m[Asym_data_long$key])/s[Asym_data_long$key]
#Remove trials where absolute asymmetry_index.Z>3 (i.e. remove outlier RTs)
Asym_data_long<-Asym_data_long[!abs(Asym_data_long$asymmetry_index.Z)>3,]
ggplot(Asym_data_long, aes(asymmetry_index))  + geom_density() + facet_wrap(~ key, scales="free")
RT_collapsed<- data %>%
# mutate(ID = as.character(ID)) %>% #just changed Id to as.character to stop left_join throwing a warning below :-)
group_by(ID, Hemifield, DAT1_3UTR) %>%
summarise(RT=mean(RT)) %>% #next bring Target-Hemifield up into wide format:
spread(Hemifield, RT) %>% #next rename
rename(RT_Left=Left, RT_Right=Right) %>% # next Calculate RT asymmetry:
mutate(RT_Asym=(RT_Left-RT_Right)/(RT_Left+RT_Right)) %>% #next add in the ERP measures:
left_join(data_participant_level, by="ID") %>% #next add in the SLF data:
left_join(SLF, by="ID")
#Get the required data i.e. ID, DAT1_3UTR and all the asymmeyry index measures
Asym_data<-RT_collapsed %>% select(., ID, DAT1_3UTR, contains("_LI_"), contains("Asym"))
#Transform it to long format
Asym_data_long<-Asym_data %>%
gather(measure, asymmetry_index, -ID, -DAT1_3UTR) %>%
na.omit()
#Plot density plots before outlier removal
ggplot(Asym_data_long, aes(asymmetry_index))  + geom_density() + facet_wrap(~ measure, scales="free")
#################################################################
#Calculate Z scores inside measure type TO REMOVE OUTLIERS
#Z-score each participant's asymmetry_index inside measure ####
#calculate mean and sd
m <- tapply(Asym_data_long$asymmetry_index,Asym_data_long$measure,mean, na.rm = T)
s <- sqrt(tapply(Asym_data_long$asymmetry_index,Asym_data_long$measure,var, na.rm = T))
#calculate asymmetry_index.Z and save it inside Asym_data_long
Asym_data_long$asymmetry_index.Z <- (Asym_data_long$asymmetry_index-m[Asym_data_long$measure])/s[Asym_data_long$measure]
#Remove trials where absolute asymmetry_index.Z>3 (i.e. remove outlier RTs)
Asym_data_long<-Asym_data_long[!abs(Asym_data_long$asymmetry_index.Z)>3,]
#################################################################
#Plot density plots again after outlier removal
ggplot(Asym_data_long, aes(asymmetry_index))  + geom_density() + facet_wrap(~ measure, scales="free")
Asym_data_long$measure<-as.factor(Asym_data_long$measure)
Asym_data_wide<-Asym_data_long %>% select(., -asymmetry_index.Z)  %>%
spread(measure, asymmetry_index)
Asym_data_wide<-Asym_data_long %>% select(., -asymmetry_index.Z)  %>%
spread(measure, asymmetry_index)
lapply(select(Asym_data_wide, contains("_LI_"), contains("Asym"), -contains(".Z")), function(x) t.test(x ~ Asym_data_wide$DAT1_3UTR, na.action=na.omit))
RT_collapsed<- data %>%
# mutate(ID = as.character(ID)) %>% #just changed Id to as.character to stop left_join throwing a warning below :-)
group_by(ID, Hemifield, DAT1_3UTR) %>%
summarise(RT=mean(RT)) %>% #next bring Target-Hemifield up into wide format:
spread(Hemifield, RT) %>% #next rename
rename(RT_Left=Left, RT_Right=Right) %>% # next Calculate RT asymmetry:
mutate(RT_Asym=(RT_Left-RT_Right)/(RT_Left+RT_Right)) %>% #next add in the ERP measures:
left_join(data_participant_level, by="ID") %>% #next add in the SLF data:
left_join(SLF, by="ID")
#Get the required data i.e. ID, DAT1_3UTR and all the asymmeyry index measures
Asym_data<-RT_collapsed %>% select(., ID, DAT1_3UTR, contains("_LI_"), contains("Asym"))
#Transform it to long format
Asym_data_long<-Asym_data %>%
gather(measure, asymmetry_index, -ID, -DAT1_3UTR) %>%
na.omit()
#Plot density plots before outlier removal
ggplot(Asym_data_long, aes(asymmetry_index))  + geom_density() + facet_wrap(~ measure, scales="free")
#################################################################
#Calculate Z scores inside measure type TO REMOVE OUTLIERS
#Z-score each participant's asymmetry_index inside measure ####
#calculate mean and sd
m <- tapply(Asym_data_long$asymmetry_index,Asym_data_long$measure,mean, na.rm = T)
s <- sqrt(tapply(Asym_data_long$asymmetry_index,Asym_data_long$measure,var, na.rm = T))
#calculate asymmetry_index.Z and save it inside Asym_data_long
Asym_data_long$asymmetry_index.Z <- (Asym_data_long$asymmetry_index-m[Asym_data_long$measure])/s[Asym_data_long$measure]
#Remove trials where absolute asymmetry_index.Z>3 (i.e. remove outlier RTs)
Asym_data_long<-Asym_data_long[!abs(Asym_data_long$asymmetry_index.Z)>3,]
#################################################################
#Plot density plots again after outlier removal
ggplot(Asym_data_long, aes(asymmetry_index))  + geom_density() + facet_wrap(~ measure, scales="free")
Asym_data_long$measure<-as.factor(Asym_data_long$measure)
#Put it back into long format so I can use lapply to do t-test on every column
Asym_data_wide<-Asym_data_long %>% select(., -asymmetry_index.Z)  %>%
spread(measure, asymmetry_index)
View(Asym_data_wide)
Asym_data_wide<-Asym_data_long %>% select(., -asymmetry_index.Z)  %>%
spread(measure, asymmetry_index)
lapply(select(Asym_data_wide, contains("_LI_"), contains("Asym")), function(x) t.test(x ~ Asym_data_wide$DAT1_3UTR, na.action=na.omit))
RT_collapsed<- data %>%
# mutate(ID = as.character(ID)) %>% #just changed Id to as.character to stop left_join throwing a warning below :-)
group_by(ID, Hemifield, DAT1_3UTR) %>%
summarise(RT=mean(RT)) %>% #next bring Target-Hemifield up into wide format:
spread(Hemifield, RT) %>% #next rename
rename(RT_Left=Left, RT_Right=Right) %>% # next Calculate RT asymmetry:
mutate(RT_Asym=(RT_Left-RT_Right)/(RT_Left+RT_Right))
RT_collapsed<-merge(RT_collapsed, DAT1, by.x = "ID", by.y = "ID")
#Add in the ERP measures
RT_collapsed<-merge(RT_collapsed, data_participant_level, by.x = "ID", by.y = "ID")
#Add in the SLF data
RT_collapsed<-merge(RT_collapsed, SLF, by.x = "ID", by.y = "ID")
#Get the required data i.e. ID, DAT1_3UTR and all the asymmeyry index measures
Asym_data<-RT_collapsed %>% select(., ID, DAT1_3UTR, contains("_LI_"), contains("Asym"))
View(Asym_data)
Asym_data_long<-Asym_data %>%
gather(measure, asymmetry_index, -ID, -DAT1_3UTR) %>%
na.omit()
ggplot(Asym_data_long, aes(asymmetry_index))  + geom_density() + facet_wrap(~ measure, scales="free")
m <- tapply(Asym_data_long$asymmetry_index,Asym_data_long$measure,mean, na.rm = T)
s <- sqrt(tapply(Asym_data_long$asymmetry_index,Asym_data_long$measure,var, na.rm = T))
#calculate asymmetry_index.Z and save it inside Asym_data_long
Asym_data_long$asymmetry_index.Z <- (Asym_data_long$asymmetry_index-m[Asym_data_long$measure])/s[Asym_data_long$measure]
#Remove trials where absolute asymmetry_index.Z>3 (i.e. remove outlier RTs)
Asym_data_long<-Asym_data_long[!abs(Asym_data_long$asymmetry_index.Z)>3,]
Asym_data_long$measure<-as.factor(Asym_data_long$measure)
#Put it back into long format so I can use lapply to do t-test on every column
Asym_data_wide<-Asym_data_long %>% select(., -asymmetry_index.Z)  %>%
spread(measure, asymmetry_index)
lapply(select(Asym_data_wide, contains("_LI_"), contains("Asym")), function(x) t.test(x ~ Asym_data_wide$DAT1_3UTR, na.action=na.omit))
